
require_relative 'reader'
require 'tree'
include Tree
require_relative 'counter'
require_relative 'display'

BEGIN_DOC = '\begin{document}'
END_DOC = '\end{document}'


class Token

  attr_reader :type, :value

  def initialize(type, value)
    @type = type
    @value = value
  end

  def to_s
    "#{type}: #{value}"
  end

end

# This is a very rough draft of Parser
# that to a large extent is my experiment
# in trying to understand what eventually
# has to be done.  The end product of
# the parse routine now consists of
# two nodes on the stack, one for the
# header, one for the document body.
# The result of parsing is stored in the
# content field of these nodes.  In a
# forthcoming iterationk, we will have
# an actual tree.  The nodes, instances
# of Tree::TreeNode, are set up to make
# thie possible.

class Parser

  include Display

  attr_accessor :reader, :token, :stack

  def initialize(text)

    @reader = Reader.new(preprocess(text))
    @stack = []
    @counter = Counter.new

  end

  # Put space around '$', '\[', and '\]' so
  # that they will be recognized as tokens
  def preprocess(text)
    text = text.gsub('$', ' $ ')
    text = text.gsub('\\[', ' \\[ ')
    text.gsub('\\]', ' \\] ')
  end

  ####################################################
  #
  #                   Tokens
  #
  ####################################################

  # Tokens are obtained from the Reader using Reader # get_word.
  # and in the case of comments, Reader # get_line
  #
  # Tokens will be
  #   - a commment, that is, a line beginnng with %
  #   - a blank line
  #   - a word.  Words are surrounded by white space.
  # A single character, .e.g. '$' may be a "word"
  #
  # get_token returns a token and also records it
  # in the instance variable @token
  #
  def get_token
    word = @reader.get_word
    if word[0] == '%'
      @token = Token.new(:comment, reader.current_line)
      reader.advance_line
    elsif word == :blank_line
      @token = Token.new(:blank, "\n")
      reader.advance_line
    else
      @token = Token.new(:word, word)
    end
    @token
  end

  # To parse LL(1) grammars we need one-token
  # look-ahead, and we sometimes need to be
  # able to put back a token that was taken
  # 'by mistake'.
  #
  def put_token
    @token = @reader.put_word
  end

  ####################################################
  #
  #                   Stack
  #
  ####################################################

  # Three methods manipulating or reading
  # the stack.  The stack is intend to hold
  # and help compute oupput of the parser.

  def push_stack(node)
    @stack.push node
  end

  def pop_stack(count=1)
    @stack.pop(count)
  end

  def top_stack
    @stack[-1]
  end

  #############################################

  # Create a TreeNode (Tree::TreeNode) with
  # given content.  The name of the node must
  # be unque and so is generated by a counter.
  # The content of the node is generally a hash.

  def new_node(content)
    TreeNode.new(@counter.get, content)
  end

  ####################################################
  #
  #                   Grammar
  #
  ####################################################

  # PRODUCTIONS
  # document = header BEGIN_DOC body END_DOC
  # body = { expr }
  # expr = { text | macro | env | inline_math | display_math }
  # macro = \command \{ {args} \}
  # env = BEGIN_ENV expr END_ENV
  # inline_math = $ math_text #
  # display_math = \[ math_text \]
  #
  #
  # Terminals:
  # BEGIN_DOC = '\begin{document}'
  # END_DOC = '\end{document}'
  # Pseutotermnals
  # BEGIN_ENV = '\begin{' env_name '}'
  # END_ENV = '\end{' env_name '}'


  ####################################################
  #
  #                   Parser
  #
  ####################################################

  # A recursive-descent parser --- the
  # method 'Parse' at the end, preceded
  # by methods for each non-terminal element
  # in the grammar. (THE GRAMMAR AND HENCE
  # THE METHODS SILL NEED WORK)

  # header pushes one node onto the stack with content
  # type: :header
  # value: a string derived from the input
  # text from the beginning up to the token `\begin{document}`
  def header
    count = 0
    while @token.value != BEGIN_DOC
      get_token
      count += 1
      push_stack @token.value
    end
    pop_stack # remove \begin{document}
    header_value = pop_stack(count).join(' ').strip
    node = new_node({type: :header, value: header_value})
    push_stack node
  end

  # environment pushes one node onto the
  # stack with the following hash as content:
  #
  # type:     :environment
  #
  # env_type: a string representing the particular
  #           environment.  Thus '\begin{theorem}'
  #           will yield env_type: 'theorem'
  #
  # value:    a list representing the body of the environment.
  #           this list will have to be parsed (next iteration!)
  #
  # Suppose that the token '\begin{theorem}' is encountered by the parser.
  # Then the environment method is called with argument 'theorem'.  The
  # body of the environment is recognized by a while loop that terminates
  # when the token '\end{theorem}' is encountered.  An environment may
  # contain environments within it.  These will have to be parsed,
  # and this will require an adjustment to the parser, since don't
  # yet implment 'expr' inside 'environmnt'
  #
  def environment(end_token)
    rx = /\\end{(.*)}/
    env_type = (end_token.match rx)[1]
    push_stack @token
    get_token
    count = 1
    while @token.value != end_token do
      push_stack @token
      count += 1
      get_token
    end
    push_stack @token
    count += 1
    environment_list = pop_stack(count)
    node = new_node({type: :environment, env_type: "#{env_type}", value: environment_list})
    push_stack node
  end

  # A text sequence is a sequence words with no in-line math, display
  # math. or macros (control sequences).  A text sequence is a piece
  # of ordinary prose.  The 'text_sequence' method pops nodes off
  # the stack and then pushes a node nto it with content hash
  #
  # type: :text
  # value: a string representing the text sequence
  #
  def text_sequence
    count = 1
    push_stack @token.value
    get_token
    while @token.value != '$' and @token.value[0] != '\\'
      count += 1
      push_stack @token.value
      get_token
    end
    if @token.value == '$' or @token.value[0] == '\\'
      @reader.put_word
    end
    str = pop_stack(count).join(' ')
    node = new_node({type: :text, value: str})
    push_stack node
  end

  # inline_math: pops nodes representing tokens in the body
  # of $ ... $, pushing a node with content
  #
  # type: :inline_math
  # value: the ...
  #
  def inline_math
    get_token
    count = 1
    push_stack @token.value

    while @token.value != '$'
      count += 1
      push_stack @token.value
      get_token
    end
    if @token.value == '$'
      # push_stack @token.value
      get_token
    end
    str = pop_stack(count).join(' ')
    node = new_node({type: :inline_math, value: str})
    push_stack node
  end

  # Like the previous, but for \[ ... \]
  #
  def display_math
    get_token
    count = 1
    push_stack @token.value
    puts @token.value.to_s.magenta
    while @token.value != '\\]'
      puts @token.value.to_s.magenta
      count += 1
      push_stack @token.value
      get_token
    end
    if @token.value == '\\]'
      get_token
    end
    str = pop_stack(count).join(' ')
    node = new_node({type: :display_math, value: str})
    push_stack node
    # display_stack
  end


  # Used by 'macro' to get all of the macro, not just \name
  #
  def paren_count(str)
    left = str.scan /{/
    right = str.scan /}/
    left.count - right.count
  end

  # recognize a macro and push onto the stack the hash
  #
  # type: :macro
  # value : str (e.g. '\foo{one, two}')
  # macro: command_name, e.g., 'foo'
  # args: the list of arguments, e.g., ['one', 'two'] -- could be nil
  #
  def macro
    str = @token.value
    cumulative_parent_count = paren_count(str)
    while cumulative_parent_count != 0 do
      get_token
      value = @token.value
      cumulative_parent_count += paren_count(value)
      str << value
    end
    name_rx =/\\([a-zA-Z].*?){/
    args_rx = /{(.*)}/
    command_name = (str.match name_rx)[1].strip
    arg_str = (str.match args_rx)[1]
    puts "arg_str: #{arg_str}".magenta
    args = arg_str.split(',').map{ |x| x.strip}
    puts "args: #{args}".magenta
    node = new_node({type: :macro, value: str, macro: command_name, args: args})
    push_stack node
  end

  # expr: a switch for the various grammar elements
  def expr
    if @token.value =~ /\A\\begin/
      begin_token = @token.value
      end_token = begin_token.gsub('begin', 'end')
      environment(end_token)
    elsif @token.value == '$'
      inline_math
    elsif @token.value == '\\['
      display_math
    elsif @token.value =~ /\\[a-zA-Z].*/
      macro
    elsif @token.value[0] != '\\'
      text_sequence
    else
      push_stack @token.value
    end
  end

  # body: push one node
  # onto the stack with content
  # a list of elments representing
  # the parsed content between
  # '\begin{document}' and '\end{document}'
  #
  # NOTE: This will eventually be a tree
  def body
    count = 0
    while @token.value != END_DOC
      get_token
      expr
      count += 1
    end
    body_list = pop_stack(count)
    node = new_node({type: :body, value: body_list})
    push_stack node
  end

  # the main method
  def parse
    get_token
    header
    if @token.value == BEGIN_DOC
      get_token
      body
      if @token.value != END_DOC
        error 'missing END_DOC'
      end
    else
      error 'missing BEGIN_DOC'
    end
  end


end
