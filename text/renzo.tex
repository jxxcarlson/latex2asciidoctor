%
% AMS-LaTeX 1.2 sample file for book proceedings, based on amsproc.cls.
%

\documentclass[12pt]{book}%{article}%{amsart}
\setcounter{chapter}{-1}

\usepackage{amsfonts}
\usepackage[T1]{fontenc}
\usepackage{pgothic}

%\usepackage{amsmath,amssymb,amstext,amsthm,amscd,epic,eepic}
%\usepackage{amsmath,amssymb,amstext,amsthm,amscd,mathtools,
%graphicx,float,caption,subcaption,todonotes,tikz,tikz-cd,hyperref}%natbib,
\usepackage{amsmath,amssymb,amstext,amsthm,amscd,
graphicx,float,caption,subcaption,todonotes,tikz,hyperref,xypic, ulem,youngtab}%natbib,


\usetikzlibrary{matrix,arrows,decorations.pathmorphing}

%\usepackage[small,nohug,heads=LaTeX]{diagrams}
%\diagramstyle[labelstyle=\scriptstyle]
%\newarrow {Corresponds} <--->
%\newarrow {Equals} =====
%\newarrow {TTo} ----{->}

%\pagestyle{myheadings}

%\setlength{\textheight}{27pc}
%\oddsidemargin-0.5truecm
%\evensidemargin-0.5truecm
%\textwidth17.5truecm
%\textheight23truecm
%\topmargin-.1truecm

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Theorems

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}

\newtheorem*{theorem2}{Theorem}
\newtheorem*{proposition2}{Proposition}
\newtheorem*{lemma2}{Lemma}

\newtheorem{conjecture}{Conjecture}

\newtheorem*{question}{Question}
\newtheorem*{claim}{Claim}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{examples}[theorem]{Examples}
\newtheorem{exercise}{Exercise}
\newtheorem{remark}[theorem]{Remark}
\newtheorem*{ack}{Acknowledgements}

\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{rems}{Remarks}
\newtheorem*{ex}{Example}
\newtheorem*{exs}{Examples}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%
% Varie

\def\bs{\boldsymbol}
\def\ds{\displaystyle}
\def\pf{{\em Proof.}\ \,}
\def\br{\buildrel}
\def\ov{\overline}
\def\su{\subseteq}
\def\co{\supseteq}
\def\({\left(}
\def\){\right)}
\def\un{\underline}
\def\nt{\noindent}

% Frecce

\def\inc{\hookrightarrow}
\def\to{\rightarrow}
\def\lto{\longrightarrow}
\def\sur{\twoheadrightarrow}

% Greek

\def\om{\omega}
\def\Th{\Theta}

% \mathbb

\def\bA{{\mathbb{A}}}
\def\bC{{\mathbb{C}}}
\def\bE{{\mathbb{E}}}
\def\bF{{\mathbb{F}}}
\def\bH{{\mathbb{H}}}
\def\bK{{\mathbb{K}}}
\def\bN{{\mathbb{N}}}
\def\bP{{\mathbb{P}}}
\def\bQ{{\mathbb{Q}}}
\def\bR{{\mathbb{R}}}
\def\bU{{\mathbb{U}}}
\def\bZ{{\mathbb{Z}}}

% \mathcal

\def\cA{{\mathcal A}}
\def\cB{{\mathcal B}}
\def\BL{{\mathcal BL}}
\def\cC{{\mathcal C}}
\def\cD{{\mathcal D}}
\def\cE{{\mathcal E}}
\def\cExt{{\mathcal E}xt}
\def\cF{{\mathcal F}}
\def\cG{{\mathcal G}}
\def\cH{{\mathcal H}}
\def\cHom{{\mathcal H}om}
\def\cI{{\mathcal I}}
\def\cL{{\mathcal L}}
\def\cM{{\mathcal M}}
\def\cN{{\mathcal N}}
\def\cO{{\mathcal O}}
\def\cP{{\mathcal P}}
\def\cR{{\mathcal R}}
\def\cS{{\mathcal S}}
\def\cT{{\mathcal T}}
\def\cTor{{\mathcal T}or}
\def\cU{{\mathcal U}}
\def\cW{{\mathcal W}}
\def\cZ{{\mathcal Z}}
\def\e{{\textnormal{e}}}
\def\HP{{\textnormal{\large\pgothfamily{H}}}}
\def\hp{{\textnormal{\pgothfamily{H}}}}
\def\ET{{\textnormal{\large\pgothfamily{E}}}}
\def\MM{{\textnormal{\pgothfamily{p}}}}
\def\f{{\textnormal{\pgothfamily{f}}}}
\def\g{{\textnormal{\pgothfamily{g}}}}
%$$
% \widetilde

\def\wt{\widetilde}
\def\tC{{\widetilde{C}}}
\def\tE{{\widetilde{E}}}
\def\tH{{\widetilde{H}}}
\def\tX{{\widetilde{X}}}
\def\tY{{\widetilde{Y}}}
\def\tp{{\widetilde{p}}}
\def\tg{{\widetilde{g}}}
\def\tTh{{\widetilde{\Theta}}}
\def\tcA{{\widetilde{\cA}}}
\def\tcU{{\widetilde{\cU}}}
\def\tPic{{\widetilde{\textrm{Pic}}}}

% \mathfrak

\def\mP{\mathfrak{P}}
\def\mR{\mathfrak{R}}
\def\mU{\mathfrak{U}}

% Math Text

\def\ch{{\textrm{ch}}}
\def\codim{}
\def\coker{{\textrm{coker\,}}}
\def\ecoker{{\emph{coker}\,}}
\def\cone{{\textrm{cone\,}}}
\def\Coh{{\textrm{Coh\,}}}
\def\Ext{{\textrm{Ext\,}}}
\def\eExt{{\emph{Ext}\,}}
\def\Hom{{\textrm{Hom\,}}}
\def\eHom{{\emph{Hom}\,}}
\def\id{{\textrm{id}}}
\def\Im{{\textrm{Im\,}}}
\def\Re{{\textrm{Re\,}}}
\def\rk{{\textrm{rk}}}


\newcommand{\Proj}{{\mathbb P}^1}
\newcommand{\PP}{{\mathbb P}^1 \times {\mathbb P}^1}
\newcommand{\Ptoo}{{\mathbb P}^2}
\newcommand{\PoneC}{{\mathbb P}^1({\mathbb C})}
\newcommand{\PtwoC}{{\mathbb P}^2({\mathbb C})}
\newcommand{\PthreeC}{{\mathbb P}^3({\mathbb C})}
\newcommand{\PnC}{{\mathbb P}^n({\mathbb C})}

\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}

\newcommand{\del}{\partial}
\newcommand{\Aut}{\text{Aut}}


\begin{document}

\title{Counting Maps of Riemann Surfaces: \\ Hurwitz Theory for Undergraduates}

\author{Renzo Cavalieri and Eric Miles}

\date{}

\maketitle



%\todo[inline]{change style back to amsart from article}
%\todo[inline]{what style should this be in? does it matter?}

%\begin{abstract}
%Here we have a book.
%\end{abstract}

\tableofcontents

%\listoftodos


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%
\chapter{Introduction}
\label{introduction}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{From Complex Analysis to Riemann Surfaces}
\label{complexAnalysis}



\begin{theorem}[Open Mapping Theorem]
\label{openMappingThm}
\end{theorem}

\end{document}

\begin{theorem}[Inverse Function Theorem]
\label{inverseFunctionThm}
\end{theorem}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Introduction to Manifolds}
\label{manifolds}

In Chapter \ref{complexAnalysis} we created honest domains for the functions $\log z$ and $z^{1/2}$ by ``gluing together'' copies of $\bC$. Manifolds generalize this construction and capture the idea of a geometric space $A$ being locally indistinguishable from a space $B$, but globally is (or at least, can be) significantly different from $B$.



\section{General Definition of a Manifold}

An illustration to have in mind is how the earth can locally be represented on your flat computer screen in Google Maps, but globally the earth is (SPOILER ALERT!) roughly spherical.

 Suppose you are Google-mapping your neighboorhood with your house at the center of your screen. We think of the map you are looking at as a function
 $$\varphi:(\text{a subset of the earth}) \to (\text{your flat computer screen}).$$
We will call such functions charts.

Now imagine your friend who lives down the street is also viewing a map of your neighborhood, centered at his house. Your friend's screen doesn't look exactly the same as yours, but there is a portion of your neighborhood which is both on yours and your friend's screen.
You may naturally construct a function
$$
\hspace{-1cm}
T:\left(
\begin{array}{c}
\text{the common portion of your}\\
\text{neighborhood on your screen}
\end{array}
\right) \to \left(
\begin{array}{c}
\text{the common portion on your}\\
\text{friend's screen}
\end{array}
\right),
$$ which identifies the points on the two screens that correspond to the same physical location. This is an example of a transition function.

A manifold is essentially a (nice) topological space $X$ equipped with a set of charts which identify subsets of $X$ with subsets of Euclidean spaces, and such that all transition functions are as suitably well-behaved.

\begin{definition}
\label{manifoldDef}
A topological space $X$ is called a {\bf [smooth] manifold} iff the following conditions are satisfied.
\begin{enumerate}
\item $X$ is a Hausdorff topological space.
\item For all $x\in X$ there exists a neighborhood $U_x \subset X$ of $x$ and a homeomorphism $\varphi_x:U_x \to V_x$ where $V_x$ is an open set in [$\bR^n$].
\item For any $U_x,U_y$ such that $U_x \cap U_y \neq \varnothing$ the {\bf transition function}
\[T_{y,x}:\varphi_y \circ \varphi_x^{-1}: \varphi_x(U_x \cap U_y) \to \varphi_y(U_x \cap U_y)
\]
is [smooth].
\end{enumerate}
\end{definition}

Recall that a function $\vec{f}=(f_1,f_2,\ldots,f_n):\bR^m \to \bR^n$ is \textbf{smooth}, i.e. $f \in \cC^\infty$, if each $f_i$ has continuous partial derivatives of all orders. In other words, if all partial derivatives $\del^k f_i/ \del x_{i_1}\del x_{i_2}\cdots \del x_{i_k}$ exist and are continuous.

\begin{remark}
We have placed (purely notational) brackets throughout Definition \ref{manifoldDef} to indicate that there is a class of manifold for many different ``categories'' relating to the real and complex numbers. For instance, one can consider differentiable $\cC^k$-manifolds, or complex analytic manifolds. In the latter case, we have $V_x \subset \bC^n$ and we ask transition functions to be holomorphic. This will be our focus from Chapter \ref{riemannSurfaces} on - however, smooth manifolds lend themselves well to visualization and so are well-suited to an introduction.
\end{remark}


\missingfigure{Figure 19 - Schematic mfld pic with charts and transition function}
\begin{figure}
\label{manifoldFirstPic}
\end{figure}



\begin{definition}
The $n$ in $\bR^n$ (or $\bC^n$ if considering complex analytic manifolds) in part 2 of Definition \ref{manifoldDef} is called the \textbf{dimension} of $X$. The pair $(U_x, \varphi_x)$ is called a \textbf{local chart} for $X$, and the function $\varphi_x$ is called a \textbf{local coordinate function}. A transition function compares different local coordinates for the same points of $X$ and is therefore also called a \textbf{change of coordinates}. A collection $\cA = \{(U_\alpha,\varphi_\alpha)\}_\alpha$ of local charts that covers $X$ and such that all transition functions are [smooth] is called an \textbf{atlas}.
\end{definition}

The same topological space can be given the structure of a manifold in different ways, i.e. can be given different atlases. However, some atlases determine the same manifold structure on the topological space - when this happens we say the two atlases are compatible.

\begin{definition}
Two atlases $\cA=\{(U_\alpha,\varphi_\alpha)\}_\alpha$ and $\cB=\{(U_\beta,\varphi_\beta)\}_\beta$ for a topological space $X$ are called \textbf{compatible} if their union $\cA \cup \cB$ is an atlas for $X$. In other words, if for all $\alpha,\beta$ such that $U_\alpha \cap U_\beta \neq \varnothing$ the transition functions $\varphi_\beta \circ \varphi_\alpha^{-1}$ and $\varphi_\alpha \circ \varphi_\beta^{-1}$ are [smooth].
\end{definition}

\begin{exercise}
Show that compatibility is an equivalence relation on the collection  of atlases for a topological space $X$.
\end{exercise}

An equivalence class of compatible atlases for $X$ is called a [smooth differentiable] {\bf structure} on $X$.




\section{Basic Examples}

The most trivial example of a smooth manifold is
euclidean space itself. In this case $\bR^n$ can be covered by the one chart atlas $(\bR^n, Id)$, and there are no transition functions to worry about. Similarly, any open subset of $\bR^n$ is a smooth manifold.

%\begin{example}
%\label{babyManifolds}
%$\bR^n$ is a smooth manifold using the one-chart atlas $(\bR^n, Id)$. Any open subset of $\bR^n$ is a smooth manifold.
%\end{example}


%We now introduce some simple, but already non-trivial examples.

\begin{example}
\label{circleManifoldEx}
We give the unit circle $S^1=\{(x,y)\in \bR^2 | x^2 + y^2 = 1\}$ with topology induced by $\bR^2$ the structure of a smooth manifold. Note that $S^1$ is Hausdorff since $\bR^2$ is. We define an atlas consisting of four charts with the following domains.
\begin{itemize}
\item $U_x^+ = \{(x,y) \in S^1 | x>0 \}$
\item $U_x^- = \{(x,y) \in S^1 | x<0 \}$
\item $U_y^+ = \{(x,y) \in S^1 | y>0 \}$
\item $U_y^- = \{(x,y) \in S^1 | y<0 \}$
\end{itemize}

We use projection to define our coordinate functions.
\begin{itemize}
\item $\varphi_x^\pm=\pi_y|_{U_x^\pm}:U_x^\pm \to (-1,1) \subset \bR$ sends $(x,y) \mapsto y$
\item $\varphi_y^\pm=\pi_x|_{U_y^\pm}:U_y^\pm \to (-1,1) \subset \bR$ sends $(x,y) \mapsto x$
\end{itemize}
%and similarly $\varphi_x^- = \pi_y|_{U_x^-}$ and $\varphi_y^- = \pi_x|_{U_y^-}$.
Note that $(\varphi_y^+)^{-1}(x) = (x, \sqrt{1-x^2})$ is a continuous function on the interval $(-1,1)$ and hence $\varphi_y^+$ is a homeomorphism. Similarly one can check all other local coordinate functions are homeomorphisms.



\missingfigure{Figure 20 - Circle with the 4 ``half charts''}
\begin{figure}
\label{circleWith4Charts}
\end{figure}



%Let us take for granted that these coordinate functions are homeomorphisms (a proof of this is very similar to the proof given in Section \ref{algebraicCurvesSection} that algebraic curves are Riemann Surfaces) and consider transition functions.\todo[inline]{this is a spot where one could use (or essentiall prove?) that ``locally a graph'' implies a manifold (a la implicit function thm)...}

Consider the intersection $U:=U_x^+ \cap U_y^+ = \{(x,y) \in S^1 | x,y >0\}$;  we have $\varphi_x^+(U) = \varphi_y^+(U) = (0,1)\subset \bR$. The transition function $T_{x^+,y^+}=\varphi_x^+ \circ (\varphi_y^+)^{-1}$ sends $x \in (0,1)$ to
\[
T_{x^+,y^+}:x \stackrel{(\varphi_y^+)^{-1}}{\longmapsto}
(x, \sqrt{1-x^2})
\stackrel{\varphi_x^+}{\longmapsto}
\sqrt{1-x^2}
\]
which is smooth on the domain $(0,1)$. Similar checks show all other transition functions are smooth.
%\begin{exercise}
%Convince yourself that $f(x)=\sqrt{1-x^2}$ is smooth on $(0,1)$. Check three more transition functions for smoothness. (Can you see the pattern? If not, check more!)
%\end{exercise}
Thus our atlas gives $S^1$ the structure of a smooth manifold.
\end{example}

\noindent\hrulefill

\begin{exercise}
Another method to give $S^1$ a manifold structure is by \textbf{stereographic projection}. Define the points $N=(0,1), S=(0,-1)$ and corresponding subsets $U_N=S^1-N, U_S = S^1-S$. Define the chart $\varphi_N:U_N \to \bR$ by $\varphi_N(x_0,y_0)=x_N$ where $x_N$ is the $x$-intercept of the unique line through $N$ and $(x_0,y_0)$ in $\bR^2$. Define $\varphi_S$ by replacing $N$ with $S$.

\begin{enumerate}
\item Find explicit formulas for $\varphi_N(x_0,y_0), \varphi_S(x_0,y_0)$ in terms of $x_0$ and $y_0$.

\item Let $x_N \in \bR$. Show that the $x$-coordinate of $(\varphi_N)^{-1}(x_N)$ is $\frac{2x_N}{x_N^2 + 1}$, and that the $y$-coordinate is the following:
\[
 \left\{
     \begin{array}{lr}
       \sqrt{1-(\frac{2x_N}{x_N^2 + 1})^2} & \text{if } |x_N| \geq 1\\
       -\sqrt{1-(\frac{2x_N}{x_N^2 + 1})^2} & \text{otherwise}
     \end{array}
     \right.
\]

\item Consider the transition function $T_{S,N} = \varphi_S \circ (\varphi_N)^{-1}$.
\begin{enumerate}
\item What is the domain and range of $T_{S,N}$?
\item Compute $T_{S,N}$ in terms of $x_N$. \textit{Hint: there will be two cases.}
\item Convince yourself that $T_{S,N}$ is a smooth function on its domain.
\end{enumerate}

\item Decide to yourself that checking the smoothness of $T_{N,S}$ will follow the check for $T_{S,N}$ very closely, and so it is not necessary to write out explicitly.

\item It turns out that the atlas $\cB$ given here using stereographic projection and the atlas $\cA$ defined in Example \ref{circleManifoldEx} are compatible. Choose a local chart $\varphi_\alpha$ from $\cA$ and a local chart $\varphi_\beta$ from $\cB$ whose domains intersect. Compute $\varphi_\beta \circ \varphi_\alpha^{-1}$ and $\varphi_\alpha \circ \varphi_\beta^{-1}$ and convince yourself that they are smooth functions on their domains. Do this again for another pair of local charts.

\item The two atlases considered for $S^1$ generalize to give atlases for each $S^n, n\geq 1$. For example, for $S^2$ the atlas analogous to $\cA$ has 6 charts and the atlas analogous to $\cB$ still has two charts. Write out the charts for both atlases.
\end{enumerate}
\end{exercise}



\begin{example}
Let the function $f$ map $\cM(m,n,\bR) = \{m \times n$ matrices with real entries$\}$ to $\bR^{mn}$ by fixing once and for all a bijection between the $mn$ positions in a matrix and the coordinates of $\bR^{mn}$ and sending each entry to the corresponding coordinate. For example, we have
\[
f:
 \begin{pmatrix}
  1 & 2 & 3 \\
  4 & 5 & 6
 \end{pmatrix}
 \in \cM(2,3,\bR) \longmapsto (1,2,3,4,5,6)\in \bR^6.
\]
We induce a topology on $\cM(m,n,\bR)$ by \textit{defining} $f$ to be a homeomorphism, i.e. $U \subset \cM(m,n,\bR)$ is open if and only if  $f(U)$ is open in $\bR^{mn}$. Then the one-chart atlas $\{\cM(m,n,\bR), f\}$ gives $\cM(m,n,\bR)$ the structure of a smooth manifold.
\end{example}
\begin{exercise}
Show that any open set of a smooth manifold $X$ is itself a smooth manifold.
\end{exercise}

\begin{example}
The set $GL(n,\bR) = \{M\in\cM(n,n,\bR)| \text{det}(M) \neq 0 \}$ is a smooth manifold since it is an open set of a smooth manifold.
\end{example}



\section{Projective Space}
\label{realProjectiveSpace}

Projective spaces are important  and ``historical" examples of manifolds; even though the current formalization of the theory happened much later, ideas in projective geometry date back to Pappus (290 - 350 AD). Renaissance painters Leon Battista Alberti (1404-1472) and Piero della Francesca (1410-1492) wrote mathematical treatises on projective geometry arising from their studies of perspective drawing. The basic idea is the following: a painter represents three-dimensional world  by projecting it onto a two-dimensional canvas. All points which lie on the same line through the eye of the painter end up at the same point on the canvas (See Figure \ref{visionIllustration}).

%For example, in an idealized model of eye-sight, any points in space lying on the same line through the focal point of your eye will register as a single point in your vision.
Projective spaces capture and formalize this idea mathematically: they are geometric objects whose points are in bijection with lines through the origin (the painter's eye) in an ambient Euclidean space. Natural charts that define a manifold structure are given by all possible canvases that the painter may place in space (away from his/her eye) and project onto. We now carefully define projective space in three stages: first we describe the set of points, then the topology and finally the manifold structure.

%\footnote{Alternatively, $1$-dimensional linear subspaces in an ambient vector space}
\missingfigure{Figure 21 - LHS: eye and 4 pts on a line, RHS: vision rectangle with one pt}
\begin{figure}
\label{visionIllustration}
\end{figure}

%To be a little more down-to-earth, this is saying that you can take your pencil and hold it to your eye so that you only see the closest end.



\begin{definition}[Projective Space: Points]\label{prp}
 The {\bf set of points} of $\bP^{n}(\bR)$ is defined to be naturally in bijection with either of the   following sets:
\begin{enumerate}

\item lines $\ell$ through the origin in $\bR^{n+1}$
\item equivalence classes of $n+1$-tuples of real numbers $(X_0, \ldots, X_n)\not= (0,\ldots, 0) $ such that for any $\lambda \in \bR\smallsetminus \{0\}$,
$$
(X_0, \ldots, X_n) \sim (\lambda X_0, \ldots, \lambda X_n).
$$
\end{enumerate}
\end{definition}

\begin{remark}\label{rem:prp}
For the reader familiar with coordinate-free linear algebra, it is worth pointing out that, given an $n+1$ dimensional $\bR$-vector space $V$, one can define the {\bf projectivization of $V$} (denoted $\bP(V)$), whose points correspond to one-dimensional linear subspaces of $V$.
\end{remark}
\begin{exercise}
Show that the three sets in Definition \ref{prp} and Remark \ref{rem:prp} are naturally in bijection with each other, and therefore anyone of them can be taken as a model for the points of $\bP^{n-1}(\bR)$.
\end{exercise}

We can use $n+1$-tuples of numbers to identify points of $\bP^{n}(\bR)$, much like coordinates in a vector space after choosing a basis. However we require  coordinates for a point to be unique, and this is not the case here. The $n+1$-tuples $(X_0,\ldots, X_n)$ are called {\bf homogeneous coordinates}; given a point  $\ell \in \bP^{n}(\bR)$, we denote  it via the equivalence class of its homogeneous coordinates by the notation
$$
\ell=[X_0: X_1:\ldots :X_n].
$$

\begin{exercise}
Which of the points listed below represent the same point in $\bP^1(\bR)$? How many distinct points of $\bP^1(\bR)$ are listed? $[1:1], [2:-1/2], [0:1], [-1/4:-1/4], [6:-3/2], [-2:-2]$. As a side puzzle:  why is $[0:0]$ not a legitimate homogeneous coordinate for any point in $\bP^1(\bR)$?
\end{exercise}

\begin{definition}[Projective Space: topology]\label{psrt}
We give a topology to $\bP^1(\bR)$ by inducing it as the quotient topology via a surjective function. Consider the natural projection function:
$$
\begin{array}{cccc}
 \pi: & \bR^{n+1} \smallsetminus \{\vec{0}\}& \to &\bP^n(\bR) \\
 & (X_0, X_1,\ldots, X_n) & \mapsto &[X_0: X_1:\ldots :X_n]
\end{array}
$$
A set $U\subseteq \bP^n(\bR)$ is defined to be open if and only if $\pi^{-1}(U)$ is open in $\bR^{n+1} \smallsetminus \{\vec{0}\}$. In other words, we give $\bP^n(\bR)$ the finest topology that makes $\pi$ continuous.
\end{definition}

\begin{exercise}
In Definition \ref{psrt} we realized $\bP^n(\bR)$ as an identification/orbit space: let $\bR^\ast = \bR\smallsetminus \{0\}$ act on $\bR^{n+1}$ by component-wise multiplication: $\lambda \cdot (X_0,X_1,\ldots,X_n) = (\lambda X_0, \lambda X_1, \ldots, \lambda X_N)$. Then
$$ \bP^n(\bR) = \left(\bR^{n+1} \smallsetminus \{\vec{0}\} \right)/ \bR^*.$$
 We now present two alternative models for $\bP^n(\bR)$ as an identification space, and leave it as an exercise that they yield homeomorphic results.
 \begin{description}
    \item[Sphere quotient] Consider the $n$-dimensional unit sphere  $S^{n}\subset \bR^{n+1}$. The multiplicative cyclic group $\mu_2=\{ 1,-1\}$ acts on the sphere by $$\pm 1\cdot (X_0,X_1,\ldots,X_n) = (\pm X_0, \pm X_1, \ldots,  \pm X_N).$$ Then $\bP^n(\bR)$ is the quotient space $S^n/\mu_2$.
    \item[Disk model] Consider the $n$-dimensional closed unit disk  $\overline{D}^{n}\subset \bR^{n}$, and consider the antipodal equivalence relation on the points of its boundary: $\mathbf{x}\sim -\mathbf{x}$ if and only if $||\mathbf{x}||=1$. Then $\bP^n(\bR)$ is the identification space $\overline{D}^{n}/\sim$.


 \end{description}
\end{exercise}
%We will denote an equivalence class $[(x_1,x_2,\ldots,x_n)] \in \bP^{n-1}(\bR)$ by $[x_1:x_2:\cdots:x_n]$ so that if $\lambda \in \bR^*$ we have $[x_1:x_2:\cdots:x_n] = [\lambda x_1:\lambda x_2:\cdots:\lambda x_n] \in \bP^{n-1}(\bR)$.
%\end{definition}
We point out that the sphere quotient and disk model for $\bP^{n}(\bR)$ immediately show that projective space is compact, and make it an  exercise to show it is Haussdorf.


We now give real projective space the structure of a smooth manifold. In order to avoid clouding the ideas with cumbersome notation, we treat explicitly the cases $n=1$ and leave it to the reader to draw the natural generalizations.


%and again there is motivation from perspective: imagine you have an invisible canvas and you want to draw exactly what you see through it. Our local charts comes from choosing canvases and associating to a point on the canvas everything we see behind (and in front of) it.

\missingfigure{Figure 22 - LHS: 3-space, a cone, and a rectangular ``canvas'', RHS: rectangle with ellipse in the middle}
\begin{figure}
\label{canvasChart}
\end{figure}


 We describe explicitly a two-chart atlas defining a smooth manifold structure on $\bP^1(\bR)$.


Inside $\bR^2$ with coordinates $(X,Y)$, identify the line $\{X=1\}$ with $\bR$ by using $y=Y$ as a coordinate. Each non-vertical line intersects the line $\{X=1\}$ at a unique point, and this association determines our coordinate function. Formally, we define
$$U_X = \bP^1(\bR) \smallsetminus \{[0:1]\} = \{[X:Y] \in \bP^1(\bR)| X \neq 0\}$$ and
$\varphi_X:U_X \to \bC $ by
$$\varphi_X([X:Y])=  Y/X=y$$
(note that $X \neq 0$ implies $[X:Y]=[1:Y/X]$).

Similarly, we define a second chart using the line $\{Y=1\}$, i.e.
$$U_Y = \bP^1(\bR) \smallsetminus \{[1:0]\} = \{[X:Y] \in \bP^1(\bR)| Y \neq 0\}$$
and $\varphi_Y:U_Y \to \bC$
$$\varphi_Y([X:Y]) =  X/Y=x.$$

\begin{exercise}
Show that $\varphi_X$ and $\varphi_Y$ are homeomorphisms.
\end{exercise}

We now consider transition functions. We have $U:=U_X \cap U_Y = \{[X:Y] \in \bP^1(\bR)| X,Y \neq 0\}$ and $\varphi_X(U)=\varphi_Y(U) = \bR\smallsetminus\{0\}$. The transition function $T_{y,x} = \varphi_Y \circ (\varphi_X)^{-1}$ sends $y\neq 0$ to
\[
T_{x,y}:y \stackrel{(\varphi_x)^{-1}}{\longmapsto}
[1:y] = [1/y:1]
\stackrel{\varphi_y}{\longmapsto}
1/y
\]
which is smooth on the domain $\bR\smallsetminus\{0\}$. Similarly $T_{x,y}:x \mapsto 1/x$ is smooth, and thus $\bP^1(\bR)$ is a smooth manifold.



\begin{exercise}
Convince yourself that $\bP^1(\bR)$ is homeomorphic to a circle. Since $\bP^1(\bR)$ has dimension 1, it is called the \textbf{projective line}.
\end{exercise}

\begin{remark}
The charts $U_X$ and $U_Y$ are often called {\bf coordinate affine charts} and the functions $x$ and $y$ {\bf affine coordinates}. Since in the case of the projective line any one affine chart is capturing all of the space except one point, it is  common to describe the space with just one affine coordinate, and allowing it to take the value $\infty$ to represent the missing point. Note however that the notion of a point being at infinity depends on the choice of the affine chart that is being used. When using $U_X$ with affine coordinate $y$, then $y=\infty$ corresponds to the point $[0:1]$, whereas for $U_Y$ the point $x=\infty$ is $[1:0]$.
\end{remark}

\begin{exercise}
Our choice of atlas for $\bP^1(\bR)$ is somewhat arbitrary (at least mathematically). Show that any choice of two non-parallel lines {not} through the origin  gives an atlas compatible with our choice.
\end{exercise}

\begin{exercise}
Show that the following three charts form an atlas for the \textbf{real projective plane}, $\bP^2(\bR)$:
\begin{eqnarray}
U_X=\{X \neq 0\}, & &\varphi_X([X:Y:Z])=  (Y/X,Z/X)\\
U_Y=\{Y \neq 0\}, & &\varphi_Y([X:Y:Z])=  (X/Y,Z/Y)\\
U_Z=\{Z \neq 0\}, & &\varphi_Z([X:Y:Z])=  (X/Z,Y/Z)
\end{eqnarray}
Generalize this construction to show that $\bP^n(\bR)$ is a smooth manifold for any positive integer $n$.
%is a smooth manifold by constructing an atlas and checking smoothness of transition functions on their domains. \textit{Hint: Now you're considering lines through the origin in $\bR^3$. Use as ``canvases'' the} planes \textit{$\{x=1\}, \{y=1\}$, and $\{z=1\}$.}
\end{exercise}

%One can similarly show that the projective spaces $\bP^n(\bR)$  are smooth manifolds for all $n \geq 1$.
Giving the structure of a complex analytic manifold to the complex projective spaces $\bP^n(\bC)$ might seem trickier, as one has to consider complex lines through the origin in $\bC^{n+1}$, but the construction of the local charts and checks of transition functions follows completely in analogy to the real case.

%\begin{exercise}
%Show that the complex projective line, $\bP^1(\bC)$, is a complex analytic manifold by constructing an atlas and checking that transition functions are holomorphic on their domains.
%\end{exercise}
%{\color{red} I am thinking about removing this exercise since we do this in Chapter $3$. Maybe put an exercise on projective space as compactifying affine?
%}


%\begin{theorem}[Implicit Function Theorem]
%\label{implicitFunctionTheorem}
%\end{theorem}

\section{Manifolds as level sets}

A natural way to construct interesting manifolds as subsets of euclidean space is by considering level sets of functions. Given the function $f(x,y)= x^2+y^2$, the unit circle can be thought of as the level set $f^{-1}(1)$;
in Example \ref{circleManifoldEx} we showed that the circle is a manifold.

Let us now consider instead the function $g(x,y)= xy$. The level set $g^{-1}(1)$ is a smooth hyperbola, which you may check is a one-dimensional smooth manifold. But the level set $g^{-1}(0)$ consists of the union of the $x$ and $y$ axes, which cannot be given the structure of a smooth manifold: no neighborhood of the origin can be homeomorphic to an open set in $\bR$.

The answer to which level sets are well behaved
lies in this classical theorem from analysis.

\begin{theorem}[The Implicit Function Theorem]\label{thm:ift}
Let $F: \bR^n \to \bR^m$ be a smooth function, and $\mathbf{x} \in \bR^n$ such that the differential $dF(\mathbf{x})$ is a surjective linear function. Say $F(\mathbf{x})=\mathbf{a}$. Then there exist:
\begin{itemize}
\item $V_{\mathbf{x}}\subseteq \bR^n$, an open neighborhood of $\mathbf{x}$,
\item $U_\mathbf{x}\subseteq \bR^{n-m}$ an open set,
\item $f_\mathbf{x}: U_\mathbf{x} \to \bR^m$ a smooth function
\end{itemize}
such that
$$
F^{-1}(\mathbf{a})\cap V_{\mathbf{x}} = \Gamma_f,
$$
where $\Gamma_f$ denotes the graph of $f$.
\end{theorem}
\missingfigure{Figure on implicit function theorem}
\begin{figure}
\label{fig:ift}
\end{figure}

\begin{proof} The geometric idea for the proof of this theorem is illustrated in Figure \ref{fig:ift}, which we invite the reader to refer to throughout the proof; to do things honestly we must alas use coordinates - let us bite the bullet and do it.

Let $F=(F_1(x_1, \ldots, x_n), \ldots, F_m(x_1, \ldots, x_n))$, and consider the $ m\times n$ martix of partial derivatives:
$$
J=
\left[
\begin{array}{ccc}
\frac{\partial F_1}{\partial x_1}(\mathbf{x}) & \ldots &\frac{\partial F_1}{\partial x_n}(\mathbf{x})\\
\vdots &  \ddots & \vdots \\
\frac{\partial F_m}{\partial x_1}(\mathbf{x}) & \ldots &\frac{\partial F_m}{\partial x_n}(\mathbf{x})
\end{array}
\right]
$$
The differential $dF(\mathbf{x})$  is the linear function represented by the matrix $J$, and therefore it is surjective if and only if  $n\geq m$ and $J$ has maximal rank $m$. We assume without loss of generality that the rightmost $m\times m$ minor of $J$ has non-zero determinant.

We now consider an auxiliary function $\hat{F}: \bR^n \to \bR^n$, specifically constructed so that it extends $F$ and  it satisfies the hypotheses of the Inverse Function Theorem (\ref{}):
$$
\hat{F}(x_1, \ldots, x_n)= (x_1, x_2, \ldots, x_{n-m}, F_1(x_1, \ldots, x_n), \ldots, F_m(x_1, \ldots, x_n)).
$$

The differential $d\hat{F}(\mathbf{x})$ is represented by the square matrix
$$
\hat{J}=
\left[
\begin{array}{c}
\begin{array}{ccc|ccc}
 & & & & & \\
& Id&  &  &0&\\
 & & & & &
%1 &0 & \ldots &
%\frac{\partial F_1}{\partial x_1}(\mathbf{x}) & \ldots &\frac{\partial F_1}{\partial x_n}(\mathbf{x})\\
%\vdots &  \ddots & \vdots \\
%\frac{\partial F_m}{\partial x_1}(\mathbf{x}) & \ldots &\frac{\partial F_m}{\partial x_n}(\mathbf{x})
\end{array}

\\
\hline
 \\
J
\end{array}
\right],
$$
which has determinant equal to the last $m\times m$ minor of $J$, non-zero by assumption.

By the inverse function theorem, there exist  neighborhoods $V_{\mathbf{x}}$ of $\mathbf{x}$ and $W_{\hat{F}(\mathbf{x})}$ of $\hat{F}(\mathbf{x})$ such that smooth local inverse function $\hat{F}^{-1}: W_{\hat{F}(\mathbf{x})}\to U_{\mathbf{x}} $ is defined.


Let $\pi_{n-m}: \bR^{n} \to \bR^{n-m}$ be the linear projection on the first $n-m$ coordinates. and $\pi_{m}: \bR^{n} \to \bR^{m}$ the projection on the last $m$ coordinates.
We define
 $$U_\mathbf{x}= \pi_{n-m}\left(W_{\hat{F}(\mathbf{x})} \cap \{x_{n-m+1}=a_1\}\ldots \cap \{x_{n}=a_m\}\right).$$

We finally define:
$
f_\mathbf{x}: U_\mathbf{x} \to \bR^m
$
by
$$
f_\mathbf{x}(x_1, \ldots, x_{n-m})= \pi_m(\hat{F}^{-1} (x_1, \ldots, x_{n-m},a_1, \ldots, a_m)).
$$
Out of exhaustion after all this hard work, we leave it to the reader to check that $V_{\mathbf{x}}, U_{\mathbf{x}}$ and $f_\mathbf{x}$ verify the statement of the theorem.
\end{proof}

Behind the technical smokescreen, what the Implicit Function Theorem says is actually very natural: if at a point $\mathbf{x}\in \bR^n$ there are $m$ coordinates such that the determinant of the matrix of the corresponding partial derivatives is non-zero, then locally around $\mathbf{x}$ you may choose the complementary $n-m$ coordinates to be local coordinates for the level set of $F$ through $\mathbf{x}$. The natural projection to these coordinates gives a local chart for the level set around $\mathbf{x}$. With this in mind, the following result should seem very natural.

\begin{definition}
Let $F: \bR^n \to \bR^m$ be a smooth function. A point $\mathbf{a} \in \bR^m$ is called a {\bf regular value} for $F$, if for every $\mathbf{x}\in \bR^n$ such that $F(\mathbf{x})= \mathbf{a}$, the differential $dF(\mathbf{x})$ is a surjective linear function.
\end{definition}

\begin{theorem}
Let $F: \bR^n \to \bR^m$ be a smooth function, and $\mathbf{a} \in \bR^m$ a regular value for $F$. Then $F^{-1}(\mathbf{a})$ is a smooth manifold.
\end{theorem}
\begin{proof}
We begin by noting that $F^{-1}(\mathbf{a})$ is Haussdorf since it is a subset of $\bR^n$ with the induced subset topology.

Since $\mathbf{a}$ is a regular value for $F$, for any $\mathbf{x}$ in the level set of $\mathbf{a}$, Theorem \ref{thm:ift} applies: the pair $(U_\mathbf{x}, \pi_{n-m})$ gives a local chart for $F^{-1}(\mathbf{a})$ around $\mathbf{x}$.

Now assume $\mathbf{x}$ and $\mathbf{x'}$ are in the level set of $\mathbf{a}$ and $V_{\mathbf{x}}\cap V_{\mathbf{x'}}\cap F^{-1}(\mathbf{a})\not =  \varnothing$. Then the transition function $T_{\mathbf{x},\mathbf{x'}}= \varphi_{\mathbf{x}}\circ \varphi_{\mathbf{x'}}^{-1}= \pi_{n-m}\circ f_{\mathbf{x'}}$ (restricted to the appropriate domain of definition) is a composition of smooth functions and hence it is smooth.
\end{proof}
\begin{exercise}
Consider the function $F: \bR^3 \to \bR$ defined by:
$$
F(x,y,z)=    \left(2 - \sqrt{x^2 + y^2}\right)^2 + z^2.
    $$
    Show that $1$ is a regular value for $F$ and hence $F^{-1}(1)$ is a smooth manifold. It is in fact a familiar surface -  try to recognize it.
\end{exercise}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Riemann Surfaces}
\label{riemannSurfaces}



In Chapter \ref{complexAnalysis} we saw that studying maximal domains of definition for complex analytic functions naturally led us to look at geometric spaces which are locally indistinguishable from $\bC$, but globally are different from  $\bC$. In Chapter \ref{manifolds} we saw that the notion of manifolds formalizes the idea of  ``spaces formed by gluing together euclidean spaces by identifying open sets''. We now revisit
 the complex spaces studied in Chapter \ref{complexAnalysis} as a particular class of manifolds, called Riemann Surfaces. The name is given after the
 mathematician Bernhard Riemann (18xx-18xx) who pioneered this point of view.



%\section{Definition of a Riemann Surface%There are two main ways to view a Riemann Surface. Here we define them as manifolds, but an equivalent definition is given in GIVEREF.

\begin{definition}
\label{riemannSurfaceDefinition}
A \textbf{Riemann Surface} is a complex analytic manifold of dimension 1.
\end{definition}

 In a few more words, ``$X$ is a Riemann Surface'' means:

\begin{enumerate}
\item $X$ is a Hausdorff topological space.
\label{hausdorffCondition}

\item For all $x \in X$ there is a homeomorphism $\varphi_x:U_x \to V_x$, where $U_x$ is an open neighborhood of $x \in X$ and $V_x$ is an open set in $\bC$.
\label{localCharts}


\item For any $U_x,U_y$ such that $U_x \cap U_y \neq \varnothing$ the transition function
$$T_{y,x}:=  \varphi_y \circ \varphi_x^{-1}:\varphi_x(U_x \cap U_y) \to \varphi_y(U_x \cap U_y)$$
is holomorphic.
\label{transitionFunctions}
\end{enumerate}

\begin{remark}
Definition \ref{riemannSurfaceDefinition} does not imply that a Riemann Surface must be connected. However, unless otherwise stated, we assume that all Riemann Surfaces considered are connected.
\end{remark}

\missingfigure{Figure 1 - donut $X$ with two coordinate charts intersecting}
\begin{figure}
\label{riemannSurfaceManifoldPic}
\end{figure}


%The pair $(U_x, \varphi_x)$ is called a \textbf{local chart}, and the function $\varphi_x$ is called a \textbf{local coordinate function}. A transition function compares different local coordinates for the same points of $X$ and is therefore also called \textbf{change of coordinates}. A collection of local charts that cover $X$ is called an \textbf{atlas}.

Topologically a Riemann Surface is an {\bf orientable surface}. We saw in \ref{} that a holomorphic function preserves orientation when thought of as a differentiable function from the (real) plane to itself. Since all transition functions are holomorphic, any atlas is a {\bf positive atlas}.

%The \textbf{transition function} $T_{y,x}$ is just going backwards using one local coordinate function and forwards using the other, i.e. $T_{y,x} = \varphi_y \circ \varphi_x^{-1}$ restricted to the domain $\varphi_x(U_x \cap U_y)$.

The remainder of the chapter is dedicated to providing several examples of Riemann Surfaces. We begin by revisiting the examples seen in Chapter \ref{} and several simple examples coming from complex analysis. We then move to  compact Riemann Surfaces, which are the main characters of this book.




\section{Examples of Riemann Surfaces}
\subsection{The Riemann Surface of the Square Root}

In Chapter \ref{complexAnalysis}, to create an honest domain for the function $z^{1/2}$ we altered the topology of two copies of $\bC \smallsetminus 0$, that we denoted $X^+$ and $X^-$: the resulting (Hausdorff) topological space $X$ can and should be thought as having cut  and re-glued the two punctured complex planes along the positive real numbers  (see \ref{}  for details). We show that $X$ is a Riemann Surface by exhibiting an atlas with four local charts: we begin by defining the inverse functions to the charts.

%\begin{exercise}
%{\color{green} Revisit \ref{} to remind yourself of the explicit construction of the topological space $X$.} Prove that $X$ is  Hausdorff.
%\end{exercise}

Define $V_1=V_3:=\bC\smallsetminus \bR^{\geq 0}$, $V_2=V_4:=\bC\smallsetminus \bR^{\leq 0}$ , and consider the four injective functions $\iota_i:V_i \to X$:
\missingfigure{Four planes gluing to ramified  double cover}
\begin{figure}
\label{fig:doublecover}
\end{figure}

\begin{eqnarray}
	\iota_1(z_1) & = & z_1 \in X^+, \nonumber\\
	\iota_2(z_2) & = & \left\{\begin{array}{ll}z_2 \in X^+  & \Re(z) \leq 0\\ z_2 \in X^-  & \Re(z) > 0 \end{array}\right., \nonumber\\
\iota_3(z_3) & = & z_3 \in X^-, \nonumber\\
\iota_4(z_4) & = & \left\{\begin{array}{ll}z_4 \in X^-  & \Re(z) \leq 0\\ z_4 \in X^+  & \Re(z) >0 \end{array}\right..
\end{eqnarray}


Call $U_i$ the image  $\iota_i(V_i)$, and  $\varphi_i: U_i\to V_i$ the inverse function of $\iota_i$.

\begin{exercise}
Prove that the sets $U_i$ are open sets in $X$. Show that the collection $\{U_i\}_{i=1, \ldots, 4}$ covers $X$, and that the functions $\varphi_i$ are homeomorphisms.
\end{exercise}


%Let $- \{z\in\bC | \Im z > 0, \Re z =0 \}$, and let $U_2=U_4:=\bC - \{z\in\bC | \Im z < 0, \Re z =0 \}$. These sets have topologies induced from $\bC$. We now define open sets $U^L_i,U^R_i \subset U_i$ which we identify to form the topological space $X$ (the $L$ and $R$ stand for ``left'' and ``right''). Let $U^L_1 := \{z \in U_1 | \Re z < 0 \}$ and $U^R_1 := \{z \in U_1 | \Re z > 0 \}$. Similarly, define $U^L_i$ and $U^R_i$ for $i=2,3,4$. Figure \ref{creatingRSForSquareRoot} is what we have so far - note that the figure includes the gluing maps which are introduced directly afterward.

%\missingfigure{Figure 2 - the 4 open sets of $\bC$ with gluing maps}
%\begin{figure}
%\label{creatingRSForSquareRoot}
%\caption{$X$ as an identification space}
%\end{figure}

%Define the map $r_{21}:U^R_1 \to U^R_2$ by $r_{21}(z)=z$. Similarly, define the map $l_{32}:U^L_2 \to U^L_3$ by $l_{32}(z)=z$. Continuing this pattern, we define the maps $r_{43}$ and $l_{14}$. We now define $X$ topologically as the identification space
%\[
%X:= \bigsqcup_{l,r} U_i
%\]
%The above expression is short-hand and is meant to include $i=1,2,3,4$ and each of the $l$ and $r$ maps (e.g. $l_{21}$) defined above. The idea is that we have glued the set $U^R_1$ to the set $U^R_2$ in the simplest possible way, and we have similarly glued the other sets.

%\begin{exercise}
%Prove that the sets $[U_i] := \{ [z] \in X | z \in U_i \}$ are open sets in $X$. Show that the collection $\{[U_i]\}_i$ covers $X$.
%\end{exercise}




%Since we have our topological space, we now discuss local charts. For $i=1,2,3,4$ define the local coordinate function $\varphi_i:[U_i] \to \bC$ by $\varphi_i([z])=z$.

%\begin{exercise}
%\label{localChartsForSquareRoot}
%Show that $\varphi_2$ is well-defined. Show that $\varphi_2$ is a homeomorphism onto its image in $\bC$.
%\end{exercise}

%Since the open sets $[U_i]$ cover $X$, Exercise \ref{localChartsForSquareRoot} shows that point \ref{localCharts} above is satisfied.

It remains to show that the transition functions are holomorphic. We consider one transition function - all other checks are analogous.

The intersection $U_1 \cap U_2$ consists of all points in $X^+$ whose imaginary part is positive.
The transition function $T_{21}: \varphi_1(U_1 \cap U_2) = \{z \in V_1|\Im z > 0\} \to \varphi_2(U_1 \cap U_2) = \{z \in V_2|\Im z > 0\}$  maps $z_1 \mapsto -z_1$ and thus gives the change of coordinates $z_2=-z_1$ which is holomorphic. This completes the proof that $X$ is a Riemann Surface.


\begin{exercise}
Exhibit the domains for $z^{\frac{1}{n}}$ and $\log z$ as Riemann Surfaces. Maybe put remark and reference Miranda \end{exercise}



\todo[inline]{Perhaps we should mention that one way to give a Riemann Surface is to give the charts with transition functions? (i.e. and have the topology be induced from this setup) That would save some writing later on...}


\subsection{Graphs of complex functions $f(z)$}


\label{graphsAreRSExample}
A class of examples of Riemann Surfaces are given by graphs of continuous complex functions. Let $f(z)$ be a continuous function mapping $\bC$ to $\bC$. The graph of $f$ is the set $\Gamma_f:=\{(z,f(z)) | z \in \bC \} \subset \bC\times \bC$ given the subspace topology. In Figure \ref{schematicGraph} we visualize all the relevant maps.



\missingfigure{Figure 3 - a schematic picture of a graph of $f(z)$}
\begin{figure}[h]
$$
\xymatrix{
\Gamma_f \ar[r]^i \ar@/^/[dr]^{\varphi} &  \bC\times\bC \ar[r]^{\pi_2} \ar[d]^{\pi_1}  & \bC \\
& \bC \ar@/^/[ul]^{\varphi^{-1}=Id \times f} \ar[ur]_f
}
$$
\label{schematicGraph}
\caption{It'd be nice to have side to side the diagram and a pictorial depiction of it.}
\end{figure}

First we note that $\Gamma_f$ is Hausdorff since $\bC\times\bC$ is. The graph of $f$ is  naturally given the structure of a Riemann Surface by an atlas with one chart, namely all of $\Gamma_f$; the local coordinate function is the first projection map $\varphi:=\pi_1|_{\Gamma_f}$ which sends $(z,f(z))$ to $z$.
To define a  Riemann Surface structure $\varphi$ must be a homeomorphism onto its image (which is all of $\bC$).
The map $\varphi=\pi \circ i$ is the composition of $i$, the natural inclusion of $\Gamma_f$ into $\bC\times\bC$, and $\pi_1$, the projection onto the first factor. Both $i$ and $\pi_1$ are continuous maps, and thus so is $\varphi$.

To show that $\varphi^{-1}$ is continuous, we observe that $\varphi^{-1}= Id \times f:\bC\to \bC\times \bC$. Since the identity function and $f$ are both continuous functions, it follows that their product is continuous.




%\begin{comment}
%In the other direction, we must show that $\varphi^{-1}$ is continuous. This is equivalent to showing that $\varphi$ is an open map, i.e. that if $U$ is open in $\Gamma_f$, then $\varphi(U)$ is open. (If you don't see why these are equivalent, take a minute and check it!) By the definition of the subspace topology we have $U=V \cap \Gamma_f$ where $V$ is an open set in $\bC \times \bC$. Since a basis for the topology of $\bC \times \bC$ is given by the sets of the form $B_{\epsilon'}(x) \times B_{\epsilon''}(y)$, for our proof we may assume that $V$ has this form, i.e. we may assume that
%\[
%U=\left( B_{\epsilon'}(x) \times B_{\epsilon''}(y) \right) \cap \Gamma_f
%\]
%In other words, if we can show that the image via $\varphi$ of this specific $U$ is open, it will imply that $\varphi$ is an open map. Now, to show that $\varphi(U)$ is open, we take a point $z_0 \in \varphi(U)$ and find a neighborhood $z_0 \in U_{z_0}\subset \varphi(U)$.

%If $U=\varnothing$ then $\varphi(U)=\varnothing$ which is open, so we are done. Suppose now that $(z_0, f(z_0) \in U$. Then $z_0 \in B_{\epsilon'}(x)$ and $f(z_0) \in B_{\epsilon''}(y)$.

%\begin{exercise}
%Complete this proof by finding a neighborhood $U_{z_0}\subset \bC$ such that $\varphi^{-1}(U_{z_0}) \subset U$. Note that this implies that $U_{z_0} \subset \varphi(U)$. \textit{Hint: $f$ continuous at $z_0$ means that for any $\epsilon$, there is a $\delta$ such that $z \in B_\delta(z_0)$ implies that $f(z) \in B_\epsilon(f(z_0))$}.
%\end{exercise}
%\end{comment}
 Given that there is only one chart, the holomprphicity of transition functions is trivially satisfied. Thus $\Gamma_f$ is a Riemann Surface. Once we discuss maps (and in particular, isomorphisms) of Riemann Surfaces, we will see that all graphs are isomorphic to the Riemann Surface $X=\bC$ (Exercise \ref{graphsAreC}).



\subsection{Algebraic Curves}
\label{algebraicCurvesSection}
The complex analysis version of the Implicit Function Theorem (Theorem \ref{thm:ift}) implies that the inverse image of a regular value for an analytic function is a complex manifold. In particular, if $f:\bC^{n+1} \to \bC^n$ is a holomorphic function such that ${0}\in\bC^n$ is a regular value for $f$, then $f^{-1}(0)$ is a complex analytic manifold of dimension 1, i.e. a Riemann Surface.



%\noindent\hrulefill
%The next example is actually a particular case of Example \ref{regularValueExample}. However, it is both important and down-to-earth, so we take the time to discuss it.
When the holomorphic function $f= (f_1, \ldots, f_n)$ is given by a collection of $n$ polynomials in $n+1$ variables, the Riemann Surfaces arising as inverse images of regular values are also called {\bf affine algebraic curves}. We study in detail the plane curve case, i.e. when $n=1$. For an analogy, recall that over the real numbers, the set $\{x^2+y^2-1=0\}$ is the unit circle: it lives in $\bR^2$, and is a manifold of real dimension 1.

\begin{definition}
For any $p(x,y)\in\bC[x,y]$, the set $V(p):=\{(x,y)|p(x,y)=0\}\subset \bC^2$ is called an {\bf affine plane curve} . We say that $V(p)$ is \textbf{smooth} if there is no $(x_0,y_0)\in V(p)$ such that $\frac{\del p}{\del x}(x_0,y_0) =0 = \frac{\del p}{\del y}(x_0,y_0)$. \end{definition}

We now give a sketch of a proof that a smooth affine plane curve is a Riemann Surface.
The idea is that if $V(p)$ is smooth, then locally it can be seen as a graph, and these local expressions patch together well. To be precise, let $(x_0,y_0)\in V(p)$. Since $V(p)$ is smooth, at least one of $\frac{\del p}{\del x}, \frac{\del p}{\del y}$ is non-zero at $(x_0,y_0)$. Say that $\frac{\del p}{\del y}(x_0,y_0)\neq 0$. By the Implicit Function Theorem  there is a neighborhood $U_{(x_0,y_0)} \subset \bC^2$, a neighborhood $V_{x_0}\subset\bC$, and a holomorphic function $f(x):V_{x_0} \to \bC$ such that $V(p) \cap U_{(x_0,y_0)} = \{(x,f(x))|x\in V_{x_0}\}$, the graph of $f$.

We  get a local chart on $V(p)$ around $(x_0,y_0)$ as in Section \ref{graphsAreRSExample}, by setting  $\varphi_{(x_0,y_0)}:V(p) \cap U_{(x_0,y_0)} \to V_{x_0}$ to be projection to the first factor: $\varphi_{(x_0,y_0)}(x,f(x)) = x$.
%From Exercise \ref{graphsAreRSExample} we know that $\varphi_{(x_0,y_0)}$  is a homeomorphism. Note that  $\varphi_{(x_0,y_0)}$ is just $\pi_x$ (projection onto the $x$ coordinate) with a restricted domain.

Finally we show that transition functions are holomorphic. Assume $U_{(x_0,y_0)}\cap U_{(x_1,y_1)} \cap V(p) \not= \varnothing$. If $\varphi_{(x_0,y_0)}$ and $\varphi_{(x_1,y_1)}$ are both projections to the same axis, the transition function $\varphi_{(x_1,y_1)}\circ\varphi^{-1}_{(x_0,y_0)}$ is just the identity function restricted to the appropriate domain in $\bC$ . Assume now that $\varphi_{(x_0,y_0)}$ is projection onto the $x$-axis and that $\varphi_{(x_1,y_1)}$ is projection on the $y$-axis. Then the set $U_{(x_0,y_0)}\cap U_{(x_1,y_1)} \cap V(p)$ is simultaneously on the graph of a holomorphic function $f_0(x)$  and of a holomorphic function $f_1(y)$. The transitions functions are then $\varphi_{(x_1,y_1)}\circ\varphi^{-1}_{(x_0,y_0)}= f_0(x)$ and $\varphi_{(x_0,y_0)}\circ\varphi^{-1}_{(x_1,y_1)}= f_1(y)$ restricted to appropriate domains, which are holomorphic.
\begin{exercise}
Spell out the details of the above argument that a smooth affine plane curve is a Riemann Surface.
\end{exercise}



\missingfigure{Figure 4 - A schematic picture of a curve in the plane}
\begin{figure}
\label{schematicCurve}
\end{figure}


\section{Compact Riemann Surfaces}

We now turn our attention to compact Riemann surfaces, which are the heroes of our story. Compactness is a strong constraint on the geometry of surfaces, and it is responsible for some of the rich structure of the theory of analytic functions among Riemann Surfaces.

From a topological point of view, a compact Riemann surface $X$ is a compact orientable surface. By the classification of compact surfaces theorem (See Appendix \ref{classificationOfSurfaces}), it must be homeomorphic to the connected sum of $g$ tori. The integer $g$ is called the {\bf genus} of $X$: it can be thought as the number of ``handles" that are attached to a sphere to obtain $X$.

 We now consider some examples of compact Riemann Surfaces. We start from the Complex Projective Line, or Riemann Sphere, which is the unique example of a Riemann Surface of genus $0$ (See \ref{}).\todo[inline]{right now this isn't proved anywhere in the book, I think}

%something about them being nice
%So far the examples of Riemann Surfaces we have all been non-compact. If your Riemann Surface happens to be compact, you can say a lot about it, and some very useful theorems apply only in this context, e.g. the Riemann-Hurwitz Formula (Theorem MAKEREF). We consider two examples of compact Riemann Surfaces beginning with the complex projective line, $\PoneC$.

\subsection{Complex Projective Line}
\label{complexProjectiveLine}
In Chapter \ref{manifolds} we introduced $\bP^1(\bR)$ as a manifold whose points parameterize  lines through the origin $\bR^2$. Similarly, $\PoneC$
is a manifold whose points parameterize complex one dimensional linear subspaces of $\bC^2$.
The construction is analogous to Section \ref{realProjectiveSpace}, so  here we take a more topological approach and present $\PoneC$ as a Riemann Surface by gluing together two copies of $\bC$.

Let $U_1=U_2:=\bC$ and define $g:U_1-\{0\} \to U_2-\{0\}$ by $g(z) = 1/z$. We define $\PoneC$  as the identification space
\[
\PoneC:= U_1 \bigsqcup_{g} U_2
\]
{\it The idea is to have two copies of $\bC$ standing side-by-side.  Then, holding both $0$'s still, fold the copies towards each other, identifying each non-zero point to a point on the other copy.}

\begin{exercise}
\label{topologyOfP1C}
Show that, as a set, $\PoneC$ is $\bC$ plus a point.
Prove that $\PoneC$ is a Hausdorff topological space. Prove that $\PoneC$ is the one point compactification of $\bC$, and it is therefore homeomorphic to a sphere. In complex analysis, it is called the {\bf Riemann Sphere}.
\end{exercise}


 For $i=1,2$, we denote by $[U_i]$ the image of the set $U_i$ after the identification by $g$: note that $[U_i]$ is an open set in $\PoneC$. Define the local coordinate functions $\varphi_i: [U_i] \to U_i$  by $\varphi_i(p)=z_i$, where $z_i$ is the complex number in $U_i$ such that  $[z_i]=p$.  Both $\varphi_1$ and $\varphi_2$ are homeomorphisms.

We now consider transition functions - specifically, we consider $T_{21}$. The intersection $[U_1]\cap[U_2]=[U_1-\{0\}]=[U_2-\{0\}]$ and $\varphi_1([U_1]\cap[U_2])=\bC-\{0\}$. This is the  domain of $T_{21}=\varphi_2 \circ \varphi_1^{-1}$ and for $z_1\neq0$ we have
\[
z_1 \stackrel{\varphi_1^{-1}}{\longmapsto}
[z_1] = [z_2 = g(z_1) = 1/{z_1}]
\stackrel{\varphi_2}{\longmapsto}
z_2=1/z_1
\]
Since $T_{21}$ has a pole only at $z_1=0$, it is holomorphic on $\bC-\{0\}$. A  symmetric computation shows that $T_{12}$ is holomorphic, and we have that $\PoneC$ is a Riemann Surface. Since $\PoneC$ is homeomorphic to a sphere, its genus is $0$.

\begin{exercise}
Here is an alternative way of showing that $\PoneC$ is a compact space. Consider a three dimensional real sphere $S^3\subset \bC^2$, as the locus of points that are distant $1$ from the origin.
Given any point $p\in S^3$, there is a unique complex line $\ell_p$  through the origin and $p$.  We therefore get a function:
$$
\begin{array}{cccc}
H: &S^3 & \to     & \PoneC \\
   & p  & \mapsto & \ell_p
   \end{array}
$$
Check that $H$ is a continuous and surjective function. Since $S^3$ is compact (closed and bounded) and the continuous image of a compact set is compact, this proves that $\PoneC$ is compact.

Check that for any point $\ell_p\in \PoneC$, the inverse image $H^{-1}(\ell_p)$ is a circle.
The map $H$, which realizes the three dimensional sphere as a circle fibration over a two dimensional sphere, is famously known as the {\bf Hopf fibration}.


\end{exercise}



\begin{exercise}
One can take  $U_1$ and $U_2$ as before and glue them together using $\tilde{g}:U_1-\{0\} \to U_2-\{0\}$ where $\tilde{g}(z)=z$. Show that the resulting topological space, $X=U_1 \sqcup_{\tilde{g}} U_2$, is not Hausdorff (and thus is \textit{not} a Riemann Surface!). It is often called the {\bf complex plane with doubled-origin}.
\end{exercise}

\subsection{Complex Tori}


{\bf Complex tori} are examples of compact Riemann Surfaces  of genus $1$. In fact, any compact Riemann Surface of genus $1$ is isomorphic to a complex torus (see Appendix \ref{}).

%In our discussion, we sacrifice generality to make the example as explicit as possible.
\begin{definition}
 Let $z_1$ and $z_2$ be two complex numbers which are linearly independent over $\bR$ (i.e. they don't lie on the same real line through $0$ in $\bC$). The set of all integral linear combinations of $\tau_1$ and $\tau_2$
 $$
  \Lambda = \{n\tau_1+m\tau_2 | n,m \in \bZ\} \subset \bC$$ is called a {\bf lattice} of complex numbers.

\end{definition}
\todo[inline]{in morphisms of RS section put exercise along the lines that multiplication of a lattice by complex number ields an iso of complex tori}
We will see in Section \ref{} that we may assume that $\tau_1=1$ and $\Im(\tau_2)>0$, so we make the simplifying assumption that a lattice has the form $\Lambda = \{n+m\tau | n,m \in \bZ, \tau \in \mathbb{H}\} \subset \bC$.  Here $\bH$ is the upper half-plane $\bH=\{z \in \bC | \Im(z)>0\}$.


Consider the quotient space $T=\bC/\Lambda$, i.e. the identification space $T=\bC/\sim$ where $z_1 \sim z_2$ iff $z_2 = z_1 + w$ for some $w\in\Lambda$. The natural projection map $\pi:\bC \to T$ given by $\pi(z)=[z]$  induces a natural quotient topology on $T$, i.e. $V\subset T$ is open in $T$ if and only if $\pi^{-1}(V)$ is open in $\bC$.

\begin{exercise}
\label{fundamentalRegion}
Denote by $P$ the closed parallelogram with vertices $0, 1,  \tau,  1 + \tau$.
Show that for any $z\in\bC$ there is a $z'\in P$ with $z \sim z'$.  This shows that $\pi|_P:P \to T$ is onto, and hence we can restrict our attention to $P$ in order to understand the geometry of $T$.
\end{exercise}

By considering the residual identification of points  in $P$ (defined in Exercise \ref{fundamentalRegion}) we see that $T$ is topologically a torus. If $z$ is in $P$ but is not on the boundary, then $z$ is not equivalent to any other point of $P$.
%\nsim z'$ for any $z'\neq z$ in $P$.
If $z$ is on the the line segment through $0$ and $\tau$, then $z \sim z+1\in P$. Also, if $z$ is on the line segment through $0$ and $1$, then $z \sim z+\tau \in P$.

%talk about the identification polygon
The topology of $T$ is described by the identification polygon  in Figure \ref{identPolygonForTorus}.

\missingfigure{Figure 5 - The torus' ident. polygon and a torus, both with ``circles'' drawn}
\begin{figure}
\label{identPolygonForTorus}
\end{figure}

{\it
You can think of the identification as telling you how to fold and glue an elastic piece of paper. Here the instructions are to take $P$, fold the top and bottom edges together and glue them so that you have a tube, then bring the circular edges of the tube together and glue them.}


\begin{exercise}
\label{piIsOpen}
Prove that $\pi$ is an open map, i.e. that $V$ open in $\bC$ implies that $\pi(V)$ is open in $T$.
\end{exercise}

We now endow $T$ with a complex structure. Exercise \ref{piIsOpen} shows that if $\pi$ restricted to a subset $V\subset\bC$ is one-to-one, then it is a homeomorphism onto its image in $T$. In this case $(\pi|_V)^{-1}$ is also a homeomorphism from the image of $\pi|_V$ to  $V$, and we may use $(\pi|_V)^{-1}$ as a chart of $T$.




\begin{exercise}
\label{boundForToriCharts}
Find a real number $r$ (depending on $\tau$) such that, for any $z\in \bC$,  $\pi$ restricted to $B_r(z)$, a ball of radius r centered  at $z$,  is a one-to-one map.
%Prove that your $b$ works! \textit{Hint: What can be said about $z_1,z_2\in B_\epsilon(z)$  if $\pi(z_1) = \pi(z_2)$?}
\end{exercise}

Given $r$ as in Exercise \ref{boundForToriCharts} and $z\in \bC$, define $$U_{z}:=\pi(B_r(z))\subset T \ \ \ \  \mbox{and}  \ \ \ \ \varphi_z:=(\pi|_{B_r(z)})^{-1}.$$

We claim that the collection:
$$
\mathcal{A}= \{ \left(U_z, \varphi_z \right) | z\in \bC\}
$$
forms an atlas for $T$. Now $\mathcal{A}$ certainly gives a (highly redundant) cover of $T$ by open sets, and we have arranged for the maps $\varphi_z$'s to be homeomorphisms onto their images.
Assume that $U_{z_1} \cap U_{z_2} \not=\varnothing$; for $i=1,2$, denote by $(\alpha_i, \beta_i)$ the unique pair of real numbers such that $z_i= \alpha_i + \beta_i \tau$.  We have that
$$T_{21}(z) =\varphi_{z_2} \circ \varphi_{z_1}^{-1}(z) = z+ k, $$
where $k= \left(\lfloor \alpha_2\rfloor-\lfloor\alpha_1\rfloor\right)+ \left(\lfloor \beta_2\rfloor-\lfloor\beta_1\rfloor\right)\tau$ is just a constant depending on $z_1$ and $z_2$. Therefore the transition function $T_{21}$ is holomorphic. This proves that $\mathcal{A}$ is an atlas and therefore $T$ is a Riemann Surface.

%To form our atlas, we only consider sets $V=B_\epsilon(z)\subset \bC$.
%Assuming we have found a $b$ in Exercise \ref{boundForToriCharts}, then for each $B_\epsilon(z)=:B$ with $\epsilon<b$ we have a chart $\varphi_{z,\epsilon}:=\pi|_B^{-1}:\text{image}(\pi|_B) \to B$. We now consider transition functions.

%To aid our discussion we introduce the notation $I(z,\epsilon):= \text{image}(\pi|_{B_\epsilon(z)})$. Note that for a chosen $I(z,\epsilon)$ we have infinitely many charts: If $w\in\Lambda$ then $I(z,\epsilon)=I(z+w,\epsilon)$ and so we have a chart $\varphi_{z+w,\epsilon}$ for each $w\in\Lambda$.

%\missingfigure{Figure 6 - $\bC$ with a grid, and a torus with a few charts for an $I(z,\epsilon)$}
\begin{figure}
\label{chartsForTorus}
\end{figure}


%\begin{exercise}
%Suppose that $I(z,\epsilon) \cap I(z',\epsilon') \neq \varnothing$. Choose a chart $\varphi_{z+w,\epsilon}$ for $I(z,\epsilon)$ and a chart $\varphi_{z'+w',\epsilon}$ for $I(z',\epsilon)$. Find the associated transition function and show that it is holomorphic. \textit{Hint: Draw a picture!}
%\end{exercise}

%We have shown that the complex torus $T$ is a Riemann Surface.



%\todo[inline]{include exercise where they find the $b$ (from Exercise \ref{boundForToriCharts}) for a general $\Lambda = \{n\mu+m\tau\}$?}

\subsection{Projective Curves}


In section \ref{algebraicCurvesSection} we constructed Riemann Surfaces in the complex plane as level sets for a regular value of a polynomial function. In a similar fashion we wish to construct compact Riemann Surfaces as closed subsets of the  complex projective plane $\PtwoC$. The first obstacle arises from the fact that polynomials in the homogeneous coordinates of the projective plane do not define functions on $\PtwoC$.

\begin{example}
Consider the polynomial $p(x,y,z)= x^2 +y +z+1$. Note that $$p(1,1,1)=4\not= 7=p(2,2,2).$$ Since $[1:1:1]= [2:2:2]$ are the same point in $\PtwoC$, $p$ is attempting to assign two different outputs to the same input, violating the definition of a function.
\end{example}
Geometrically, the coordinates of any point belonging to a complex line $\ell$ through the origin in $\bC^3$ can be choosen to represent the point corresponding to $\ell$ in $\PtwoC$; hence for a polynomial in three variables to give a well defined function on $\PtwoC$ one would need the polynomial to remain constant along lines through the origin. Alas, the only polynomials that satisfy such condition are globally constant polynomials, which don't make for particularly exciting functions...

Recall however that in defining an affine plane curve we only care about points where the polynomial vanishes. We therefore now seek polynomials in three variables that vanish along lines through the origin in $\bC^3$. Luckily there is a large collection of such polynomials, giving us a rich set of examples of compact Riemann Surfaces.

\begin{definition}\label{homog}
    A polynomial $P\in \bC[X,Y,Z]$ is said to be {\bf homogeneous of degree $d$} if any of the following equivalent conditions is satisfied:
    \begin{enumerate}
        \item Every monomial of $P$ has degree $d$
    \item For every $t\in \bC$, $$P(tX,tY,tZ)= t^d P(X,Y,Z)$$
    \item $$X\frac{\partial P}{\partial X}+Y\frac{\partial P}{\partial Y}+Z\frac{\partial P}{\partial Z}=d P  $$
    (here $dP$  denotes the number $d$ times the polynomial $P$).
    \end{enumerate}

\end{definition}
\begin{exercise}
Show that conditions $1$, $2$  and $3$ in definition \ref{homog} are indeed equivalent. Condition $3$ is sometimes called {\bf Euler's Identity}.
\end{exercise}

\begin{exercise}
If $P\in \bC[X,Y,Z]$ is a homogeneous polynomial, then the set of points $[X:Y:Z]\in \PtwoC$ where $P$ vanishes is well-defined. We call this set the {\bf vanishing locus} of $P$.
%\todo[color=green!40]{I never know if I should put a dash between ``well'' and ``defined'' - I think I generally put it in - it doesn't really matter, but we should pick one, eh?} %{\color{green} We call this set $V(P)$ - see Definition \ref{pralgc}.}
\end{exercise}


\begin{definition}\label{pralgc}
Given $P\in \bC[X,Y,Z]$ a homogeneous polynomial of degree $d$, the set
$$
V(P):=\{[X:Y:Z]\in \PtwoC | P(X,Y,Z)=0\}
$$
is called a {\bf plane projective curve}  of degree $d$. If
$$
\left\{(X,Y,Z) \in \bC^3 | \frac{\partial P}{\partial X}=\frac{\partial P}{\partial Y}=\frac{\partial P}{\partial Z}=0\right\}\subseteq \{(0,0,0)\}
$$
then $V(P)$ is said to be {\bf smooth}.
\end{definition}
\begin{exercise}
Show that $V(P)$ is smooth if and only if there is no point of  $\PtwoC $ where $P$ and any two of its partial derivatives vanish simultaneously.
\end{exercise}

\begin{proposition}
A smooth projective plane curve $V(P)$ is a compact Riemann Surface.
\end{proposition}
\begin{proof}
We first show that $V(P)$ is compact by showing that $V(P)$ is a closed set in $\PtwoC$, which is a compact topological space. Consider the diagram

$$
\xymatrix{
  \hspace{-2cm} \bC^3\smallsetminus \{(0,0,0)\} \ar[d]_\pi \ar[r]^{P} & \bC \\  \PtwoC},$$

 where $\pi$ is the natural projection function and $P$ is the (continuous) function defined by the homogeneous polynomial $P$ (i.e. $P:(X,Y,Z) \mapsto P(X,Y,Z)$). By definition, $V(P)$ is a closed subset of $\PtwoC$ if $\pi^{-1}(V(P))$ is closed in $\bC^3\smallsetminus (0,0,0)$. But $$\pi^{-1}(V(P))=P^{-1}(0)$$ is the inverse image of the closed set $\{0\}\subset \bC$, therefore it is closed.

 We prove that $V(P)$ is a Riemann Surface by showing that its intersection with any of the coordinate open sets of $\PtwoC$ is a Riemann Surface (See Proposition \ref{} - \todo[inline]{In mfld chapter put a proposition along the lines of a submanifold of a manifold can be checked chart by chart}). Consider (without loss of generality) the chart $$U_Z=\{[X:Y:Z]| Z\not=0\}\subseteq \PtwoC$$ with affine coordinates $$ (x,y)= \varphi_Z(X,Y,Z)=(X/Z,Y/Z).$$
The set $\varphi_Z(V(P)\cap U_Z)$ is equal to $V(p)$, where $p(x,y):= P(x,y,1)$ is called the dehomogenization of $P$ with respect to $Z$.  For any $({x},{y})\in \bC^2$
\begin{equation} \label{parx}
\frac{\partial p}{\partial x} ({x},{y})=\frac{\partial P}{\partial X} ({x},{y},1)
\end{equation}

\begin{equation}\label{pary}
\frac{\partial p}{\partial y} ({x},{y})=\frac{\partial P}{\partial Y} ({x},{y},1).
\end{equation}


We claim that there can be no $(\tilde{x}, \tilde{y})\in \bC^2$ such that
\begin{equation}\label{sys}
p(\tilde{x}, \tilde{y})=\frac{\partial p}{\partial x} (\tilde{x},\tilde{y})=\frac{\partial p}{\partial y} (\tilde{x},\tilde{y})=0.
\end{equation}

The claim implies that $V(p)$ is a smooth affine plane curve and therefore a Riemann Surface as in Section \ref{algebraicCurvesSection}. Since the restriction of $V(P)$ with any affine chart is a Riemann Surface, so is $V(P)$.

To prove the claim, assume there is $(\tilde{x}, \tilde{y})\in \bC^2$ satisfying the system of equations in \eqref{sys}. By \eqref{parx}, \eqref{pary}, and the smoothness of $V(P)$, it must be that
$$
\frac{\partial P}{\partial Z} (\tilde{x},\tilde{y},1)\not= 0.
$$
But now Euler's Identity gives us a contradiction, since

$$
0\not= \frac{\partial P}{\partial X} (\tilde{x},\tilde{y},1)+\frac{\partial P}{\partial Y} (\tilde{x},\tilde{y},1)+\frac{\partial P}{\partial Z} (\tilde{x},\tilde{y},1) = dP (\tilde{x},\tilde{y},1)= 0.
$$
\end{proof}
\begin{example}[Conics]
Consider the homogeneous polynomial
$$
P(X,Y,Z)=X^2+Y^2-Z^2.
$$
We check that $V(P)$ is a smooth projective plane curve of degree $2$, also known as a {\bf conic}. Indeed,
$$
\frac{\partial P}{\partial X}=2X,  \ \ \ \
\frac{\partial P}{\partial Y}=2Y, \ \ \ \
\frac{\partial P}{\partial Z} =-2Z
$$
and $(0,0,0)$ is the only point where all partial derivatives vanish simultaneously.

We observe that if we dehomogenize $P$ with respect to $Z$ (by defining $x=X/Z$, $y=Y/Z$) we recognize the equation of a circle, whereas if we dehomogenize with respect to $X$ or $Y$ we obtain the equation of a hyperbola. This has to do with the fact that affine plane conics are obtained as plane sections of a cone - but in projective space the cone {\bf IS} the conic and slicing it with different planes just amounts to restricting the curve to different affine charts.
We will see in Section \ref{} that smooth conics are isomorphic to $\PoneC$, and are therefore Riemann Surfaces of genus $0$.
\end{example}


\missingfigure{Cone}
%\caption{Conics are sections of a cone!}
%\label{fig:conic section}}

\begin{exercise}
Consider an arbitrary homogeneous polynomial $P \in \bC[X,Y,Z]$ of degree $2$. What are the conditions on the coefficients of $P$ for $V(P)$ to be a smooth conic? When these conditions are not met, $V(P)$ is called a {\bf degenerate conic}. Show that there are two distinct types of degenerate conic.

\end{exercise}

\begin{exercise}
Recall from linear algebra that a homogeneous polynomial $P\in \bC[X,Y,Z]$ of degree $2$ naturally defines a quadratic form which can be represented in a unique way by a $3\times 3$ symmetric matrix $A_P$. What linear algebraic conditions on $A_P$ correspond to $V(P)$ being a smooth conic or  each of the two types of degenerate conics?
\end{exercise}

\begin{exercise}\label{projectivity}
A {\bf projectivity} is a map $\varphi: \PtwoC\to \PtwoC$ defined by $\varphi([X:Y:Z])= [p_1: p_2:p_3]$, where the $p_i$'s are linear homogeneous polynomials in $X,Y,Z$ (it can be thought as a ``change of coordinates" in the projective plane). Two subsets of $\PtwoC$ are called {\bf projectively equivalent} if there exists a projectivity that sends one to the other.
Show that any two smooth complex conics are projectively equivalent.
\end{exercise}

\begin{example}[Elliptic Curves]

Consider a polynomial $P$ of the form:
$$
P(X,Y,Z)= Y^2Z-(X-\alpha_1Z)(X-\alpha_2Z)(X-\alpha_3Z),
$$
where $\alpha_1, \alpha_2, \alpha_3$ are three distinct complex numbers. Note that the partial derivative with respect to $Y$ is $\partial P/\partial Y=2YZ$, which is zero only if $Z=0$ or $Y=0$. We show that $V(P)$ is a smooth projective curve by considering the cases $Z=0, Y=0$ and finding in each case a non-vanishing partial derivative.

\noindent{\bf Case 1:} If $Z=0$, then the only point
in $\PtwoC$ belonging to $V(P)$ is $[0:1:0]$. But we have
$$
  \frac{\partial P}{\partial Z} = Y^2 + Q(X,Z),
     %\begin{array}{l}
      % Y^2-((-\alpha_1)(X-\alpha_2Z)(X-\alpha_3Z) \\
      %  + (X-\alpha_1Z)(-\alpha_2)(X-\alpha_3Z) \\
      %  + (X-\alpha_1Z)(X-\alpha_2Z)(-\alpha_3))
    % $\end{array}
$$
where $Q(X,Z)$ is a homogeneous degree $2$ polynomial in $X$ and $Z$ - and so $\partial P/\partial Z(0,1,0) = 1 \neq 0$.

%\noindent{\bf Case 2:} If $Y=0$, then the points belonging to $V(P)$ are $[\alpha_1:0:1], [\alpha_2:0:1]$, and  $[\alpha_3:0:1]$. We have
%$$
%\frac{\partial P}{\partial X} = -((X-\alpha_2Z)(X-\alpha_3Z) + %(X-\alpha_1Z)(X-\alpha_3Z) + (X-\alpha_1Z)(X-\alpha_2Z))
%$$
%and hence for $i=1,2,3$ we have $\partial P/\partial X(\alpha_i,0,1) \neq 0$ since the $\alpha_i$'s are distinct. Thus $V(P)$ is a smooth projective curve of degree $3$, also known as an {\bf elliptic curve}.

%Let us first look at the partial derivative with respect to $Y$:
%$$
%\frac{\partial P}{\partial Y}=2YZ
%$$
%\noindent{\bf Case 1:} If $Z=0$, then the only point
%in $\PtwoC$ belonging to $V(P)$ is $[0:1:0]$.But then
%$$
%\frac{\partial P}{\partial Z}(0,1,0)\not= 0.
%$$
\noindent{\bf Case 2:} If $Y=0$, then the points belonging to $V(P)$ are $[\alpha_1:0:1], [\alpha_2:0:1]$, and $[\alpha_3:0:1]$. For $i=1,2,3$
$$
\frac{\partial P}{\partial X}(\alpha_i,0,1)\not= 0
$$
follows from the facts that the $\alpha_i$'s are distinct.
This proves that $V(P)$ is a smooth projective curve of degree $3$, also known as an {\bf elliptic curve}.



Elliptic curves are Riemann Surfaces of genus $1$. The connection between elliptic curves and complex tori is a very beautiful and classical story which we sketch in Apprendix\ref{}.
\end{example}

One can generalize  the notion of $V(P)$ to that of a {\bf projective algebraic variety}: a subset of $\mathbb{P}^n(\mathbb{C})$ defined by the simultaneous vanishing of a collection of homogeneous polynomials. A projective algebraic variety of complex dimension one is called a {\bf projective curve}, and when it is smooth it is a compact Riemann Surface.

Generically, one needs $n-1$ homogeneous polynomials in $n+1$ variables to cut out a one dimensional set in $\mathbb{P}^n(\mathbb{C})$ (we make this precise in Exercise \ref{projcurv}); however, there exist projective curves that cannot be ``cut out" by the ``right'' number of equations; we see the first example in Exercise \ref{twcub}.

\begin{exercise}\label{projcurv} Let $P_1, \ldots, P_{n-1}$ be homogeneous polynomials in $n+1$ variables, and define
$$
V(\mathbf{P})=\{[X_0:\ldots:X_n]| P_1(X_0, \ldots, X_n)=\dots=P_{n-1}(X_0, \ldots, X_n)=0\} \subset \mathbb{P}^n(\mathbb{C})
$$
Show that if for every point  $\mathbf{X}\in V(\mathbf{P})$, the matrix of partial derivatives
$$
\left[
\begin{array}{ccc}
\frac{\partial P_1}{\partial X_0}(\mathbf{X}) & \ldots & \frac{\partial P_1}{\partial X_n}(\mathbf{X})\\
\vdots & \ldots & \vdots\\
\frac{\partial P_{n-1}}{\partial X_0}(\mathbf{X}) & \ldots & \frac{\partial P_{n-1}}{\partial X_n}(\mathbf{X})\\
\end{array}
\right]
$$
has maximal rank $n-1$, then by the Implicit Function Theorem $V(P)$ is a compact Riemann Surface.
\end{exercise}

\begin{exercise}\label{twcub}
Consider the function
$$
\varphi: \PoneC \to \PthreeC
$$
defined in homogeneous coordinates by
$$
\varphi([S:T])= [S^3:S^2T:ST^2:T^3].
$$
You may check, or just believe for now, that $\varphi$ is a map of complex manifolds and that the image of $\varphi$ is isomorphic to $\PoneC$. We call the image of $\varphi$ the {\bf twisted cubic} in $\PthreeC$.

Denoting $[X:Y:Z:W]$ the homogeneous coordinates of $\PthreeC$, consider the polynomials
\begin{eqnarray}
P_1 &=& XW-YZ\\
P_2 &=& XZ-Y^2\\
P_3 &=& YW-Z^2.
\end{eqnarray}
Show that the vanishing locus of $P_1, P_2$ and $P_3$ is precisely the twisted cubic, but that the vanishing locus of any two of the three polynomials is strictly larger. The twisted cubic is the first example of a projective curve which is not a {\bf complete intersection}, i.e. which is not cut out by the ``right" number of equations.
\end{exercise}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Maps of Riemann Surfaces}

In mathematics, perhaps even more important than having interesting objects or spaces to work with, is having maps that relate them. We also want these maps to relate their domain and target objects in a meaningful way, making use of whatever structure we have at our disposal. In this chapter, we define the maps of interest between Riemann Surfaces and give a number of examples.

\section{Holomorphic maps of Riemann Surfaces}

%Since Riemann Surfaces are complex analytic manifolds, maps of Riemann Surfaces are simply maps of such manifolds - we call such a map a holomorphic map of Riemann Surfaces.
Because Riemann surfaces are locally identified with $\bC$, we require morphisms of Riemann Surfaces locally to be holomorphic maps from $\bC$ to $\bC$; as a consequence,  many results from complex analysis in one variable carry over to the setting of Riemann Surfaces (see Section MAKEREF).



\begin{definition}
\label{holomorphicMapsOfRS}
Let $X,Y$ be Riemann Surfaces and $f:X \to Y$ a set function.
\begin{enumerate}
\item We say that $f$ is \textbf{holomorphic at} $x\in X$ if for every choice of charts $\varphi_x, \varphi_{f(x)}$ the function $\varphi_{f(x)} \circ f \circ \varphi_x^{-1}$ is holomorphic at $x$.

\item If $U\subset X$ is open, we say that $f$ is \textbf{holomorphic on }$U$ if $f$ is holomorphic at each $x\in U$.

\item If $f$ is holomorphic on $U=X$ we say that $f$ is a \textbf{holomorphic map}.
\end{enumerate}
\end{definition}


\missingfigure{Figure 7- a schematic picture of a map of RS's with local expression}
\begin{figure}
\label{schematicMapOfRS}
\end{figure}

The function $F = \varphi_{f(x)} \circ f \circ \varphi_x^{-1}$ is called a \textbf{local expression} for $f$. From Definition \ref{holomorphicMapsOfRS} it would seem that in order to show a function $f$ is a holomorphic map, one must check the local expression for all possible combinations of local charts. However, the Exercise \ref{oneLocalExpressionSuffices} shows that if suffices to find one local expression that works.

\begin{exercise}
\label{oneLocalExpressionSuffices}
Show that a map of Riemann Surfaces $f:X \to Y$ is holomorphic at $x\in X$ iff there is \textit{a} choice of charts $\varphi_x, \varphi_{f(x)}$ such that $\varphi_{f(x)} \circ f \circ \varphi_x^{-1}$ is holomorphic at $x$.
%Write and prove the corresponding statement for a map $f$ being holomorphic on an open $U\subset X$.
\end{exercise}
We begin with some trivial examples that we pose as exercises.
\begin{exercise}
Let $X,Y$ be Riemann Surfaces and choose a point $y_0\in Y$. Define the constant map $c:X \to Y$ by $c(x) = y_0$ for all $x \in X$. Show that $c$ is a holomorphic map.
\end{exercise}


\begin{exercise}
Let $X$ be a Riemann Surface. Define the \textbf{identity map} on $X$ as the function $I_X:X \to X$ such that $I_X(x)=x$ for all $x\in X$. Prove that $I_X$ is a holomorphic map.
\end{exercise}

Now for a more interesting example of a holomorphic function.

\begin{figure}[tb]
\centering
$$
\xymatrix{
(U_1, z) \ar[rrr]^{F:\ z\mapsto w=z^2} \ar[dr]^{\varphi_1^{-1}} \ar[dd]_{T_{21}:z\mapsto \tilde{z}=\frac{1}{z}} & & & (U_1, w) \ar[dl]_{\varphi_1^{-1}} \ar[dd]^{T_{21}:w\mapsto \tilde{w}=\frac{1}{w}}\\
&\PoneC \ar[r]^f & \PoneC &\\
(U_2, \tilde{z}) \ar[ur]_{\varphi_2^{-1}} \ar[rrr]_{\tilde{F}:\ \tilde{z}\mapsto \tilde{w}=\tilde{z}^2}  & & & (U_2, \tilde{w}) \ar[ul]^{\varphi_2^{-1}}
}
$$
\caption{We check that the map $f$ is holomorphic by checking that two local expression, corresponding to charts that cover $\PoneC$, are holomorphic. Note that in our diagram we depict the inverses to the local coordinate functions, since the coordinate functions are only defined on open subsets of $\PoneC$.}
\label{fig:holomap}
\end{figure}


\begin{example}
\label{xSquaredOnP1C}
 Refer to Figure \ref{fig:holomap} to keep track of how all ingredients of this proof fit together. Recall from Exercise \ref{topologyOfP1C} that, as a set, $\PoneC = \bC$ plus a point. Identifying $\bC$ with the image of the first affine chart $\varphi_1([U_1])$, the  additional point corresponds to the image of $0$ in the second affine chart $U_2$. We denote this point by $\infty$ and thus have $\PoneC = \bC \cup \{\infty\}$.
Using this identification, define the function $f:\PoneC \to \PoneC$ by $z \mapsto w=z^2$ and $\infty \mapsto \infty$. We show that $f$ is a holomorphic map.

We observe the way we described the set function $f$ is by giving a local expression for it, using the chart $U_1$ for both the source and target $\PoneC$. We denoted by $z$ the corresponding local coordinate on the source and by $w$ the local coordinate on the target to avoid confusion. Then since $w=F(z)=z^2$ is a holomorphic function on all of $\PoneC$, $f$ is holomorphic on the image of $U_1$.



%To aid in our discussion, call the domain projective line $A$ and the target projective line $B$, i.e. $f:A \to B$ where $A=B=\PoneC$. Since we have identified $\bC=\varphi_1([U_1])\subset \PoneC$, then the local expression of $f$ using the coordinates given by $\varphi_1$ on $A$ and $\varphi_1$ on $B$ is $z \mapsto z^2$. Since $z \mapsto z^2$ is holomorphic for all $z\in\bC$, the map $f$ is holomorphic for all $[z] \in [U_1]$ (to conclude this, we used Exercise \ref{oneLocalExpressionSuffices}).

All that is left to consider is whether $f$ is holomorphic at $\infty$. We consider the local expression for $f$ using the charts $U_2$ whose image contains $\infty$. We denote by $\tilde{z}= 1/z$ the corresponding local coordinate for the source, and $\tilde{w}= 1/w$ the coordinate on the target.

The local expression $\tilde{F}$ for $f$ in these coordinates is obtained on the intersection of the charts by composing $F(z)$ with the transition functions for the local coordinates:

$$\tilde{F}(\tilde{z})= \tilde{w}= \frac{1}{w} = \frac{1}{z^2} = \tilde{z}^2. $$

Since the point $\infty$ corresponds to $\tilde{z}=\tilde{w}=0$, and we have $f(\infty)= \infty$ and $\tilde{F}(0)=(0)$, the local expression $\tilde{F}$ extends on the whole chart, and is in particular a holomorphic function at the point $0$. This means that $f$ is holomorphic at $\infty$ and completes the proof that $f$ is a holomorphic function on all of $\PoneC$.

%for $\infty \in A$ and $f(\infty)=\infty \in B$. Since $\infty = [0]$ for $0\in U_2$, we use the charts given by $\varphi_2$ for $A$ and $\varphi_2$ for $B$.

%Let $0 \neq z\in\varphi_2([U_2])$. To see where $z$ is sent via $f$ in the coordinates chosen on $B$, we must first associate $z$ to a $w$ for some $w\in \varphi_1([U_1])$. Then we may apply the rule for $f$ given at the beginning of this example. The image, $w^2$, is in the $\varphi_1$ coordinates for $B$, and so me must finally transition to $\varphi_2$ coordinates. We carry out this process below.
%\[
%0 \neq z \stackrel{T_{12}}{\longmapsto}
%1/z
%\stackrel{f}{\longmapsto}
%(1/z)^2 = 1/{z^2}
%\stackrel{T_{21}}{\longmapsto}
%1/(1/{z^2}) = z^2
%\]
%Since $\infty=0$ in $\varphi_2$ coordinates, the local expression of $f$ using $\varphi_2$ coordinates for both $A$ and $B$ is (also) $z \mapsto z^2$. This is holomorphic at $0$, and hence $f$ is a holomorphic map.
\end{example}




\noindent\hrulefill

\begin{exercise}
\label{polynomialMapsOfPoneC}
Choose $a,b,c \in \bC$ and consider the polynomial $p(z) = (z-a)(z-b)(z-c)$.  Prove that the function $f: \PoneC \to \PoneC$ given by $z \mapsto p(z)$ and $\infty \mapsto \infty$ is a holomorphic map, where we again identify $\PoneC = \bC \cup \{\infty\}$ as in Example \ref{xSquaredOnP1C}.
\end{exercise}

\begin{exercise}
Consider an arbitrary rational function
$$
f(z) = \frac{p(z)}{q(z)},
$$
for $p(z), q(z) \in \bC[z]$ two polynomials with distinct roots. You may extend it to a function from $\PoneC$ to $\PoneC$ by defining:
\begin{itemize}
\item $f(\alpha)=\infty$, for $\alpha$ any root of $q(z)$.
\item $f(\infty)= \lim_{z\to \infty} p(z)/q(z)$.
\end{itemize}
Prove that $f$ is a holomorphic function on  of $\PoneC$.
\end{exercise}



\begin{definition}
\label{isomorphicRS}
Two Riemann Surfaces $X,Y$ are called \textbf{isomorphic} (or \textbf{bi-holomorphic}) if there are holomorphic maps $f:X \to Y$ and $g:Y \to X$ such that $g \circ f = I_X$ and $f \circ g = I_Y$. In this case, we write $X \cong Y$ and call $f$ and $g$ \textbf{isomorphisms} (or\textbf{ bi-holomorphisms}).
An isomorphism $h:X \to X$ from a Riemann Surface to itself is called an \textbf{automorphism} of $X$.
\end{definition}

\begin{exercise}
Let $X,Y$ be Riemann Surfaces. Show that $X \cong Y$ (from Definition \ref{isomorphicRS}) iff there is a holomorphic map $f:X \to Y$ that is one-to-one and onto, and such that $f^{-1}$ is holomorphic.
\end{exercise}

\begin{exercise}
\label{graphsAreC}
Let $f:\bC \to \bC$ be a holomorphic function and $\Gamma_f \subset \bC^2$ its graph (as defined in Example \ref{graphsAreRSExample}). Show that $\Gamma_f \cong \bC$.
\end{exercise}

\begin{exercise}
In Exercise \ref{projectivity} you proved that any two smooth conics in $\PtwoC$ are projectively equivalent; show that this implies that they are isomorphic as Riemann Surfaces.

Prove that any smooth conic is isomorphic to $\PoneC$ by choosing a particular conic for which it is simple to exhibit an explicit isomorphims with the projective line.
\end{exercise}

\section{Structure of Maps}
\label{structureOfMaps}

An important feature of  holomorphic maps of Riemann Surfaces is that they have many different local expressions near a point $x\in X$, depending on the choice of charts and local coordinates around $x$ and $f(x)$; given a local coordinate function $\varphi_x$,  post-composing with any bi-holomorphism $h$ of $\bC$ results in a new local coordinate function. For example, choosing $h:z \mapsto e^{(\pi/4)i}z$  rotates the coordinates by $45$ degrees, or choosing $h: z \mapsto z+(2+i)$ results in translated coordinates.


%When considering what a holomorphic map of Riemann Surfaces $f:X \to Y$ looks like ``near'' an $x \in X$, we may choose whatever charts around $x$ and $f(x)$ that we like. And we have many to choose from: given a local coordinate function $\varphi_x$, we can post-compose with any bi-holomorphism $h$ of $\bC$ to obtain a new local coordinate function $h \circ \varphi_x$. For example, choosing $h:z \mapsto e^{(\pi/4)i}z$ would rotate the old coordinates by $45$ degrees, or choosing $h: z \mapsto z+(2+i)$ will give translated coordinates.

In fact, the map $h$ doesn't need to be bi-holomorphic on all of $\bC$ - as long as it is bi-holomorphic ``near'' the point $\varphi_x(x)$, you can use $h \circ \varphi_x$ to get new coordinates around $x$.


For any holomorphic map $f$, there exist choices of local coordinates such that the local expression of $f$ around a given $x\in X$ is very simple - specifically, it is $z \mapsto z^k$ for some uniquely determined $k\geq 1$. This fact has remarkably deep implications  in the theory of functions of Riemann Surfaces, which we explore in this chapter.


%We first describe why this is the case, then state a number of consequences and carry out examples.

\subsection{Local Expression as $z^k$}

Our desired charts will use branches of $k^\text{th}$-root functions, so we discuss these first.

Let $k \geq 1$ be an integer and consider the function $f:\bC \to \bC$ defined by $f(z)=z^k$. If we give the target $\bC$ coordinates $w$ we may write $f$ as $w=z^k$. (This is in complete analogy with writing the real-valued function $p(x) = x^+1$ as $y=x^2+1$.)

Recall from the Inverse Function Theorem (Theorem \ref{inverseFunctionThm}) that for any $z_0$ such that $f'(z_0) \neq 0$, there is a local inverse function around $f(z_0)=z_0^k=:w_0$. Now $f'(z)=kz^{k-1}$, so the Inverse Function Theorem gives information for $z\neq 0$.

Note that $z \neq 0$ implies $z^k=w \neq 0$ and for any $w_0 \neq 0$ there is a $z_0$ with $z_0^k=w_0$ (in fact, there are $k$ such $k^\text{th}$-roots of $z_0$!). Thus, what the Inverse Function Theorem tells us in our situation is that for any $w_0 \neq 0$ and $z_0$ such that $z_0^k=w_0$ there is a holomorphic function $f_{z_0}^{-1}$ defined in a neighborhood $U$ of $w_0$ such that $f_{z_0}^{-1}(w_0) = z_0$ and $f \circ f_{z_0}^{-1}(w) = w$ for all $w\in U$. This is described as choosing a branch of the $k^\text{th}$-root function $z=w^{1/k}$ near $w_0$.

\missingfigure{Figure 8 - Domain and Range of $w=z^k$ with branch of $k^\text{th}$-root chosen}
\begin{figure}
\label{branchOfKthRootPic}
\end{figure}

Furthermore, if $g(z)$ is a holomorphic function from $\bC$ to $\bC$, then for any $z_0$ such that $g(z_0) \neq 0$, there is a choice of branch so that, near $z_0$, the map $g(z)^{1/k}$ is well-defined and holomorphic. We also denote this function by $\sqrt[k]{g(z)}$.

We are now ready to state the theorem (after a quick definition) which shows that a nice local expression of a holomorphic map can always be found.

\begin{definition}
A chart $(U_x, \varphi_x)$ for a Riemann Surface $X$ is called \textbf{centered at} $x$ if $\varphi_x(x) = 0$.
\end{definition}

\begin{theorem}
\label{zToTheKCharts}
Let $f:X \to Y$ be a non-constant holomorphic map of Riemann Surfaces. For any $x \in X$ there are charts given by $\tilde{\varphi}, \tilde{\psi}$ centered at $x, f(x)$ respectively, such that the local expression of $f$ using these charts is $z \mapsto z^k$ for some integer $k \geq 1$.
\end{theorem}
\todo[inline]{Do we want to state that a holomorphic map, for us is non-constant? or just keep qualifying as we go?}
\begin{proof}
Choose charts $\varphi, \psi$ centered at $x, f(x)$. Call the corresponding local expression $F:= \psi \circ f \circ \varphi^{-1}$. Since $F(0)=0$, near $0$ we may write $F(z) = 0 + a_1 z + \cdots + a_n z^n + \cdots$. Let $k$ be the smallest positive integer such that $a_k \neq 0$. Then $F(z) = a_k z^k + a_{k+1} z^{k+1} + \cdots = z^k(a_k + a_{k+1} z + \cdots )$.

Set $G(z) = a_k + a_{k+1} z + \cdots$. Then $G(z)$ is holomorphic at $0$ and $G(0) = a_k \neq 0$. Thus we may make a  choice of branch so that the map $\sqrt[k]{G(z)}$ is well-defined and holomorphic around $0=\varphi(x)$.

\begin{exercise}
\label{kthRootChart}
Define $h(z) = z\sqrt[k]{G(z)}$. We know that $h$ holomorphic in a neighborhood $U$ of $0=\varphi(x)$. Show that $h(0) = 0$ and that $h'(0) \neq 0$. Use the Inverse Function Theorem to conclude that $h$ is bi-holomorphic on a neighborhood $U' \subset U$ of $\varphi(x)$. \textit{Hint: Use the product formula to compute $h'$, but don't try to explicitly compute $\frac{d}{dz} \sqrt[k]{G(z)}$.}
\end{exercise}

Exercise \ref{kthRootChart} gives new coordinates $\tilde{\varphi} = h \circ \varphi$ for $x\in X$. We claim that using the coordinates $\tilde{\varphi}$ for $x$ and $\tilde{\psi}:=\psi$ for $f(x)$ gives the local expression $\tilde{F}:z \mapsto z^k$.

\missingfigure{Figure 9 - Altered charts to get $z^k$ local expression}
\begin{figure}
\label{zToTheKChartsFigure}
\end{figure}

To see this, note that $\tilde{F} = F \circ h^{-1}$. Any $z$ in the domain of $h^{-1}$ can be written as $z=h(w)=w\sqrt[k]{G(w)}$ for a unique $w\in U'$. Thus $\tilde{F}(z) = F(h^{-1}(z)) = F(w) = w^k G(w)$, i.e. we have $\tilde{F}:z=w\sqrt[k]{G(w)} \mapsto w^k G(w) = (w\sqrt[k]{G(w)})^k = z^k$.
\end{proof}

\todo[inline]{I'm not 100\% sure that what I said to conclude $\tilde{F}(z) = z^k$ is legitimate...}

Before moving on, we note that it can be shown that the $k$ associated to a map $f$ and $x\in X$ is well-defined. In other words, if there are other charts around $x$ such that the local expression of $f$ around $x$ is $z \mapsto z^{k'}$ then $k=k'$.

\subsection{Ramified Covers and the Riemann-Hurwitz Formula}
Here we introduce some terminology relating to the nice local expressions of holomorphic maps given in Theorem \ref{zToTheKCharts} and state a number of results.

Whether or not a Riemann Surface is compact is a valuable piece of information, as a number of results (including the important Riemann-Hurwitz Formula) require compact Riemann Surfaces. Because of this, we mention a result which completely describes the topology of a compact Riemann surface in terms of a single invariant called its genus. See Appendix \ref{classificationOfSurfaces} for the classification of compact, connected topological surfaces, from which the result follows.

\begin{remark}
If $X$ is a compact Riemann Surface, then topologically $X$ is a ``donut'' shell with $g=g_X$ holes. The number $g$ is called the genus of $X$. Two Riemann Surfaces $X,Y$ are topologically the same (homeomorphic) iff $g_X=g_Y$.
\end{remark}

\missingfigure{Figure 10 - Donuts}
\begin{figure}
\label{donutsFigure}
\end{figure}

Thus, one way to think of Riemann Surfaces is as a (possibly multi-holed) donut together with a complex structure, i.e. a local identification with $\bC$.

Recall from Theorem \ref{zToTheKCharts} that around any $x \in X$ a holomorphic map $f:X \to Y$ can be given the local expression $z \mapsto z^k$ for some $k \geq 1$. Of special interest are points $z$ where the corresponding $k$ is $2$ or more. We give some terminology to that effect.

\begin{definition}
Let $f:X \to Y$ be a non-constant holomorphic map of Riemann Surfaces.
\begin{itemize}
\item Given a point $x \in X$, the $k$ associated to the local expression centered at $p$ is called the \textbf{ramification index} of $f$ at $x$.

\item If a point $x$ has associated $k=1$, then we say $f$ is \textbf{unramified} at $x$.

\item A point $x$ such that $k \geq 2$ is called a \textbf{ramification point}. The \textbf{ramification locus} $R$ is the subset of $X$ consisting of all ramification points.

\item If $x$ is a ramification point, then $f(x)\in Y$ is called a \textbf{branch point}. The \textbf{branch locus} $B$ is the subset of $Y$ consisting of all branch points - it is the image via $f$ of the ramification locus.
\end{itemize}
\end{definition}


%fig
\missingfigure{Figure 11 - Pic of a Ramified Cover}
\begin{figure}
\label{ramifiedCoverFigure}
\end{figure}

\begin{remark}
We have that $x \in X$ is associated to $k=1$ iff $f$ is locally invertible at $x$ iff $f'(x) \neq 0$
\end{remark}
\todo[inline]{We haven't defined what $f'$ is for a map of Riemann Surfaces}

\begin{exercise}
\label{discreteRamExercise}
Let $f:X \to Y$ be a non-constant holomorphic map of Riemann Surfaces. Suppose the ramification index of $x_0\in X$ is $k_0$. Show that there is a neighborhood $U_0$ of $x_0$ such that the ramification of each $x\in U$ with $x\neq x_0$ is $k=1$.
\end{exercise}

As an immediate consequence of Exercise \ref{discreteRamExercise} we have the following result.

\begin{corollary}
The ramification locus $R$ is a discrete subset of $X$, i.e. there exist open sets $U_i \subset X$ such that each $U_i$ contains exactly one $x \in R$ and $R \subset \cup_i U_i$.
\end{corollary}

If $X$ was compact and had infinitely many ramification points for a map $f$, then the ramification points would have a limit point in $X$ (Does this seem strange to you? If so, try and prove it!). This would violate the discreteness of $R$ and so we have the following corollary.

\begin{corollary}
\label{finiteRamification}
If $X$ is a compact Riemann Surface and $f:X \to Y$ is a holomorphic map of Riemann Surfaces, then the ramification locus is a finite set. Since the branch locus is the image of $R$ via $f$, it follows that the branch locus is also a finite set.
\end{corollary}

\noindent\textbf{Warning!} The branch locus is the image of the ramification locus, \textit{but} the ramification locus is not necessarily the inverse image of the branch locus. The point is that it is possible to have $x_1$ associated to $k_1 = 1$ and $x_2$ associated to $k_2 \geq 2$ with $f(x_1) = f(x_2)$.


Besides having nice local expressions, the images of holomorphic maps $f:X \to Y$ are also well-structured. For example, the next theorem shows that, if $X$ is compact, then such a map $f$ either ``hits'' all of $Y$ or just one point in $Y$.

\begin{theorem}
Let $f:X \to Y$ be a holomorphic map of Riemann Surfaces with $X$ compact. If $f$ is non-constant then it is onto.
\end{theorem}
\todo[inline]{Say anything about the proof? It's short (see pg 41 of Miranda), but I'm not sure if saying it here would be good, or giving it as an exercise - it requires knowing that a compact subset of a Hausdorff space is closed.... perhaps a little esoteric for our readers? -- I think we could also list this as a consequence of Thm \ref{degreeThm} if we wanted...}

A relatively fast corollary of holomorphic maps $f:X \to Y$ having local expressions of the form $z \mapsto z^k$ for each $x \in X$ is that for each $x$ there is a neighborhood $U$ of $x$ such that, in $U$, there are no other preimages of $f(x)$, i.e. such that $U \cap f^{-1}(f(x))= \varnothing$. Hence, for any $y \in Y$ the preimage set $f^{-1}(y)$ is discrete, and if $X$ is compact, then (as in Corollary \ref{finiteRamification}) we have that $f^{-1}(y)$ is a finite set. The next result shows that, outside of the branch locus, the size of these preimage sets, $|f^{-1}(y)|$, are constant.

\begin{theorem}
\label{degreeThm}
Let $f:X \to Y$ be a non-constant holomorphic map of Riemann Surfaces with $X,Y$ compact and $Y$ connected. If $y_0, y_1 \in Y$ are not in the branch locus of $f$, then $|f^{-1}(y_0)| = |f^{-1}(y_1)|=:d$. We call the number $d \geq 1$ the \textbf{degree} of $f$.
\end{theorem}
\begin{exercise}
Let's prove Theorem \ref{degreeThm}: Call the branch locus $B$. Since $B$ is finite, $Y-B$ is a connected topological space, and hence it can not have a proper subset which is both open and closed. Let $y_0\in Y-B$ and set $d:=|f^{-1}(y_0)|$.
\begin{enumerate}
\item Set $A = \{y \in Y-B | |f^{-1}(y)| = d\}$. Show that $A$ is open in $Y-B$ by showing that $y\in A$ implies that there is a neighborhood $y\in U \subset Y-B$ such that $u \in U$ implies that $|f^{-1}(u)| = d$. \textit{Hint: What does $y\in Y-B$ imply about the local expressions of $f$ around each $x\in f^{-1}(y)$?}

\item Show that $A^c = \{y \in Y-B | |f^{-1}(y)| \neq d\}$ is open in $Y-B$.

\item Deduce the statement of the theorem using 1 and 2.
\end{enumerate}
\end{exercise}

\todo[inline]{Mention something as a remark or thm or exercise about a point being in the branch locus iff it has less than the degree of $f$ preimages?}

\todo[inline]{Mention that the the sum of the ramification indices of the preimages of any $y$ is $d$? I use that in my sketch of the Riemann-Hurwitz formula}



\subsection{Riemann-Hurwitz Formula}
\label{riemannHurwitzFormulaSection}

Here we give a very useful result which, for a holomorphic map $f:X \to Y$, relates the genus of $X$ to the genus of $Y$ using the ramification and degree data of $f$.

\begin{theorem}[Riemann-Hurwitz Formula]
\label{riemannHurwitzFormula}
If $f:X \to Y$ is a non-constant, degree $d$, holomorphic map of connected compact Riemann Surfaces, then the following equation holds
\[
2g_X-2 = d(2g_Y-2) + \sum_{x \in X} (k_x - 1)
\]
where $k_x$ is the ramification index of $f$ at $x$.
\end{theorem}

Note that since $k_x-1 \neq 0$ iff $x$ is a ramification point, we could replace the the index set $X$ in the above sum with the ramification locus.

\begin{proof}[Idea of the proof]
Recall that a Riemann Surface $X$ is topologically a $g_X$-holed torus. Thus its Euler Characteristic (which can be computed using a ``good graph''\footnote{a \textit{good graph} on $X$ means a graph $\Gamma$ on $X$ such that (i) $X-\Gamma$ is homeomorphic to a disjoint union of open disks, (ii) wherever two edges cross there is a vertex, and (iii) no edges end without a vertex} on $X$) is $\chi(X) = 2-2g_X$. Thus Riemann-Hurwitz Formula asserts that $\chi(X) = d\chi(Y) - \sum_{x \in X} (k_x - 1)$.

Given a good graph on $X$, the Euler Characteristic is computed as $\chi(X) = |V|-|E|+|F|$ where $V$ is the number of vertices on the graph, $E$ the number of edges, and $F$ the number of faces. Our strategy is to take a particular good graph on $Y$ and ``lift'' it to a good graph on $X$ which we use to compute $\chi(X)$.

To begin, choose a good graph $\Gamma_Y$ on $Y$ which has vertices only at the branch points of $f$. Say the graph has $V_Y$ vertices, $E_Y$ edges, and $F_Y$ faces. Now ``lift'' $\Gamma_Y$ using the map $f$ to get a good graph $\Gamma_X$ on $X$- by ``lift'' we mean that the vertices $V_X$ are the preimages of the vertices of $\Gamma_Y$, the edges $E_X$ are the preimages of the edges of $\Gamma_Y$, and similarly for the faces.

We now relate $\Gamma_X$ to $\Gamma_Y$. If $\Gamma_Y$ had a vertex at a point \textit{not} in the branch locus, then there would be $d$ vertices above it in $\Gamma_X$. However, we have chosen the vertices of $\Gamma_Y$ to be the branch locus, and for each ramification point above, we lose some preimages. Specifically, if the ramification index of $x$ is $k_x$, then we have lost $k_x-1$ preimages of $f(x)$ from the ``expected'' $d$. Taking our expected number of preimages and subtracting off our ``lost'' preimages due to ramification gives $|V_X| = d|V_Y| - \sum_{x \in X} (k_x - 1)$.

We may think of the edges and faces of $\Gamma_Y$ as living in $Y-B$ and thus nothing is ``lost'' in the lift, i.e. each has $d$ preimages. We thus have $|E_X| = d|E_Y|$ and $|F_X| = d|F_Y|$. See Figure \ref{illustrationOfRHFormula}

Finally, computing $\chi(X)$ using $\Gamma_X$ gives
\begin{align*}
\chi(X) &= |V_X|-|E_X|+|F_X| \\
&= d|V_Y| - \sum_{x \in X} (k_x - 1) - d|E_Y| + d|F_Y| \\
&= d(|V_Y|-|E_Y|+|F_Y|) - \sum_{x \in X} (k_x - 1) \\
&= d\chi(Y) - \sum_{x \in X} (k_x - 1)
\end{align*}
\end{proof}

\missingfigure{Figure 12 - Lifting the graph on $Y$}
\begin{figure}
\label{illustrationOfRHFormula}
\end{figure}


\begin{remark}
We emphasize that the Riemann-Hurwitz Formula only applies if $X$ and $Y$ are connected, compact Riemann Surfaces. Also, it is common to also use the notation $v_x := k_x - 1$. Note that $v_x$ is exactly how many preimages of $f(x)$ are ``lost'' at due to the ramification at $x$.
\end{remark}

Often times one has a partial knowledge of the genus and ramification data of a map $f$ and then uses the Riemann-Hurwitz Formula to deduce the rest of the information. This is the case in the next example.

\begin{example}
\label{twoPointsFullRamExample}
Let $f:X \to Y$ be a degree $d$ holomorphic map with $X=Y=\PoneC$. Suppose that $r_1,r_2 \in X$ have full ramification, i.e. $k_1 = k_2 = d$  where we set $k_{r_i}=: k_i$. One can ask ``Can there be any other ramification points?'' We use the Riemann-Hurwitz Formula to answer this.

Noting that $g_X=g_Y=0$, we have
\begin{align*}
2g_X-2 &= d(2g_Y-2) + \sum_{x \in X} (k_x-1) \\
-2 &= d(-2) + (k_1-1) + (k_2-1) + \sum_{x \neq r_1,r_2} (k_x-1) \\
-2 &= d(-2) + (d-1) + (d-1) + \sum_{x \neq r_1,r_2} (k_x-1) \\
0 &= \sum_{x \neq r_1,r_2} (k_x-1)
\end{align*}
So each $x\neq r_1,r_2$ must have $k_x = 1$. Thus, the answer to our question is ``no,'' there can be no other ramification points.
\end{example}

\begin{exercise}
\label{twoPointsFullRamGone}
Start with the setup of Example \ref{twoPointsFullRamExample} except suppose that $X$ now has genus $g_X=1$. Can there be any other ramification points besides $r_1,r_2$? If so, describe what kind of ramification is possible.
\end{exercise}

Note that in Example \ref{twoPointsFullRamExample} and Exercise \ref{twoPointsFullRamGone} we are not constructing holomorphic maps - we are simply determining what ramification is necessary for a holomorphic map $f$ to even be possible.

\begin{exercise}
Suppose that $f:X \to Y$ is a non-constant holomorphic map of connected compact Riemann Surfaces.
\begin{enumerate}
\item Show that $\sum_{x \in X} v_x$ is even.
\item Show that $g_X \geq g_Y$. This means that $X$ can never map (non-trivially) to a $Y$ with higher genus.
\end{enumerate}
\end{exercise}


\section{More Examples of Holomorphic Maps}

\subsection{Elliptic and Hyperelliptic Curves}
\begin{example}
\label{hyperellipticCurveExample}
A Riemann Surface is called \textbf{hyperelliptic} if it admits a holomorphic map $f$ to $\PoneC$ of degree 2. Applying the Riemann-Hurwitz Formula to $f$ gives
$2g_X-2 = 2(-2) + \sum_{x \in X} v_x$ and thus $\sum_{x \in X} v_x = 2g_X+2$.

Since the degree of $f$ is $2$, a point $x \in X$ is a ramification point iff $k_x = 2$ (i.e. if $v_x = 1$). Then $\sum_{x \in X} v_x = 2g_X+2$ implies that $f$ has $2g_X + 2$ distinct ramification points. It also follows that there are $2g_x+2$ distinct branch points in $\PoneC$ - do you see why? If not, prove it!
\end{example}

\todo[inline]{I technically only defined a hyperell. Riemann Surface, not a hyperell. curve - is this ok or do we want to change something? Also, by this def $\PoneC$ is hyperelliptic - is that ok?}

\begin{example}
\label{ellipticCurveExample}
Define the curve $E_1\subset \bC^2$ by $y^2 = (x-a_1)(x-a_2)(x-a_3)$ where the $a_i \in \bC$ are distinct. In the language of Example \ref{smoothCurveExample} we have $E_1 = V( y^2 - (x-a_1)(x-a_2)(x-a_3))$.

\begin{exercise}
Show that $E_1$ is a smooth curve iff the $a_i$ are all distinct.
\end{exercise}

\missingfigure{Figure 13 - a schematic graph of an elliptic curve}
\begin{figure}
\label{ellipticCurveGraph}
\end{figure}


We have a map $\pi:E_1 \to \bC$ defined by $\pi: (x,y) \mapsto x$. Because $\pi$ is simply a projection from a smooth curve, it is a holomorphic map of Riemann Surfaces: to be more precise, if $(x,y)\in E_1$ has $y\neq 0$ then near $(x,y)$ the map $\pi$ is the local coordinate function $\varphi_{(x,y)}$, and thus has local expression $z \mapsto z$ (which is holomorphic). Note that this shows $\pi$ is unramified at $(x,y)$.
%
%\begin{exercise}
%Prove the last statement by proving the following more general statements. Let $X$ be a Riemann Surface and $(U_x, \varphi_x)$ a chart around $x \in X$.
%\begin{enumerate}
%\item Construct an atlas on $U_x$ so that $U_x$ is a ``sub-Riemann Surface'' of $X$
%
%\item Show that $\varphi_x:U_x \to \bC$ is a holomorphic map of Riemann Surfaces.
%\end{enumerate}
%\end{exercise}

If instead our point is $(x,0) \in E_1$, then we have a chart $(U,\varphi)$ around $(x,0)$ which realizes $U$ as the graph of $x=g(y)$ for some holomorphic function $g$ (this is how we gave curves in $\bC^2$ the structure of Riemann Surfaces in Example \ref{smoothCurveExample}). In these coordinates, we have $\pi=g$ and hence $\pi$ is holomorphic at $(x,0)$. These considerations show that $\pi$ is a holomorphic map of Riemann Surfaces.

%%%%% be more rigorous than that??

For $x_0 \neq a_i$ for any $i$ then $|\pi^{-1}(x_0)|=2$ - can you see why? If not, prove it! Hence $|\pi^{-1}(a_i)|=1$ implies that $(a_i,0)$ are ramification points of $E_1$ of index $2$.

As it stands, $E_1$ is not compact, but we can compactify it by placing $E_1$ in $\PtwoC$ and seeing what extra points ``at infinity'' $E_1$ picks up. (We've seen this idea of adding points to something to compactify before: taking $\bC$ and wrapping it up with an extra point $\infty$ gives $\PoneC$, the Riemann Sphere!)

The process of taking the (affine curve) $E_1$ and compactifying it inside $\PtwoC$ so that we get a compact (projective) curve $E \supset E_1$ is called \textbf{homogenization}. To get the defining equation for $E \subset \PtwoC$ we simply introduce a new variable $z$ to $x$ and $y$ and use $z$ to make every term in the equation for $E_1$ homogeneous, i.e. of the same degree. Since $(x-a_1)(x-a_2)(x-a_3)$ is a degree 3 polynomial, we have $E = \{y^2z = (x-a_1z)(x-a_2z)(x-a_3z)\}$, i.e. $E = \{[x:y:z]\in \PtwoC |y^2z - (x-a_1z)(x-a_2z)(x-a_3z)=0\}$. Notice that $E$ restricted to the patch of $\PtwoC$ with $z=1$ is $E_1\subset \bC^2$.

The points ``at infinity'' that we have added to $E_1$ to get $E$ are those points $[x:y:z] \in \PtwoC$ with $z=0$. Plugging in $z=0$ to the defining equation of $E$ gives $x=0$ and thus there is just one point ``at infinity,'' namely $[0:1:0]$. Let us call this point $\infty$, so that as a set, $E = E_1 \cup \{\infty\}$. We call $E$ an \textbf{elliptic curve}.

We can extend the holomorphic map $\pi:E_1 \to \bC$ to a holomorphic map $\pi:E \to \PoneC$ by sending $\infty \mapsto \infty$. The result is a holomorphic map of degree 2 of connected compact Riemann Surfaces.

\begin{exercise}
\label{ellipticCurveRamificationEx}
Use the Riemann Hurwitz Formula to show that $\infty \in E$ is a ramification point of $\pi$ and that $g_E = 1$.
\end{exercise}
\end{example}

\todo[inline]{Should we say more about why the extended $\pi$ is holomorphic, or mention that we're not going to explicitly show that?}


\begin{remark}
We have actually seen elliptic curves before - as complex tori! (Quick sanity check: what is the genus of each?) For any complex torus $T$, there is an equation which realizes $T$ as an elliptic curve $E \cong T$, and vice versa. Algebraically minded people tend to favor thinking of them as elliptic curves, while complex analytic minded people prefer complex tori, but they're both equivalent!
\end{remark}
\todo[inline]{Renzo, I'm sure you can make this remark much better/true than I have.}


\begin{exercise}
A nonconstant holomorphic map between complex tori $\tilde{f}: \bC/\Lambda \to \bC/\Lambda'$ is called an \textbf{isogeny}. One way to construct an isogeny is to create a holomorphic map $f:\bC \to \bC$ which is well-defined when we mod out by the lattices, i.e. such that for any $z \in \bC$ and any $l \in \Lambda$ we have $f(z+l) = f(z) + l'$ for some $l' \in Lambda'$.

It can be shown (without an excessive amount of trouble - see MIRANDA) that every isogeny is induced by a map $f(z) = az+b$ where $a,b \in \bC$ and $a\Lambda \subset \Lambda'$.

\begin{enumerate}
\item Show that any isogeny $f$ is unramified.

\item Consider the isogeny $\tilde{f}:\bC/\Lambda \to \bC/\Lambda'$ induced by $f(z) = z+1$, where $\Lambda = \{n+m(1+i)|n,m \in \bZ\}$ and $\Lambda' = \{n(1/2)+m(1/2+i/2)|n,m \in \bZ\}$. Find the degree of $\tilde{f}$.

\item Let $D$ be the set of $d \geq 1$ such that there is an isogeny of degree $d$. Is $D = \bZ_{\geq 1}$?
\end{enumerate}
\end{exercise}



\subsection{Maps from $\PoneC$ to $\PoneC$}

\begin{example}
In Exercise \ref{polynomialMapsOfPoneC} it is essentially shown that any polynomial $p(x) \in \bC[x]$ gives a holomorphic map $p:\PoneC \to \PoneC$ by the rule $x \in \bC \mapsto p(x)$ and $\infty \mapsto \infty$. But what about a function with poles - something like $\tilde{p}(x) = 1/x$? Well, ever since kindergarten we've wanted to say that $1/0 = \infty$ and $1/\infty = 0$, and this is exactly what makes $\tilde{p}:\PoneC \to \PoneC$ a holomorphic map! In other words, we have $\tilde{p}:0 \mapsto \infty, \infty \mapsto 0$, and $x \mapsto \tilde{p}(x)$ for $x \neq 0, \infty$.

\begin{exercise}
\label{oneOverXCubedExercise}
Let $\tilde{q}(x) = 1/x^3$. Show that the induced map $\tilde{q}:\PoneC \to \PoneC$ is holomorphic.
\end{exercise}

One similarly obtains a holomorphic map $f=p/q:\PoneC \to \PoneC$ from any rational function $p(x)/q(x)$ where $p(x),q(x) \in \bC[x]$ have no common roots.

\begin{remark}
\label{rationalFunctionsAreP1Maps}
One can show (without an excessive amount of work - see MIRANDA Theorem 2.1) that \textit{any} holomorphic map $f:\PoneC \to \PoneC$ can be written as a rational function $f=p(x)/q(x)$ where $p(x),q(x) \in \bC[x]$ have no common roots.
\end{remark}


Let us consider which of these rational functions are automorphisms of $\PoneC$. We have already encountered one - namely $f=\tilde{p}(x)=1/x$. This map essentially turns the Riemann Sphere upside down. Are there any other automorphisms?

Recall that an automorphism must in particular be a one-to-one function, but our map $f$ has a zero at each root of $p(x)$ and a pole (i.e. preimage of $\infty$) at each root of $q(x)$. Hence for $f$ to be one-to-one, $p(x)$ and $q(x)$ must each only have one root. Thus we have
\[
f = \frac{p(x)}{q(x)}=\frac{a(x-a_1)^n}{c(x-c_1)^m}
\]
where $a,a_1,c,c_1 \in \bC$ and $a_1 \neq c_1$.

At $x=a_1$ the map $f$ will have local expression $z \mapsto z^n$ and at $x=c_1$ the local expression will be $z \mapsto z^m$. \todo[inline]{I don't actually prove this - is that ok?} These are $n$-to-one and $m$-to-one maps, respectively, and so if we want $f$ to be one-to-one, we must have $n=m=1$, i.e.
\[
f = \frac{p(x)}{q(x)}=\frac{ax+b}{cx+d}
\]
for $a,b,c,d \in \bC$. Let us now see which of these $f$'s are automorphisms.

\begin{exercise}
\label{mobiusTransExercise}
Let $f:\PoneC \to \PoneC$ be the map induced by $(ax+b)/(cx+d)$ for $a,b,c,d \in \bC$. Suppose that $ad-bc \neq 0$.
\begin{enumerate}

\item Show that $f$ is one-to-one.
\item Show that $f$ is onto.
\item Show that $f^{-1}:\PoneC \to \PoneC$ is a holomorphic map.
\item Consider enough cases where $ad-bc=0$ to convince yourself that 1, 2, and 3 are false when $ad-bc=0$.
\end{enumerate}
These maps $f$ with $ad-bc \neq 0$ are called \textbf{M\"{o}bius transformations} and, in light of Remark \ref{rationalFunctionsAreP1Maps}, are \textit{all} of the automorphisms of $\PoneC$.
\end{exercise}
\end{example}

\noindent\hrulefill

\begin{remark}
\label{mobiusFromLinearMaps}
One can arrive at the M\"{o}bius transformations in another way. If we think of $\PoneC = (\bC^2 - \{\vec{0}\})/{\bC^\star}$ then we may induce an automorphism of $\PoneC$ from a linear automorphism of $\bC^2$, i.e. an element $M \in \text{GL}(2,\bC)$ where
\[
\text{GL}(2,\bC) = \{\left(\begin{array}{cc}
a &b\\
c &d\\
\end{array}\right)| a,b,c,d \in \bC \text{ with } ad-bc \neq 0\}
\]
If we associate the vector $\vec{x}=(x, y)^T$ to the homogeneous coordinates $[x:y]$ then $M\vec{x} = (ax + by, cx + dy)^T$ implies that $M$ sends $[x:y]$ to $[ax + by : cx + dy]$. Writing the local expression of $M$ using the charts where the second homogeneous coordinate is non-zero gives $[x:1] \mapsto [(ax+b)/(cx+d):1]$ so we see that $M$ is a M\"{o}bius transformation.
\end{remark}
\todo[inline]{Remark \ref{mobiusFromLinearMaps} (especially the local expression bit at the end) feels pretty rough...}


\todo[inline]{I've decided to leave out showing that conics are all isomorphic to $\PoneC$ - do you think we need it? If you think we should put it in, how should we go about showing that?}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Covering Theory}
\label{coveringTheory}

\todo[inline, color=blue!40]{Perhaps we should call this chapter ``Loops and Lifts'' as these are the main concepts here, and actually the fundamental group is emphasized more than coverings right now.}


\todo[inline]{I'm thinking that maybe this chapter should go right before Chapter \ref{countingMonodromyReps} - the Monodromy Reps chapter - what do you think? We really don't need this material for the first Hurwitz Numbers Chapter (6), and it would allow us to reword Example \ref{ellCurveMapViaLifts} to serve as an intro to the idea of lifting...}


Holomorphic maps of Riemann Surfaces are strongly connected to topology (we have already seen one example of this with the Riemann-Hurwitz Formula, Theorem \ref{riemannHurwitzFormula}). In Chapter \ref{countingMonodromyReps} this connection will be exploited further, and we will see how maps of Riemann Surfaces are determined by ``lifting'' loops from the base space to the domain.

We introduce here the relevant topological notions - in particular, we discuss homotopies and the fundamental group, as well as coverings and path lifting.

\section{Homotopies}

Homotopies formalize the notion of continuously altering (or ``wiggling'') a continuous map of topological spaces. Later we will consider certain maps (specifically, loops) the same if they differ by a homotopy.

\textit{The idea is that a homotopy between to maps $f$ and $g$ is a 1-hour long movie, which at time $t=0$ shows the map $f$, and at time $t=1$ shows the map $g$.}

\begin{definition}
Let $f,g:X \to Y$ be continuous maps of topological spaces. A \textbf{homotopy} between $f$ and $g$ is a continuous map $H:X \times [0,1] \to Y$ such that $H(x,0) = f(x)$ and $H(x,1)=g(x)$ for all $x \in X$. If such an $H$ exists, we say that $f$ and $g$ are \textbf{homotopic} and write $f \sim g$.
\end{definition}


\missingfigure{Figure 23 - schematic picture showing a homotopy of maps}
\begin{figure}
\label{homotopyPic}
\end{figure}

We begin by demonstrating that the topology of $\bR^n$ allows any two maps with target in $\bR^n$ to be ``wiggled'' one to the other.

\begin{example}
\label{stuffIsHomotopicInRn}
Let $f,g:X \to \bR^n$ be continuous maps. We claim that $f \sim g$. To see this, it suffices to consider the ``straight-line homotopy'' $H:X \times [0,1] \to \bR^n$ given by $H(x,t)=(1-t)f(x) + tg(x)$. \todo{should we mention anything about why $H$ is continuous?}
\end{example}

\begin{exercise}
\label{equalImpliesHomotopic}
Show that $f=g:X \to Y$ implies $f \sim g$.
\end{exercise}

\begin{exercise}
Convince yourself that the two maps $\alpha, \beta: S^1 \to T$ depicted below are \textit{not} homotopic, but that the two maps $\gamma, \sigma$ \textit{are} homotopic.
\missingfigure{Figure 24 - LHS: two main circles on a torus, RHS: two circles going around handle of torus}
\begin{figure}
\label{nonHomotopicCirclesPic}
\end{figure}
\end{exercise}

\begin{exercise}
Convince yourself that the constant map $\pi:S^1 \to S^1$ defined by $\pi(x) = [0]$ is \textit{not} homotopic to $Id_{S^1}$. Here we think of $S^1$ as the topological space $[0,1]/0\sim1$ (i.e. we do not embed $S^1$ into any ambient space).
\end{exercise}

\begin{exercise}
Prove that any two continuous maps $f,g:\{pt\} \to X$ are homotopic iff $X$ is path-connected. Here $\{pt\}$ is the one-point set.\todo{should we make $pt$ just be normal text?}
\end{exercise}


\begin{definition}
Two topological spaces $X,Y$ are called homotopic (and we write $X \sim Y$) if there exists continuous maps $f:X \to Y$ and $g:Y \to X$ such that $g \circ f \sim Id_X$ and $f \circ g \sim Id_Y$.
\end{definition}

By Exercise \ref{equalImpliesHomotopic}, this is a relaxing of the notion of ``homeomorphic'' which requires equality instead of simply homotopic. This relaxing is extreme, as the following example shows.

\begin{example}
We show that $\{pt\} \sim \bR^n$. Consider the constant map $\pi:\bR^n \to \{pt\}$ and the inclusion $\iota:\{pt\} \to \bR^n$ given by $\iota(pt) = \vec{0}$. Then $\pi \circ \iota = Id_{pt}$ (and thus are homotopic) and $\iota \circ \pi:\bR^n \to \bR^n$ (which is the constant function $\vec{0}$) is homotopic to $Id_{\bR^n}$ by Example \ref{stuffIsHomotopicInRn}. We call a space \textbf{contractible} if it is homotopic to $\{pt\}$.
\end{example}

\begin{exercise}
Show that homotopic is an equivalence relation on the class\todo{set?} of maps from a space $X$ to a space $Y$.
Show that homotopy equivalence is an equivalence relation on the class\todo{set?} of topological spaces.
\end{exercise}

\begin{exercise}
Fill in the necessary details (using Figure \ref{contractionPic} as a guide) to show that the cylinder is homotopic to the circle is homotopic to the punctured plane.
\missingfigure{Figure 25 - cylinder, circle and punctured plane with indicated contraction maps}
\begin{figure}
\label{contractionPic}
\end{figure}
\end{exercise}



\section{The Fundamental Group}
The fundamental group, or $\pi_1$, is an important construction in topology which, to a topological space, associates a group of loops in that space. We now give the precise definition after some preliminaries.

%%%%%%%%%%
%Commented out is what I had when I first talked about pi_1 as a functor - I moved it below because I thought that it would be a bit awkward to talk about the objects properties without knowing the object at all. I think that introducing the language after the construction will strengthen the idea that the language of category theory is nice because it describes things that we care about. That said - I'm definitely willing to talk about the order and adjust!
%%%%%%%%%%
%The ``gadget'' $\pi_1$ assigns to any (pointed) topological space $X$, a group $\pi_1(X, x_0)=:\pi_1(X)$, and in fact assigns to any continuous map $f:X \to Y$, a group homomorphism $\pi_1(f):\pi_1(X) \to \pi_1(Y)$. Moreover, it's a fact that $\pi_1$ preserves composition of functions and identities: $\pi_1(g \circ f) = \pi_1(g) \circ \pi_1(f)$ and $\pi_1(Id_X) = Id_{\pi_1(X)}$.

%Such a ``gadget'' is called a \textbf{functor} $\pi_1:\cT \to \cG$ from the category $\cT$ of topological spaces and continuous maps, to the category $\cG$ of groups and group homomorphisms. (This is really just fancy terminology - don't be frightened!)

%From this, we can prove that fundamental groups are an invariant of homeomorphism classes.

%\begin{proposition}
%Let $X,Y$ be topological spaces. Then $X$ homeomorphic to $Y$ implies $\pi_1(X)$ isomorphic to $\pi_1(Y)$, i.e. $\pi_1(X) \cong \pi_1(Y)$.
%\end{proposition}
%\begin{proof}
% To see this, note that $X$ homeomorphic to $Y$ means there are continuous maps $f:X \to Y$ and $g:Y \to X$ such that $g \circ f = Id_X$ and $f \circ g = Id_Y$. Hitting the first equality of maps with $\pi_1$ gives that $\pi_1(g \circ f) = \pi_1(Id_X)$. But $\pi_1(g \circ f) = \pi_1(g) \circ \pi_1(f)$ and $\pi_1(Id_X)=Id_{\pi_1(X)}$. Hitting the second equality, $f \circ g = Id_Y$ with $\pi_1$ similarly yields $\pi_1(f) \circ \pi_1(g) = Id_{\pi_1(Y)}$. Thus $\pi_1(X) \cong \pi_1(Y)$.
%\end{proof}

\begin{definition}
Let $X$ be a topological space and $x_0 \in X$. A \textbf{loop in $X$ with base point $x_0$} is a continuous map $\gamma:[0,1]_s \to X$ such that $\gamma(0)=\gamma(1)=x_0$. (We write $[0,1]_s$ to denote that we use the variable $s$ to correspond to this interval.)

This next definition makes explicit the notion of deforming one loop to the other while keeping the base point fixed: Two loops $\gamma_1,\gamma_2$ with base point $x_0$ are said to be \textbf{homotopic with respect to their base point} if there exists a homotopy $H:[0,1]_s \times [0,1]_t \to X$ between $\gamma_1$ and $\gamma_2$ such that for all $t$ we have $H(0,t)=H(1,t)=x_0$.
\end{definition}

\missingfigure{Figure 26 - picture of homotopy between two loops wrt base point (see p20 of Amanda's notes)}
\begin{figure}
\label{basePointHomotopyPic}
\end{figure}

\begin{definition}
\label{fundamentalGroupDef}
Let $X$ be a topological space and $x_0 \in X$. The fundamental group of $X$ with base point $x_0$ as a set is
\[
\pi_1(X,x_0) = \{\text{loops in $X$ centered at $x_0$} \}/\sim
\]
where for two loops, $\gamma_1 \sim \gamma_2$ iff $\gamma_1$ is homotopic to $\gamma_2$ with respect to their base point.
\end{definition}

Given two loops $\gamma_1,\gamma_2$, intuitively one can get a new loop by first ``walking around'' $\gamma_1$ and then walking around $\gamma_2$. Since loops must have domain $[0,1]$ we are forced to walk around $\gamma_1$ ``twice as fast'', and then walk around $\gamma_2$ twice as fast. We must be careful in applying this intuition to obtain a binary operation on $\pi_1(X,x_0)$, as elements of the fundamental group are \textit{classes of} loops.

\begin{definition}
\label{concatLoopsDef}
Given two loops $\gamma_1,\gamma_2$ in $X$ with base point $x_0$, we define the loop $\gamma_2 * \gamma_1$ in $X$ with base point $x_0$ as follows.
\[
\gamma_2 * \gamma_1(s) =
   \left\{
     \begin{array}{lr}
       \gamma_1(2s) & \text{if } s \in [0,1/2]\\
       \gamma_2(2s-1) & \text{if } s \in [1/2,1]
     \end{array}
   \right.
\]

Given two elements $[\gamma_1],[\gamma_2] \in \pi_1(X,x_0)$ we define the element $[\gamma_1]*[\gamma_2]:= [\gamma_2 * \gamma_1] \in \pi_1(X,x_0)$.
\end{definition}

\begin{remark}
We will not explicitly prove that the maps $\gamma_2 * \gamma_1$ or the homotopies which follow this remark are continuous, but we hope that continuity will be thoroughly believable in each case.
\end{remark}

\begin{lemma}
The operation $*$ for $\pi_1(X,x_0)$ defined in Definition \ref{concatLoopsDef} is well defined.
\end{lemma}
\begin{proof}
We must show that if $\gamma_1 \sim \gamma$ and $\gamma_2 \sim \delta$, then $[\gamma_2 * \gamma_1] = [\delta * \gamma]$, i.e. that the loops $\gamma_2 * \gamma_1$ and $\delta * \gamma$ are homotopic with respect to their base point $x_0$.

Let $H_1$ be a homotopy between $\gamma_1$ and $\gamma$, and similarly for $H_2$ between $\gamma_2$ and $\delta$, both with respect to the base point $x_0$. Then we create a homotopy $H$ between $\gamma_2 * \gamma_1$ and $\delta * \gamma$ with respect to $x_0$ by ``placing $H_1$ and $H_2$ side-by-side.'' Specifically, we define $H:[0,1]_s \times [0,1]_t \to X$ as follows (see Figure \ref{wellDefinedOperationPic}).

\[
H(s,t) =
   \left\{
     \begin{array}{lr}
       H_1(2s,t) & \text{if } s \in [0,1/2]\\
       H_2(2s-1,t) & \text{if } s \in [1/2,1]
     \end{array}
   \right.
\]

Note that $H(0,t)=H(1,t)=x_0$.
\end{proof}


\missingfigure{Figure 27 - Homotopy squares of $H_1, H_2, H$}
\begin{figure}
\label{wellDefinedOperationPic}
\end{figure}

\begin{theorem}
Let $X$ be a topological space and $x_0 \in X$. Then $\pi_1(X,x_0)$ is a group under the binary operation $*$.
\end{theorem}
\begin{proof}
The identity element $e$ with respect to $*$ is the (class of the) loop $\epsilon_{x_0}(s)=x_0$ for all $s$, i.e. we have $[\epsilon_{x_0}] * [\gamma] = [\gamma] = [\gamma] * [\epsilon_{x_0}]$ for all $\gamma \in \pi_1(X,x_0)$. To see the first equality, consider the homotopy $H$ given by ``taking more and more time to go through $\gamma$.''

\missingfigure{Figure 28 - LHS: Homotopy square for the $[\epsilon_{x_0}] * [\gamma] = [\gamma]$, RHS: exact definition}
\begin{figure}
\label{identHomotPic}
\end{figure}

To be precise, we have
\[
H(s,t) =
   \left\{
     \begin{array}{lr}
       \gamma(\frac{2s}{t+1}) & \text{if } t \geq 2s-1\\
       x_0 & \text{if } t \leq 2s-1
     \end{array}
   \right.
\]

Given an element $[\gamma]$, its inverse is $[\gamma]^{-1} = [\gamma^{-1}]$ where $\gamma^{-1}(s) = \gamma(1-s)$. Note that $\gamma^{-1}$ ``walks backwards'' along $\gamma$. To see that $[\gamma^{-1}]*[\gamma]=[\epsilon_{x_0}]$, consider the homotopy $H$ given by ``walking less and less along $\gamma$, then coming back.''

\missingfigure{Figure 29 - Homotopy square for the $[\gamma^{-1}]*[\gamma]=[\epsilon_{x_0}]$}
\begin{figure}
\label{inverseHomotPic}
\end{figure}

To be precise, we have
\[
H(s,t) =
   \left\{
     \begin{array}{ll}
       \gamma(s) & \text{if } s \leq \frac{1-t}{2}\\
       \gamma(\frac{1-t}{2}) & \text{if }  \frac{1-t}{2} \leq s \leq \frac{t+1}{2}\\
      \gamma^{-1}(s) & \text{if }   \frac{t+1}{2} \leq s
     \end{array}
   \right.
\]

\begin{exercise}
Draw the appropriate pictures and write out explicit homotopies to show the following.
\begin{enumerate}
\item $[\gamma]*[\epsilon_{x_0}]  = [\gamma]$
\item $[\gamma]*[\gamma^{-1}]=[\epsilon_{x_0}]$
\item The operation $*$ is associative.
\end{enumerate}
\end{exercise}
This finishes the proof that $\pi_1(X,x_0)$ is a group.
\end{proof}


\subsection{As a Functor}

Since loops are first of all continous maps, $\pi_1$ plays well with maps between topological spaces. Specifically, if $f:X \to Y$ is a continuous map and $\gamma$ a loop on $X$, then $f \circ \gamma$ is a loop on $Y$. And if $f(x_0)=y_0$, we obtain a function $\pi_1(f):\pi_1(X,x_0) \to \pi_1 (Y,y_0)$ defined by $[\gamma] \mapsto [f \circ \gamma]$.

\begin{exercise}
\label{functorPropertiesEx}
Let $f:X \to Y$ and $g:Y \to Z$ be continuous maps sending $x_0 \mapsto y_0 \mapsto z_0$.
\begin{enumerate}
\item Prove that $\pi_1(f): \pi_1(X,x_0) \to \pi_1(Y,y_0)$ is a group homomorphism. \textit{Hint: First show that $f \circ (\delta * \gamma) = (f \circ \delta) * (f \circ \gamma)$.}
\item Prove that $\pi_1(Id_X) = Id_{\pi_1(X,x_0)}$. \textit{Hint: First show that $Id_X \circ \gamma = \gamma$.}
\item Prove that $\pi_1(g \circ f) = \pi_1(g) \circ \pi_1(f)$. \textit{Hint: Compare their outputs for a general input.}
\end{enumerate}
\end{exercise}

Thus $\pi_1$ is a ``gadget'' that assigns to any pointed topological space $X$, a group $\pi_1(X, x_0)=:\pi_1(X)$, and by Exercise \ref{functorPropertiesEx} assigns to any continuous map $f:X \to Y$, a group homomorphism $\pi_1(f):\pi_1(X) \to \pi_1(Y)$ which preserves composition of functions and identities.

Such a ``gadget'' is called a \textbf{functor} $\pi_1:\cT \to \cG$ from the category $\cT$ of pointed topological spaces and continuous maps, to the category $\cG$ of groups and group homomorphisms. (This is really just fancy terminology - don't be frightened!)

From this (somewhat ``high-level'' information), we can prove that fundamental groups are an invariant of homeomorphism classes.

\begin{proposition}
\label{functorPropsAtWork}
Let $X,Y$ be topological spaces. Then $X$ homeomorphic to $Y$ implies $\pi_1(X)$ isomorphic to $\pi_1(Y)$, i.e. $\pi_1(X) \cong \pi_1(Y)$.
\end{proposition}
\begin{proof}
Note that $X$ homeomorphic to $Y$ iff there are continuous maps $f:X \to Y$ and $g:Y \to X$ such that $g \circ f = Id_X$ and $f \circ g = Id_Y$. Hitting the first equality of maps with $\pi_1$ gives that $\pi_1(g \circ f) = \pi_1(Id_X)$. But $\pi_1(g \circ f) = \pi_1(g) \circ \pi_1(f)$ and $\pi_1(Id_X)=Id_{\pi_1(X)}$. Hitting the second equality, $f \circ g = Id_Y$ with $\pi_1$ similarly yields $\pi_1(f) \circ \pi_1(g) = Id_{\pi_1(Y)}$. Thus $\pi_1(X) \cong \pi_1(Y)$.
\end{proof}

In fact, fundamental groups are very loose invariants. They are not only constant in homeomorphism classes, but also in homotopy classes!

\begin{exercise}
Suppose that $f,g:X \to Y$ are continuous maps. Show that if $f$ is homotopic to $g$, then $\pi_1(f) = \pi_1(g)$. Use this fact to show that if $X$ is homotopy equivalent to $Y$, then $\pi_1(X) \cong \pi_1(Y)$. \textit{Hint: For the second part, mimic the argument of Proposition \ref{functorPropsAtWork}.}
\end{exercise}

\begin{remark}
The information of a base point is often unnecessary when considering fundamental groups. Precisely, if $X$ is path-connected and $x_0,x_1 \in X$, then $\pi_1(X,x_0) \cong \pi_1(X,x_1)$. However, the isomorphism relies on a non-canonical choice: Choose $\sigma$ \textit{any} path from $x_1$ to $x_0$, then the function $\Phi_\sigma: \pi_1(X,x_0) \to \pi_1(X,x_1)$ defined by $[\gamma] \mapsto [\sigma^{-1}*\gamma*\sigma]$ is a group isomorphism. (Note that, as a loop, $\sigma^{-1}*\gamma*\sigma$ is not well-defined, but the \textit{class} $[\sigma^{-1}*\gamma*\sigma]$ is well-defined.)
\end{remark}

\subsection{Examples}

The purpose of this section is to introduce you to a few different fundamental groups. We will resort to hand-waving throughout.

\begin{enumerate}
\item Since $\pi_1(\{pt\}) = \{e\}$, it follows that $X$ contractible implies $\pi_1(X) = \{e\}$.
\item The sphere $S^2$ is not contractible, but any loop on the sphere can be ``pulled in,'' i.e. is homotopic to $\epsilon_{x_0}$. Thus $\pi_1(S^2) = \{e\}$. Any path-connected space $X$ such that $\pi_1(X) = \{e\}$ is called \textbf{simply connected}.
\item Any loop on the circle $S^1$ is homotopic to a loop that simply travels around the circle clock-wise (or counter clock-wise) a certain number of times. Furthermore, each loop can be seen as multiple iterations of a loop which travels around only once. Thus $\pi_1(S^1) = \bZ\ (=\,$the free group on 1 generator, $\bF_1$).
\item Take $g$ circles, label a point on each one, and glue them  together at the chosen points. We call the resulting space a flower graph.
\missingfigure{Figure 30 - A flower graph with 4 petals (p22 Amanda's notes)}
\begin{figure}
\label{flowerGraphPic}
\end{figure}
The loops on such a graph are generated by the simple loops which go around a particular ``petal'' once, and there are no relations between them. Thus, if the graph $\Gamma$ has $g$ petals, then $\pi_1(\Gamma) = \bF_g$, the free group on $g$ generators.
\item Let $\Gamma$ be a connected graph. By contracting a spanning tree on $\Gamma$ we see that $\Gamma$ is homotopy equivalent to a flower graph with a certain number of petals, $g$.
\missingfigure{Figure 31 - A graph before and after contracting spanning tree (p22 Amanda's notes)}
\begin{figure}
\label{contractSpanTreePic}
\end{figure}
In fact, the number $g$ is the genus of the graph and is given by the formula $1-g=\chi(\Gamma)=V-E$, where $V$ is the number of vertices of $\Gamma$ and $E$ the number of edges. Thus $\pi_1(\Gamma)=\bF_{E-V+1}$.
\item A sphere with one point removed $S':=S^2-\{pt\}$ is contractible, so $\pi_1(S') = \{e\}$. A sphere with two points removed $S''$ is homeomorphic to a circle,  so $\pi_1(S'') = \bF_1$. A sphere with three points removed $S'''$ is homeomorphic to a flower graph with two petals, so $\pi_1(S''') = \bF_2$.
\item Let $T$ be the torus defined as the identification space $T=[0,1]_x \times [0,1]_y / \sim$ where we identify $(0,y) \sim (1,y)$ and $(x,0) \sim (x,1)$. There are two fundamental loops $\alpha,\beta$ on $T$ and they satisfy a relation: Figure \ref{torusHomotopyPic} illustrates a homotopy between the loops $\beta * \alpha$ and $\alpha * \beta$.
\missingfigure{Figure 32 - LHS: torus with loops, RHS: homotopy square (p23 Amanda's notes)}
\begin{figure}
\label{torusHomotopyPic}
\end{figure}
Thus $\pi_1(T) \cong \la a,b | ab=ba \ra \cong \bZ \oplus \bZ$.
\item A torus with one point removed $T'$ is homeomorphic to a flower graph with two petals, so $\pi_1(T') = \bF_2$. A torus with two points removed $T''$ is homeomorhpic to a flower graph with 3 petals, so $\pi_1(T'')=\bF_3$.
\end{enumerate}

\begin{exercise}
Convince yourself of the claims in all examples in this section.
\end{exercise}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Covering Spaces}

Coverings are maps which are locally homeomorphisms. Because of this, one can take a path in the target space and  ``lift'' it to a path in the domain space consisting of pre-images\todo{keep hyphen?} of the original path. By considering loops, one can relate the fundamental groups of the spaces, and in fact a rich theory relating coverings and fundamental groups exists.

\begin{definition}
A \textbf{covering} is a continuous, surjective map $p:Y \to X$ such that for every $x \in X$ and each $y_i \in p^{-1}(x)$ there exist disjoint neighborhoods $U_x, V_{y_i}$ such that each restriction of $p$ to $V_{y_i}$ is a homeomorphism $p:V_{y_i} \to U_x$.
\end{definition}

\missingfigure{Figure 33 - schematic picture of a covering}
\begin{figure}
\label{coveringPic}
\end{figure}

For any covering $p:Y \to X$ and $x \in X$ we have that $p^{-1}(x)$ is a discrete set. Under a few mild assumptions, $|p^{-1}(x)|$ is the same (and finite) for all $x \in X$ - in this case we call $|p^{-1}(x)|$ the \textbf{degree} of $p$ (compare with Theorem \ref{degreeThm}).
\todo[inline]{I am a bit vague in this paragraph as, I believe that to properly introduce degree we'd have to use words like locally path-connected and such that come for free when we're dealing with manifolds.}


\begin{example}
Let $f:Y \to X$ be a holomorphic degree $d$ map of Riemann Surfaces with ramification locus $R \subset Y$ and branch locus $B \subset X$. Then the restriction $f:(Y-R) \to (X-B)$ is a covering of degree $d$.
\end{example}

\begin{exercise}
Let $X$ be a topological space and $X \sqcup X$ be the disjoint union of $X$ with itself. Show that the natural projection $\pi:X \sqcup X \to X$ is a covering. What is the degree of $\pi$? This example can be generalized to $d$ disjoint copies of $X$ (in the case $d=1$ we have $\pi=Id_X$).
\end{exercise}

\begin{example}
Identify the circle $S^1$ with the complex unit circle $S^1 = \{z \in \bC | |z|=1\}$.
\begin{itemize}
\item The map $p:S^1 \to S^1$ defined by $p(z)=z^4$ is a covering  of degree 4. One similarly has a covering for each map $p(z)=z^d$ where $d \in \bN$.
\item Define the map $\tilde{p}:\bR \to S^1$ by $p(t) = e^{2\pi i t}$. Then $\tilde{p}$ is a covering with each set $\tilde{p}^{-1}(z)$ in bijection with $\bZ$.
\end{itemize}
\end{example}





\subsection{Connection to $\pi_1$}

Coverings and fundamental groups are intimately connected. Given a covering $p:Y \to X$ and a loop $\gamma:[0,1] \to Y$, one can ``push-forward'' the loop to obtain a new loop $p \circ \gamma$ on $X$. Conversely, since $p$ is locally a homeomorphism, one can ``pull-back'' or ``lift'' a loop on $X$ to a path on $Y$ with an appropriately chosen starting point; however, the lift may just be a \textit{path}, as the loop may ``open up'' in the lift.

Here we present the crucial lifting lemmas, then sketch a little of the connection present between coverings and fundamental groups.

\begin{definition}
\label{liftDef}
Given a covering $p:Y \to X$ and a path $\alpha:[0,1] \to X$, a \textbf{lift} of $\alpha$ is a path $\tilde{\alpha}:[0,1] \to Y$ such that $p \circ \tilde{\alpha} = \alpha$.
\end{definition}

\begin{lemma}[Paths lift]
\label{pathsLiftLemma}
Let $p:Y \to X$ be a covering. If $\alpha:[0,1] \to X$ is a path such that $\alpha(0) = x_0$ and $y_0 \in p^{-1}(X) \subset Y$, then there exists a unique lift $\tilde{\alpha}:[0,1] \to Y$ such that $\tilde{\alpha}(0) = y_0$.
\end{lemma}
\begin{proof}[Sketch of Proof]
We build the lift piece-by-piece. Choose a neighborhood $U_{x_0}$ and corresponding $V_{y_0}$ such that the restriction $p:V_{y_0} \to U_{x_0}$ is a homeomorphism - in particular, the restriction has an inverse, $p^{-1}_0$.

Suppose that for $0<s<s_1$ we have $\alpha(s) \in U_{x_0}$ but $\alpha(s_1) \notin U_{x_0}$. Then for $0<s<s_1$ define the lift $\tilde{\alpha}(s) = p^{-1}_0(s)$.

We may now repeat this process using $x_1:=\alpha(s_1)$ instead of $x_0$ to extend the lift to $s_2>s_1$, and we may continue until we have a full lift $\tilde{\alpha}:[0,1] \to Y$. (Note: the compactness of $[0,1]$ is what guarantees we can reach $s=1$ in a finite number of steps.)
\end{proof}

\missingfigure{Figure 34 - two pieces of path lift}
\begin{figure}
\label{pathLiftingPic}
\end{figure}



Using a similar ``piece-together-as-you-go'' strategy, we can also lift homotopies of paths.

\begin{lemma}[Homotopies of paths lift]
\label{homotopiesLiftLemma}
Let $p:Y \to X$ be a covering and $H:[0,1]_s \times [0,1]_t \to X$ a homotopy between the paths $\alpha,\beta:[0,1]_s \to X$. Let $x_0 = \alpha(0) = H(0,0)$ and $y_0 \in p^{-1}(x_0) \subset Y$. Then there exists a unique lifting $\tilde{H}:[0,1]_s \times [0,1]_t \to Y$ of $H$ such that $\tilde{H}(0,0) = y_0$. (By ``lifting of $H$'' we mean that $p \circ \tilde{H} = H$.)
\end{lemma}
\begin{proof}[Sketch of Proof]
Again we build the lift piece-by-piece. Choose a neighborhood $U_{x_0}$ and corresponding $V_{y_0}$. Now there is a ``chunk'' of $H$ which lies in $U_{x_0}$, and we define $\tilde{H}$ on this chunk as $H$ composed with the appropriate inverse of (the restriction of) $p$. By considering other neighborhoods $U \subset X$ we can extend the domain of $\tilde{H}$ until we have defined it over all of $[0,1] \times [0,1]$. (Here it is the compactness of $[0,1] \times [0,1]$ which allows the process to terminate in a finite number of steps.)
\end{proof}

A consequence of the uniqueness in Lemma \ref{homotopiesLiftLemma} is that two homotopic loops will lift to paths with the same start-points and end-points.

\begin{corollary}
\label{sameStartEnd}
Let $p:Y \to X$ be a covering. If $\alpha,\beta$ are loops in $X$ which are homotopic with respect to their base point $x_0$, then their lifts satisfy $\tilde{\alpha}(0)=\tilde{\beta}(0)$ and $\tilde{\alpha}(1)=\tilde{\beta}(1)$.
\end{corollary}

Corollary \ref{sameStartEnd} in particular gives that a class of loops $[\alpha] \in \pi_1(X,x_0)$ has well-defined start and end-points of lifts.

\begin{exercise}
\label{pushForwardInjective}
Let $p:Y \to X$ be a covering and choose $x_0 \in X$ and $y_0 \in p^{-1}(x_0) \subset Y$. Denote by $p_*$ the ``push-forward'' homomorphism $p_*:\pi_1(Y,y_0) \to \pi_1(X,x_0)$ defined by $p_*([\gamma]) = [p \circ \gamma]$. Show that $p_*$ is injective. \textit{Hint: Show that the ker$(p_*) = \{\epsilon_{x_0}\}$.}
\end{exercise}

Exercise \ref{pushForwardInjective} shows that for any covering $p:Y \to X$ we have $\pi_1(Y)$ is a subgroup of $\pi_1(X)$ (via $p_*$). It is the subgroup of $\pi_1(X)$ consisting of the (classes of) loops whose lifts are loops.

In fact, there is a bijection between subgroups of $\pi_1(X)$ and (isomorphism classes of) coverings of $X$ (one considers quotient spaces of the ``universal cover'' of $X$ via an action by the chosen subgroup to go from left to right). One can also consider lifts of maps with domain different from the topological space [0,1]. The interested reader can consult \ref{} for details.

















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%


\chapter{Counting Maps}
\label{countingMaps}


\section{Hurwitz Numbers as Counting Maps}

``How many \rule{.7in}{0.4pt} are there?'' is a simple and natural question which often leads to rich mathematics. From comparing infinite sets (does $\bZ$ or $\bQ$ have ``more'' elements?), to counting the roots of polynomials (should the root of $p(x)=x^2$ at $x=0$ count as one root or two?), enumerating a certain class of ``things'' is often an interesting endeavor.

Hurwitz theory counts the number of holomorphic maps between Riemann Surfaces. We have seen that these maps have a strong structure (e.g. they are either constant or onto, and have $z\mapsto z^k$ local expression) and so perhaps it is not surprising that there are not that many of them. More specifically, after choosing invariants (genera of domain and target, degree and ramification of map) so that the Riemann-Hurwitz Formula is satisfied, there are only a \textit{finite} number of maps whose domain and target have the specified genera, and have the specified degree and ramification profile.

As with the example of counting roots of polynomials (we \textit{do} want to count the root of $p(x)$ as a ``double root'') we want to be careful how we count such maps. For us this means that we do not want to double-count \textit{isomorphic} maps, and we want to weight the maps we do count by their \textit{automorphisms}. So far isomorphisms and automorphisms have described relationships between Riemann Surfaces, but we now use these terms to describe relationships between \textit{maps} of Riemann Surfaces.

\begin{definition}
Two holomorphic maps of Riemann Surfaces $f:X \to Y$ and $g:\tilde{X} \to Y$ are called isomorphic, if there is an isomorphism $\phi:X \to \tilde{X}$ such that $f=g \circ \phi$. An automorphism of $f:X \to Y$ is an automorphism $\psi:X \to X$ such that $f = f \circ \psi$. The group of automorphisms of $f$ is denoted $\Aut(f)$.
\end{definition}

Note that if $f$ and $g$ are isomorphic maps via $\phi$, then $\phi$ respects pre-images, i.e. for any $y\in Y$ the map $\phi$ gives a bijection $\phi:f^{-1}(y) \to g^{-1}(y)$.

\begin{exercise}
\label{involutionOfEllCurve}
Consider a curve $E_1 = V( y^2 - (x-a_1)(x-a_2)(x-a_3)) \subset \bC^2$ with the $a_i \in \bC$ distinct. From Example \ref{ellipticCurveExample} we know that the map $\pi: E_1 \to \bC$ defined by $(x,y) \mapsto x$ is a holomorphic map. Show that the map $\sigma:E_1 \to E_1$ defined by $(x,y) \mapsto (x, -y)$ gives an automorphism of $E_1$.
\end{exercise}

\begin{exercise}
Show that $\Aut(f)$ is a group under the operation of function composition.
\end{exercise}

When enumerating maps of Riemann Surfaces, we only want to count each isomorphism class of maps once (as an analogy, if we were counting groups of order two, we would not want to count $(\bZ/{2\bZ}, +)$ and $(\{-1,1\}, \times)$ as different groups).

Also, given a representative $f$ of an isomorphism class of maps, we want to weight its addition to our count by the size of $\Aut(f)$. Using the philosophy that more automorphisms should make something count for less, we will divide by $|\Aut(f)|$. (Note that this contrasts with the polynomial root example, where we have special cases where a root counts for more, but never less.) After two quick definitions, we are ready to formally define Hurwitz numbers.

\begin{definition}
Let $d>0$ be an integer. A \textbf{partition} of $d$ is a tuple of positive integers $\eta = (k_1, k_2, \ldots)$ such that $d = \sum k_i$ and $k_i \geq k_{i+1}$ for all $i$. For example, $(3)$ and $(2,1)$ are both partitions of $d=3$. We may equivalently define a partition of $d$ as a \textit{subset} $\eta \subset \bZ_{>0}$ such that $\sum_{k\in \eta} k = d$.
\end{definition}

\begin{exercise}
Write down all the partitions of $3, 4$ and $5$.
\end{exercise}

\begin{definition}
Let $f:X \to Y$ be a holomorphic map of Riemann Surfaces of degree $d$, and let $y \in Y$ and $f^{-1}(y) = \{x_1,\ldots,  x_n\}$. We call the set $\{k_{x_1},\ldots, k_{x_n}\}$ the \textbf{ramification profile} of $f$ at $y$. Note that the ramification profile of $f$ at $y$ is a partition of $d$.

If the  ramification profile of $f$ at $y$ is $(2)$ or $(2,1,\ldots,1)$, then $f$ is said to have \textbf{simple ramification} at $y$.
\end{definition}

\begin{exercise}
Consider the holomorphic map $p:\PoneC \to \PoneC$ given by the polynomial $p(x) = x^3$. Write the ramification profile of $p$ at $0, 9, 1+i$ and $\infty$.
\end{exercise}

\begin{definition}[Hurwitz number]
\label{hurwitzNumberAsMaps}
Let $Y$ be a connected, compact Riemann Surface of genus $h$. Choose points $b_1, \ldots, b_n \in Y$ and let $\lambda_1,\ldots,\lambda_n$ be partitions of a positive integer $d$. We define the \textbf{Hurwitz number} as
\begin{equation}
\label{hurwitzNumberAsMapsEqn}
H^d_{g\to h}(\lambda_1,\ldots,\lambda_n) = \sum_{[f]} \frac{1}{|\Aut(f)|}
\end{equation}

\noindent where the sum in \ref{hurwitzNumberAsMapsEqn} runs over each isomorphism class of $f:X \to Y$ where
\begin{enumerate}
\item $f$ is a holomorphic map of Riemann Surfaces
\item $X$ is connected, compact, and has genus $g$
\item the branch locus of $f$ is $B=\{b_1,\ldots,b_n\}$
\item the ramification profile of $f$ at $b_i$ is $\lambda_i$

\end{enumerate}
\noindent We call a map $f$ satisfying 1-4 a \textbf{good map} for the Hurwitz number.
\end{definition}


Note that if the invariants $g, h, d, r, \lambda_1, \ldots, \lambda_n$ do not satisfy the Riemann-Hurwitz Formula, then $H^d_{g\to h}(\lambda_1,\ldots,\lambda_n) = 0$.

\section{First Examples of Hurwitz Numbers}
\begin{example}
\label{Hd00dd}
Let $Y=\PoneC$ and set $b_1 = 0, b_2 = \infty$. Choose $d>0$ and let $\lambda_1 = \lambda_2 = (d)$. We compute $H^d_{0\to 0}((d),(d))$. (Take a moment to verify that these invariants satisfy the Riemann-Hurwitz Formula.)

Example \ref{xSquaredOnP1C} shows that $p(x) = x^d$ gives a holomorphic map $p:\PoneC \to \PoneC$ (actually it only treats the case $d=2$ but the general case is shown in exactly the same way). Moreover, $p$ is ramified only over $0$ and $\infty$ and has ramification profile $(d)$ there. Thus we count $p$ when computing the Hurwitz number, i.e. $p$ is a ``good map.'' We will show that any good map $f:X \to \PoneC$ is isomorphic to $p$, so that $p$ is the only map we need to consider for computing the Hurwitz Number.

A fact that we will not prove is that any Riemann Surface of genus 0 is isomorphic to $\PoneC$. Thus a good map is first of all a holomorphic map $f:\PoneC \to \PoneC$ and so $f$ is a rational function by Remark \ref{rationalFunctionsAreP1Maps}.

A good map has degree $d$ and is ramified only at $r_1,r_2$ where $f(r_1) = 0, f(r_2) = \infty$, both with ramification index $d$. Assuming that neither $r_1$ nor $r_2$ is $\infty$, we have $f = b(x-r_1)^d/(x-r_2)^d$ for some $0\neq b \in \bC$. (We leave the case that one of $r_1,r_2$ is $\infty$ as an exercise.)

To show that the map $f$ is isomorphic to $p$, we must construct an isomorphism of Riemann Surfaces $\phi:\PoneC \to \PoneC$ such that $f = p \circ \phi$. Thus $\phi$ is a M\"{o}bius transformation (see Exercise \ref{mobiusTransExercise}) which, in particular, sends $r_1 \mapsto 0$ and $r_2 \mapsto \infty$, i.e. we have $\phi = a(x-r_1)/(x-r_2)$ for some $0\neq a \in \bC$.

The equation $f = p \circ \phi$ is
\[
b\frac{(x-r_1)^d}{(x-r_1)^d} = \left(a\frac{x-r_1}{x-r_1}\right)^d
\]
which is satisfied by any choice of $a:=b^{1/d}$. Thus $f$ is isomorphic to $p$ via $\phi$, and we have only one isomorphism class of good maps to consider to compute the Hurwitz number. What's left is to compute $|\textbf{Aut}(p)|$.

\begin{exercise}
\label{autOfP}
Let $p:\PoneC \to \PoneC$ be the (above) map given by $p(x) = x^d$. Show that $\Aut(p) = \{ \tilde{\phi}= cx | c = 1^{1/d}\}$.
\end{exercise}
Exercise \ref{autOfP} implies that $|\textbf{Aut}(p)| = d$ and so $H^d_{0\to 0}((d),(d)) = 1/d$.
\end{example}

\noindent\hrulefill

\begin{example}
\label{ellCurveMapViaLifts}
Let $E$ be an elliptic curve. In Example \ref{ellipticCurveExample} we saw that $E$ has a degree 2 projection $\pi:E \to \PoneC$, and Exercise \ref{ellipticCurveRamificationEx} shows that $E$ has genus 1 and that $f$ is ramified at $4=2*1+2$ points. Thus $\pi$ is a good map for the Hurwitz number $H^2_{1\to 0}((2),(2),(2),(2))=:H^2_{1\to 0}((2)^4)$, which we now compute.

We state without proof that any good map for this Hurwitz number is isomorphic to $\pi$, so all we must determine is $\Aut(\pi)$. We show via path lifting that any $\phi \in \Aut(f)$ is completely determined by its action on an unramified $x \in E$.

Let $\phi:X \to Y$, with $X=Y=E$, be an automorphism of $f$ and let $R\subset X$ be the ramification locus of $f$. If $x \in R$ then we must have $\phi:x \mapsto x$, since $\pi^{-1}(\pi(x)) = \{x\}$.

\begin{exercise}
\label{constructingAutViaLifting}
Choose an $x_0  \in E - R$ and set $\phi(x_0)=p$ where $p \in \pi^{-1}(\pi(x_0))$. Let $x_0 \neq x \in X - R$, and let $\gamma:[0,1] \to X - R$ be any path from $x_0$ to $x$, i.e. $\gamma(0) = x_0$ and $\gamma(1)=x$.
\begin{enumerate}
\item Show that $\tilde{\gamma} = \phi \circ \gamma$ where $\tilde{\gamma}$ is the lift of the path $\pi \circ \gamma$ to $Y$ such that $\tilde{\gamma}(0) = p$.

\item Conclude that $\tilde{\gamma}(1) = \phi(x)$.
\end{enumerate}
\end{exercise}

Exercise \ref{constructingAutViaLifting} shows that once $\phi(x_0)=p$ is chosen for an unramified $x_0$, the images of all other unramified $x\in X$ are determined - to determine $\phi(x)$ follow these steps: (1) take any path $\gamma$ from $x_0$ to $x$ in $X$, (2) push the path down to $\PoneC$ via $\pi$, (3) lift that path to a path $\tilde{\gamma}$ in $Y$ starting at $p$, (4) wherever $\tilde{\gamma}$ ends is/must be $\phi(x)$. And since there is no choice for the image of a ramification point, $\phi$ is then completely determined.

Now, for $x \in E - R$ we have $|\pi^{-1}(\pi(x))| = 2$, so there are at most two automorphisms of $\pi$ (one that sends $x \mapsto x$ and one that sends $x \mapsto y \neq x$). Since the identity map $I_E$ and the involution $\sigma$ (which can be obtained by extending the automorphism $\sigma$ given in Exercise \ref{involutionOfEllCurve}) are two different automorphisms of $\pi$ we have $|\Aut(\pi)|=2$ and thus $H^2_{1\to 0}((2)^4) = 1/2$.
\end{example}

\todo[inline]{Is there a nice way to see that any other good map $f$ is isomorphic to our $\pi$?}

\todo[inline]{Would it be helpful at all to mention the fact that our arguments in Exercise \ref{constructingAutViaLifting} show that any automorphism of a map of Riemann Surfaces $f:X \to Y$ is completely determined ON UNRAMIFIED POINTS by its action on one unramified $x$? or would that just be confusing and unnecessary? --UPDATE-- I think this is unnecessary, as this idea is now pointed at (and hopefully discovered) in Exercise \ref{partitionViaAut} part 1 below}



\todo[inline]{I'd like to move the Riemann Existence theorem to this Chapter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Counting Monodromy Representations}
\label{countingMonodromyReps}
Considering Hurwitz numbers as counting holomorphic maps (Definition \ref{hurwitzNumberAsMaps}) is a beautiful and geometric definition. However, it is very impractical for computation - even relatively ``simple'' Hurwitz numbers are beyond our reach. We would like to translate our problem from counting holomorphic maps to counting something else.

For us, ``something else'' will be monodromy representations. These somehow provide gluing instructions for constructing a topological cover of a base space $Y$. Riemann's Existence Theorem allows us to then complete our cover to a map of Riemann Surfaces, with ramification prescribed by the monodromy representation.

Before introducing monodromy representations, we first state Riemann's Existence Theorem.

%
%We have seen in Section \ref{structureOfMaps} that if $f:X \to Y$ is a holomorphic map of Riemann Surfaces of degree $d$ with ramification locus $R \subset X$, then $f^\circ: X-R \to Y-B$ is a topological covering map of degree $d$. Riemann's Existence Theorem (Theorem \ref{riemannsExistenceTheorem}) gives an inverse relationship, so that (in the case of compact Riemann Surfaces) counting holomorphic maps is the \textit{same} as counting topological covers. Later we will see that counting topological cover is the same as counting monodromy representations - a notion well-suited for computations.


\begin{theorem}[Riemann's Existence Theorem]
\label{riemannsExistenceTheorem}
Let $Y$ be a Riemann Surface and $X^\circ$ a topological space. Assume that there are a finite number of points $y_1,\ldots, y_b \in Y$ and a function $f^\circ: X^\circ \to Y-\{y_1,\ldots,y_b\}$ which is a topological cover. Then there exists a unique (up to bi-holomorphism) compact Riemann Surface $X$ which contains $X^\circ$ as a dense open set (in fact $X$ is $X^\circ$ plus a finite number of points) such that $f^\circ$ extends to $f:X \to Y$ a holomorphic map of Riemann Surfaces.
\end{theorem}
%\begin{proof}[Sketch of the Proof]
%Induce a complex structure on $X^\circ$ by composing the covering map (suitably restricted) with local coordinate charts of $Y$. Consider neighborhoods around each $y_i$ and use to see what points to add to $X^\circ$.
%\end{proof}
\todo[inline]{Should we include a sketch of the proof? Or just leave it as a black box?}
%\todo[inline]{We should maybe mention something about uniqueness up to isomorphism - is there anything helpful to say to this effect?}


\section{From Maps to Monodromy}
\label{fromMapsToMonodromy}

We will work our way to defining monodromy representation by first considering how, given a holomorphic map, loops in the base space permute the preimages of a point outside of the branch locus.

%Let $f:X \to Y$ be a holomorphic map of connected Riemann Surfaces, with $g_X=g, g_Y = h$. Say that $f$ has degree $d$ with branch locus $B=\{b_1,\ldots,b_n\} \subset Y$. Choose a $y_0 \notin B$ and consider a loop $\gamma:[0,1] \to Y-B$ starting at $y_0$ which goes around $b_1$ (but no other $b_i$).
Let $f:X \to Y$ be a degree $d$ holomorphic map of connected Riemann Surfaces with branch locus $B=\{b_1,\ldots,b_n\} \subset Y$. Choose a $y_0 \notin B$ and consider a small loop $\gamma:[0,1] \to Y-B$ starting at $y_0$ which goes around $b_1$ (but no other $b_i$) as shown in Figure \ref{liftingAGenericLoopPic}.

Choosing a preimage $x \in f^{-1}(y_0)$, we may lift $\gamma$ to a path $\tilde{\gamma}_x$ in $X$ starting at $x$. Since $\gamma(1)=y_0$, the lifted path $\tilde{\gamma}_x$ ends at a  preimage of $y_0$ (possibly different from $x$).


\missingfigure{Figure 14 - lifting a generic loop}
\begin{figure}
\label{liftingAGenericLoopPic}
\end{figure}


\begin{example}
\label{quarterLoopLift}
Let $f:\bC \to \bC$ be defined by $f(x) = x^4$. Choose $y_0 = 1$ and consider the loop $\gamma(t) = \exp(2\pi t i)$. The lift $\tilde{\gamma}_1$ of $\gamma$ which starts at $x=1$ ends at $x=i$. In fact, $\tilde{\gamma}_1(t) = \exp(\frac{\pi}{2}t i)$.
\end{example}

Lifting the loop $\gamma$ to a path starting at $x \in f^{-1}(y_0)$ thus yields a function $\sigma_\gamma:f^{-1}(y_0) \to f^{-1}(y_0)$ defined by $\sigma_\gamma(x) = \tilde{\gamma}_x(1)$.

\begin{exercise}
\label{loopsPermutePreimages}
Show that the function $\sigma_\gamma$ is a bijection. \textit{Hint: since $|f^{-1}(y_0)|=d<\infty$ you need only show that $\sigma_\gamma$ is injective.}
\end{exercise}
%idea: if a lift leads from a to b, then the reverse lift leads from b to a. Thus, if two lifts lead to the same spot, then the reverse lift shows that their starting points must be =

Exercise \ref{loopsPermutePreimages} shows that the loop $\gamma$ yields a permutation $\sigma_\gamma$ of the preimages of $y_0$. To write $\sigma_\gamma$ as an explicit element of the symmetric group $S_d$, we label the $d$ preimages of $y_0$ with the numbers $1,2,\ldots, d$. If $x\in f^{-1}(y_0)$ we write $x^\star$ to denote the number assigned to $x$. Then $\sigma_\gamma \in S_d$ is given by $\sigma_\gamma(x^\star) = \tilde{\gamma}_x(1)^\star$.


\missingfigure{Figure 15 - covering map with lifted paths giving a permutation of the preimages}
\begin{figure}
\label{permutationFromLiftingPic}
\end{figure}


\begin{exercise}
\label{quarterLoopExercise}
Let $f, y_0$ and $\gamma$ be as in Example \ref{quarterLoopLift}.
\begin{enumerate}
\item Write out the function $\sigma_\gamma:f^{-1}(1) \to f^{-1}(1)$.
\item Choose a labeling 1,2,3,4 for the elements of $f^{-1}(1)$ and use your labeling to write $\sigma_\gamma \in S_d$ in function notation and in cycle notation.
\end{enumerate}
\end{exercise}

Let us call the small loop $\gamma$ starting at $y_0$ and winding around $b_1$ by the name $\gamma =: \rho_1$. Similarly, we have small loops $\rho_k$ around each $b_k$. For each of these, and in fact, for \textit{any} loop $\gamma$ starting at $y_0$ we obtain a permutation $\sigma_{\gamma}$.

The permutation $\sigma_\gamma$ actually only depends on the homotopy class of the loop $\gamma$, and the permutation associated to the concatenation of two loops is the composition of the associated permutations: $\sigma_{\gamma \star \eta} = \sigma_\gamma \circ \sigma_\eta$. Thus a holomorphic map $f:X \to Y$ gives a \textit{group homomorphism} $\Phi:\pi_1(Y-B, y_0) \to S_d$ defined by $\Phi:\gamma \mapsto \sigma_\gamma$ (after choosing a labeling of the preimages of $y_0$) - we call such homomorphisms \textit{monodromy representations}.


\begin{definition}[Monodromy Representation]
Let $Y$ be a connected Riemann surface of genus $h$ let and $b_1,\ldots,b_n \in Y$. Let $\lambda_1,\ldots,\lambda_n$ be partitions of a positive integer $d$. Then a \textbf{monodromy representation} of type $(h,d,\lambda_1,\ldots, \lambda_n)$ is a group homomorphism $\Phi:\pi_1(Y-\{b_1,\ldots,b_n\}) \to S_d$ such that, if $\rho_k$ is the homotopy class of a small loop around $b_k$, then the permutation $\Phi(\rho_k)$ has cycle type $\lambda_k$. If in addition the subgroup $\Im \Phi \leq S_d$ acts transitively on the set $\{1,2,\ldots,d\}$ we say $\Phi$ is a \textbf{connected monodromy representation}.
\end{definition}

\begin{remark}
A few notes are in order:
\begin{enumerate}
\item Our suppression of a chosen basepoint $y_0$ for the fundamental group is justified since $Y-\{b_1,\ldots,b_n\}$ path-connected implies that any two basepoints will yield isomorphic fundamental groups.

\item A permutation whose cycle decomposition consists of cycles of length $\{l_1,\ldots,l_k\}$ is said to have has \textbf{cycle type} $\{l_1,\ldots,l_k\}$. For example, the permutation $(12)(45)(367) \in S_8$ has cycle type $\{3,2,2,1\}$.

\item If the holomorphic map $f$ has ramification profile $\lambda = \{l_1, \ldots, \l_k\}$ at $b_i \in Y$ then the permutation $\Phi(\rho_i) = \sigma_{\rho_i} \in S_d$ has cycle type $\lambda$. Compare this with Exercise \ref{quarterLoopExercise}, then spend a few minutes with a picture convincing yourself that the general statement is true.
\end{enumerate}
\end{remark}


\begin{example}
\label{monodromyOnPoneC}
We consider monodromy representations for $Y = \PoneC$. Choose a finite subset $B=\{b_1,\ldots,b_n\} \subset \PoneC$. The punctured sphere $\PoneC - B$ is homotopic a point with $n-1$ loops attached to it. (If this seems strange, take a moment to convince yourself of the $n=3$ case.)

\missingfigure{Figure 16 - point with two loops}
\begin{figure}
\label{pointWithTwoLoopsPic}
\end{figure}

The fundamental group of this space is the free group with $n-1$ generators $\gamma_1,\ldots,\gamma_n$. Thus, for a chosen $d$, a group homomorphism $\Phi: \pi_1(Y-B) \to S_d$ is given by a choice of images $\Phi(\gamma_k) \in S_d$ with no restrictions.

For an alternative view, choose $y_0$ ``far away'' from the $b_k$ (as in Figure \ref{pointWithTwoLoopsPic}) and let $\rho_k$ be a small loop starting at some $y_0$ around $b_k$. We may choose the images $\Phi(\rho_1),\ldots,\Phi(\rho_{n-1})$ with no restrictions. However, these choices determine $\Phi(\rho_n)$: the loop $\rho_{n} \star \rho_{n-1} \star \cdots \star \rho_1$ is homotopic to a loop around all the $b_k$. But this loop can then contract to a point along the opposite side of the sphere. Thus we must have $\Phi(\rho_n) \circ \cdots \circ \Phi(\rho_1) = e \in S_d$ (where $e = (1)$ is the identity permutation).
\end{example}

The monodromy representation $\Phi$ obtained from a holomorphic map $f$ depends on the (arbitrary) choice of labeling given to the elements of $f^{-1}(y_0)$.

\begin{exercise}
Let $f:X \to Y$ be a holomorphic map of degree $d$ and choose $y_0 \in Y$ not in the branch locus. Suppose two labelings $L_1,L_2:f^{-1}(y_0) \to \{1,2,\ldots, d\}$ differ by a permutation $\tilde{\sigma} \in S_d$, i.e. $L_2 = \tilde{\sigma} \circ L_1$. Describe the relationship between the associated monodromy representations $\Phi_1, \Phi_2$. \textit{Hints: Give yourself a simple example, then try to generalize it! Also, your stated relationship should involve $\tilde{\sigma}$.}
\end{exercise}

\section{Hurwitz Numbers as Counting Monodromy Representations}

Section \ref{fromMapsToMonodromy} shows that a holomorphic map (a choice of labeling) yields a monodromy representation $\Phi$. One can also go the other way: a monodromy representation can be used to construct a topological cover, then Riemann's Existence Theorem shows that this cover can be completed to a holomorphic map of Riemann Surfaces.

The idea to have in mind is that a monodromy representation gives ``gluing instructions'' which are applied to multiple copies of (subsets of) $\bC$. Example \ref{constructCoverOfP1} illustrates this idea.

\begin{example}
\label{constructCoverOfP1}
Let $Y = \PoneC$ and choose $y_0,b_1,b_2,b_3 \in \PoneC$ as in Figure \ref{slicedPoneCWithIdentPoly}. Let $\rho_k$ be a small loop around $b_k$ and define a (connected) monodromy representation $\Phi:\pi_1(Y-\{b_1, b_2, b_3\}, y_0) \to S_3$ by $\rho_1 \mapsto (123), \rho_2 \mapsto (13), \rho_3 \mapsto (12)$. (Recall from Example \ref{monodromyOnPoneC} that the images of two of the $\rho_k$ are unconstrained, but the last image is determined by $\Phi(\rho_3) \star \Phi(\rho_2) \star \Phi(\rho_1) = e$.)

\missingfigure{Figure 17 - sliced $\PoneC$ and homeomorphic identification polygon}
\begin{figure}
\label{slicedPoneCWithIdentPoly}
\end{figure}

Choose a point $p$ as in the figure and draw a line from $p$ to each of the $b_k$. Then $Y-\{b_1,b_2,b_3\}$ is homeomorphic to the identification polygon $P$ on the right in Figure \ref{slicedPoneCWithIdentPoly}.

We wish to construct a cover whose associated monodromy is our $\Phi$. The idea is that above each $y \neq b_k$ there will be three preimages, but above the $b_k$ there will be ramification. We construct our cover by taking three copies of the polygon $P$ (which we label $P_1, P_2, P_3$) and repeatedly using each $\rho_k$ together with $\Phi(\rho_k)$ to indicate how these polygons should be glued to each other.

\missingfigure{Figure 18 - sliced $\PoneC$ with glued patches above}
\begin{figure}
\label{gluingCoverOfPoneCPic}
\end{figure}

For example, label the points $y_1,y_2,y_3$ which correspond to $y_0$ in each respective polygon $P_k$  and consider lifting the loop $\rho_1$ starting at $y_1$. The lift will exit $P_1$ through the top-left side, and since we have $\Phi(\rho_1):1 \mapsto 2$ the lift will enter $P_2$ on the bottom-left side and end at $y_2$. This gives us the ``gluing instruction'' of identifying the top-left side of $P_1$ with the bottom-left side of $P_2$.

Lifting $\rho_1$ again, but now starting at $y_2$ yields a path which ends at $y_3$ (since $\Phi(\rho_1):2 \mapsto 3$) and gives a similar identification of sides for $P_2$ and $P_3$. Lifting $\rho_1$ once more, starting at $y_3$, brings us back to $y_1$ and gives an identification of sides between $P_3$ and $P_1$. See Figure \ref{gluingCoverOfPoneCPic} for an illustration.

\begin{exercise}
Discover the remaining identifications by repeated lifting $\rho_2$ and repeatedly lifting $\rho_3$.
\end{exercise}

We thus have a topological cover $\pi^\circ:X^\circ:=(\sqcup P_k /\sim) \to Y-\{b_1,b_2,b_3\}$ and by Riemann's Existence Theorem (Theorem \ref{riemannsExistenceTheorem}) there is a unique map of compact Riemann Surfaces $\pi:X \to Y$ which extends $\pi^\circ$.

\begin{exercise}
Show that the monodromy representation associated to $\pi:X \to Y$ (with our choice of $y_0$ and labeling $y_k^\star = k$) is the $\Phi$ given at the beginning of this example (Example \ref{constructCoverOfP1}).
\end{exercise}
\end{example}
\noindent\hrulefill

From a holomorphic map, we can construct a monodromy representation, and from a monodromy representation we can construct a holomorphic map. However, these are slightly off from being inverse constructions. Theorem \ref{monodromyHurwitzNumbersThm} gives the precise relationship between Hurwitz numbers and connected monodromy representations.

\begin{theorem}
\label{monodromyHurwitzNumbersThm}
Let $M$ be the number (literally, ``the size of the set'') of connected monodromy representations of type $(h,d,\lambda_1,\ldots,\lambda_n)$. The following equality holds
\[
H^d_{g\to h}(\lambda_1,\ldots,\lambda_n) = \frac{M}{d!}
\]
where $g$ is determined by the Riemann-Hurwitz Formula.
\end{theorem}

\todo[inline]{does the fact that a monodromy rep is a homomorphism guarantee that the $g$ determined through the RH Formula is an integer?}

Before walking through the proof of Theorem \ref{monodromyHurwitzNumbersThm}, let's get a little practice with its use.

\begin{exercise}
\label{Hd00ddMono}
Use Theorem \ref{monodromyHurwitzNumbersThm} to compute $H^d_{0\to 0}((d), (d))$ for $d>0$. Compare your answer with Example \ref{Hd00dd}. \textit{Hint: Example \ref{monodromyOnPoneC} discusses what monodromy representations for $Y=\PoneC$ look like.}
\end{exercise}


\begin{proof}[Sketch of the Proof of Theorem \ref{monodromyHurwitzNumbersThm}]
Given a connected monodromy representation of type $(h,d,\lambda_1,\ldots,\lambda_n)$, one can construct a good map for the Hurwitz number $H^d_{g\to h}(\lambda_1,\ldots,\lambda_n)$, where we write any simple ramification as a $\lambda_i$. (Example \ref{constructCoverOfP1} was an example of one such construction.)

On the other hand, given a good map $f:X \to Y$ for the Hurwitz number and a smooth point $y_0 \in Y$, there are $d!$ ways to label the preimages $f^{-1}(y_0)$. Each labelling $L_i:f^{-1}(y_0) \to \{1,2,\ldots,d\}$ yields an associated monodromy representation $\Phi_{L_i}$. However, different labellings can yield the same monodromy representation. Complete this next exercise before moving on.
\todo[inline]{Does $X$ connected imply that the associated mon rep $\Phi$ is a \textbf{connected} mon rep?}

\begin{exercise}
\label{labellingPreimagesEx}
Consider the map $p:\PoneC \to \PoneC$ given by $p(x)=x^3$, and choose $y_0 = 1$. Label the preimages of $y_0$ in all possible ways. How many distinct monodromy representations are produced by these labellings? Is there a natural way to relate the labellings that yield the same monodromy representation?
\end{exercise}

Automorphisms of the map $f$ can relate labellings to one another. Specifically, if $L$ is a labelling of the elements of $f^{-1}(y_0)$ and $\alpha \in \Aut(f)$, then we define the associated labelling $\alpha \bullet L := L \circ \alpha^{-1}$. Note that this means that if $L(x)=2$ and $\alpha:x \mapsto y$, then $(\alpha\bullet L)(y) = 2$.

\begin{exercise}
Go back to Exercise \ref{labellingPreimagesEx}. Determine which labellings are related by the action of some $\alpha \in \Aut(p)$.
\end{exercise}

\begin{exercise}
Let $f:X \to Y$ be a degree $d$ holomorphic map of connected Riemann Surfaces, and choose $y_0 \in Y$ a smooth point.

\begin{enumerate}
\item Show that the action $\alpha \bullet L = L \circ \alpha^{-1}$ for $\alpha \in \Aut(f)$ and $L:f^{-1}(y_0) \to \{1,2,\ldots,d\}$ a labelling is a \textit{left group action}.

\item Show that the action is \textit{free}, i.e. that $\alpha \bullet L = L$ implies $\alpha = I_X$, the identity map.
\end{enumerate}
\end{exercise}

We state without proof the vague fact that automorphisms of any holomorphic map $f$ act by cycling preimages around each ramification point. Conversely (and still vaguely), any prescribed cycling of preimages corresponds to a unique automorphism of $f$. One can put the precise statements underlying these vague ones together to prove the following.
\todo[inline]{Is this statement completely true? Does an automorphism always have $\alpha(x)=x$ if $x$ is a ramification point, or could it swap an $x$ and $y$ if they're both ramification points for the same branch point and share the same index?}

\begin{remark}
\label{autGivesSameRep}
The monodromy representations $\Phi_{L_i}, \Phi_{L_j}$ associated to the labellings $L_i, L_j$ (respectively) are equal iff $L_j = \alpha \bullet L_i$ for some $\alpha \in \Aut(f)$.
\end{remark}

Remark \ref{autGivesSameRep} implies that the action of $\Aut(f)$ partitions the $d!$ labellings of $f^{-1}(y_0)$ into blocks, where all labellings in a particular block yields the same monodromy representation. (If this statement seems cloudy to you, take a few minutes and make sense of it!)

\begin{exercise}
\label{partitionViaAut}
\begin{enumerate}
We determine the size of these partition blocks.

\item Let $f:X \to Y$ be a degree $d$ holomorphic map of connected Riemann Surfaces, and choose $x_0 \in X$ an unramified point. If $\alpha \in \Aut(f)$ has $\alpha(x_0) = x_0$, show that $\alpha = I_X$. \textit{Hint: Transfer ideas from Example \ref{ellCurveMapViaLifts} to show that $\alpha$ is determined on a large portion of $X$. Argue why $\alpha$ must agree with $I_X$ on this portion, then argue why $\alpha$ must agree with $I_X$ on all of $X$.}
\label{identifyImpliesIdentity}

\item Show that Remark \ref{autGivesSameRep} and Exercise \ref{partitionViaAut} part \ref{identifyImpliesIdentity} imply that the action of $\Aut(f)$ on the set of labellings of $f^{-1}(y_0)$ partitions the labels into blocks of size $|\Aut(f)|$.
\end{enumerate}
\end{exercise}

Exercise \ref{partitionViaAut} shows that the $d!$ labellings of the elements of $f^{-1}(y_0)$ yield $d!/|\Aut(f)| =: m_f$  distinct monodromy representations. (Note also that any map $g \cong f$ will yield these exact same monodromy representations, i.e. will contribute no new representations.)

\begin{exercise}
Let $M$ be the number of connected monodromy representations of interest (as in Theorem \ref{monodromyHurwitzNumbersThm}). Show that $M = \sum_{[f]} m_f$, where the sum is over all isomorphism classes of good maps and $m_f$ is defined in the paragraph directly above.
\end{exercise}

Finally, we have
\[
H^d_{g\to h}(\lambda_1,\ldots,\lambda_n) = \sum_{[f]} \frac{1}{|\Aut(f)|} = \sum_{[f]} \frac{m_f}{d!} = \frac{1}{d!}\sum_{[f]} m_f = \frac{1}{d!}M
\]
\end{proof}

\noindent\hrulefill

\begin{exercise}
Summarize to yourself the ``story'' of the proof of Theorem \ref{monodromyHurwitzNumbersThm}. (With a long proof, it's easy to understand the details, but miss the big picture - this exercise is designed to hopefully counteract that tendency.)
\end{exercise}


\begin{remark}
The transitivity requirement in the definition of connected monodromy representations insures that the associated Riemann Surface constructed is connected. If we instead count monodromy representations, then a theorem analogous to Theorem \ref{monodromyHurwitzNumbersThm} allows us to count (possibly) \textbf{disconnected Hurwtiz covers}. Specifically, let $M^\bullet$ be the number of (not necessarily connected) monodromy representations of type $(h,d,\lambda_1,\ldots,\lambda_n)$. Then we have $H^{d\bullet}_{g\to h}(\lambda_1,\ldots,\lambda_n) = \frac{M^\bullet}{d!}$, where the Hurwitz number $H^\bullet$ is defined in the same was as standard (henceforth ``\textbf{connected}'') Hurwitz numbers, but the domain is allowed to be disconnected. (Note that we will use $H$ (resp. $H^\bullet$) as shorthand for a specific connected (resp. disconnected) Hurwitz number when the reference is clear from the context.)
\end{remark}

\begin{exercise}
Let $Y=\PoneC$ and $X$ be two disjoint copies of $\PoneC$. Define $f:X \to Y$ where both copies of $\PoneC$ in $X$ map to $Y$ via $x^3$. Set $y_0 = 1$. Label the preimages $f^{-1}(y_0)$ and show that the associated monodromy representation is \textit{not} a connected monodromy representation.
\end{exercise}



\section{Examples of Computations}
\label{examplesOfComputations}
Theorem \ref{monodromyHurwitzNumbersThm} allows us to compute many Hurwitz numbers that were out of reach (or at least extremely difficult) when only considering the original definition. Most of our examples will have $Y=\PoneC$, as we understand well its fundamental group after puncturing it with a finite number of points (e.g. Example \ref{monodromyOnPoneC}).

\begin{example}
Let us compute $H^2_{1\to 0}((2),(2),(2),(2))=:H^2_{1\to 0}((2)^4)$. The good maps for $H$ have degree 2, four ramification points (with simple ramification), and four branch points $b_1,\ldots,b_4$. We consider connected monodromy representations $\Phi:\pi_1(Y-B) \to S_2$.

Since the ramification profile over $b_1$ is $\{2\}$, any $\Phi$ must send $\rho_1 \mapsto (12)$. (More generally, $\rho_1$ must be sent to a \textit{2-cycle}, but there is only one 2-cycle in $S_2$!) Similarly, we must have $\rho_2 \mapsto (12), \rho_3 \mapsto (12)$ and then $\Phi(\rho_4)$ is determined by $\Phi(\rho_4)\circ\Phi(\rho_3)\circ\Phi(\rho_2)\circ\Phi(\rho_1) = e$.

Thus there is only one monodromy representation of type $(0,2,(2)^4)$, and hence $H^{\bullet}=1/2$. Since the image of the monodromy representation acts transitively on $\{1,2\}$, we have $H=1/2$ as well. (Compare this with Example \ref{ellCurveMapViaLifts}.)
\end{example}

\begin{exercise}
Compute the connected (and disconnected) Hurwitz numbers $H^2_{g\to 0}((2)^r)$ for all possible $g,r$.
\end{exercise}

\begin{example}
Let us compute $H^3_{0\to 0}((3), (2,1), (2,1)) =: H^3_{0\to 0}((3), (2,1)^2)$. Note that the ramification index $(3)$ implies that the image of any $\Phi$ must contain a 3-cycle and so will act transitively on $\{1,2,3\}$. Thus all monodromy representations in question are connected.

Any $\Phi$ must have $\rho_1 \mapsto (123)$ or $(132),  \rho_2 \mapsto (12)$ or $(13)$ or $(23)$, and $\Phi(\rho_3)$ is determined by $\Phi(\rho_3)\circ\Phi(\rho_2)\circ\Phi(\rho_1) = e$. Thus there are $2*3=6$ choices for the images of the $\rho_i$ and so $H^2_{0\to 0,3}((3)) = 6/3! = 1$.

Compute $H$ again, but this time leave the image of $\rho_1$ until last, letting it be determined by the choice of 2-cycles. Do you get a different answer? Try and see what's going on.
\todo[inline]{Is this last question weird? i.e. do you think it will be overly confusing, or a good kind of confusing?}
\end{example}


\begin{exercise}
Compute the following.
\begin{enumerate}
\item $H^3_{g\to 0}((3), (2,1)^{2g+2})$
\item $H^3_{m+n-2\to 0}((3)^m, (2,1)^{2n})$
\end{enumerate}
\end{exercise}

\begin{example}
Let us compute the disconnected (and then connected) Hurwitz number $H^{3\bullet}_{0\to 0}((2,1)^4)$.

Any monodromy representation $\Phi:\pi_1(Y-\{b_1,\ldots,b_4\} \to S_3$ must send $\rho_1 \mapsto (12)$ or $(13)$ or $(23)$. Similarly, we may choose any two cycles for the image of $\rho_2, \rho_3$, then the image of $\rho_4$ is determined. This gives $3*3*3$ choices, and so $H^\bullet = 3^3/3! = 9/2$.

Not all of these monodromy representations $\Phi$ are connected - it is possible to have the image of $\Phi$ not act transitively on $\{1,2,3\}$. However, the only way this can happen is if each of $\rho_1,\ldots,\rho_4$ get sent to the same transposition (note that this gives a valid homomorphism since then the product of their images is the identity). Thus there are 3 ``non-transitive homomorphisms,'' and subtracting them off gives $H=(3^3-3)/3!=4$.

It's a fact that the difference of 1/2 between the connected and disconnected Hurwitz numbers comes from the disconnected cover consisting of an elliptic curve mapping to the line (i.e. $\PoneC$) as a double cover and a line mapping isomorphically.
\end{example}

\begin{exercise}
\label{subSymmetryEx}
Compute the disconnected (and then connected) Hurwitz number $H^{4\bullet}_{0\to 0}((2,1)^6)$.
\end{exercise}
\todo[inline]{This exercise (Exercise \ref{subSymmetryEx}) is, in my opinion, pretty hard but fun - do you think it's ok to keep it in? if we do keep it in, should we mention that it's a harder one or anything? I can see both sides (indicate or don't indicate)...}

\begin{example}
\label{Hd11nil}
Let us compute $H^{d\bullet}_{1\to 1}$. Notice that good maps for this Hurwitz number are unramified, and have a complex torus $T$ as domain. Now $\pi_1(T) \cong \bZ \oplus \bZ$ which is isomorphic to the group with two generators, $g_1, g_2$, subject to the relation $g_1g_2g_1^{-1}g_2^{-1}=e$, i.e. the group $\la g_1, g_2 | g_1g_2g_1^{-1}g_2^{-1}=e \ra$.

Hence any homomorphism $\Phi:\pi_1(T) \to S_d$ is determined by a choice of $\Phi(g_1), \Phi(g_2) \in S_d$ (call these images $\sigma_1, \sigma_2$ respectively) such that $\sigma_1\sigma_2\sigma_1^{-1}\sigma_2^{-1} = e$, i.e. $\sigma_1\sigma_2 = \sigma_2\sigma_1$. Thus, after $\sigma_1$ is chosen, $\sigma_2$ must be chosen from the centralizer of $\sigma_1$. Recall that the \textbf{centralizer} of an element $g \in G$ is the subgroup $\xi(g) = \{h\in G| hg=gh\}$ of all elements which commute with $g$.

Thus the number of monodromy representations of type $(1,d,\varnothing)$ is $\sum_{\sigma_1 \in S_d} |\xi(\sigma_1)|$, and so Theorem \ref{monodromyHurwitzNumbersThm} yields $H^{d\bullet}_{1\to 1} = (1/d!)\sum_{\sigma_1 \in S_d} |\xi(\sigma_1)|$. The Orbit-Stabilizer Theorem (applied to a group $G$ acting on itself by conjugation) implies $|G|=|\xi(g)||C_g|$ for any $g \in G$ and where $C_g$ is the conjugacy class of $g$. For us this gives $d! = |\xi(\sigma_1)||C_{\sigma_1}|$ for any $\sigma_1 \in S_d$, and hence
\begin{equation}
\label{conjClassSum}
H^{d\bullet}_{1\to 1} = \frac{1}{d!}\sum_{\sigma_1\in S_d}\frac{d!}{|C_{\sigma_1}|} = \sum_{\sigma_1\in S_d} \frac{1}{|C_{\sigma_1}|}=c
\end{equation}
where $c$ is the number of conjugacy classes in $S_d$.

\begin{exercise}
Prove the last equality in \ref{conjClassSum}. \textit{Hint: Replace $S_d$ with a general finite group $G$ and prove the corresponding equality.}
\end{exercise}
\end{example}

\todo[inline]{Should we make the orbit-stabilizer theorem into a (possibly multi-part) exercise?}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Representation Theory of $S_d$}
\label{characterTheoryOfSd}
%I want to let them know where they're going to see this stuff used in later chapters....


%\begin{definition}
%\label{conjugateDef}
%Two elements $g,h \in G$ are conjugate if they are both wearing hats.
%\end{definition}

%\begin{exercise}
%\label{conjugacyClassEx}
%Show that being conjugate is an equivalence relation on $G$. An equivalence class of this relation is called a \textbf{conjugacy class}.
%\end{exercise}

%\begin{example}
%\label{charTableS3}
%Here's where we do the character table for $S_3$
%\end{example}
Representation theory makes group theory and linear algebra communicate. Reference to Fulton Harris for proofs.
Everything $S_d$ specific.



\section{The Group Ring}

%Given a group $G$ and a field $\bK$ (for us $\bK=\bC$) one may form a ring.
A natural step in trying to convert group theory into linear algebra information is to construct a vector space that ``knows a lot'' about the group.
We construct a ring that encodes the group operation as its multiplication, and notice that in fact we also have a vector space structure.


\begin{definition}
The \textbf{group ring} of the symmetric group $S_d$, denoted $\bC[S_d]$,  has elements
formal $\bC-$linear combinations of elements  of $S_d$:
 $$\bC[S_d] = \left\{\sum_{\sigma\in S_d} a_\sigma \sigma| a_\sigma \in \bC\right\}.$$
Addition is formal:
$$
\sum_{\sigma\in S_d} a_\sigma \sigma+\sum_{\sigma\in S_d} b_\sigma \sigma=\sum_{\sigma\in S_d} (a_\sigma+b_\sigma) \sigma.
$$
Multiplication for elements of the form $\sigma$ is defined to be the multiplication
of $S_d$, and is extended to arbitrary linear combination by requiring it to be bilinear.
\end{definition}
Since $S_d$ is not an abelian group, $\bC[S_d]$ is not a commutative ring.
\begin{example}\label{ex:grr}
For $G = S_3$,
%Then $(13) + (-8)(123)$ and $(1+i)(12)$ are elements of $\bC[S_3]$.
 $x=3(12) + 5(123)$ and $y= 4(13) - 6(123) = 4(13) + (-6)(123)$ are elements of $\bC[S_3]$. We have

 $$x+y = 3(12) + 4(13) + (5-6)(123) = 3(12) + 4(13) -(123)$$
 and

\begin{align}
x \cdot y &= (3(12) + 5(123))(4(13) - 6(123))\\
& = 12(12)(13) - 18(12)(123) + 20(123)(13) - 30(123)(123) \label{eq:formal} \\
&= 12(132) - 18(23) + 20(23) - 30(132) \label{eq:factual}\\
&= 2(23) - 18(132)
\end{align}
\end{example}

Example \ref{ex:grr} illustrates that carrying out the product of elements of $\bC[S_d]$ happens in two steps: first one uses bilinearity to go from a product of sums to a sum of products of permutations \eqref{eq:formal}; then one uses the group operation
to reduce each of the products to just one permutation \eqref{eq:factual}.

We call the result of step one  the {\bf formal expansion} of a product of elements of $\bC[S_d]$,
and each of the terms in the sum an {\bf ordered monomial} in the formal expansion. Order matters since multiplication is not commutative.

\begin{remark}
\label{groupRingEqualElts}
There is a natural way to scalar multiply elements of $\bC[S_d]$ by scalars $\alpha \in \bC$, which gives $\bC[S_d]$ also the structure of a vector space, with a natural basis given by $\sigma\in S_d$.
%give a natural basis for the vector space structure on $\bC[S_d]$.
A set with operations that make it simultaneously a ring and a vector space is called an {\bf algebra}.
%Prove that $\bC[S_3]$  is a vector space of dimension 6 using this scalar multiplication and the formal addition defined above. If $G$ is any finite group, what is the dimension of $\bC[G]$ (viewed as a vector space)?
%If $x = \sum_{g \in G} a_g g$ and $y = \sum_{g \in G} b_g g$ are elements of $\bC[G]$, then $x=y$ iff $a_g = b_g$ for all $g \in G$.

%\todo[color=green!40,inline]{I know that we haven't defined ``algebra'' precisely above, but I feel like we should set it apart, as we use the word later on quite a bit, and students might want to jump back to recall what it means (I did the same for ``module'' below).}\end{remark}

%\todo[inline]{mention something like this?... For $\bC[G]$, it is standard notation to write, for example, $4 + 3g$ to mean $4e + 3g$ where $e\in G$ is the identity. }
%vector space with the elements of $G$ as basis vectors. Specifically, if $G$ is a finite group, we define the vector space $\bC\la G\ra := \{a_1g_1 + a_2g_2 + \cdots + a_ng_n | g_i \in G, a_i \in \bC\}$ where the addition and scalar multiplication is formal, i.e. we have $\bK\la G\ra = \bC^{|G|}$ and we think of each component $\bC$ as corresponding to a specific $g\in G$.

%\begin{exercise}
%\label{centerGrpRingEx}
%Note that there is a natural way to scalar multiply elements of $\bC[G]$ by scalars $\alpha \in \bC$ (what is $(5+i)(3(13)) \in \bC[S_3]$?). Prove that $\bC[S_3]$  is a vector space of dimension 6 using this scalar multiplication and the formal addition defined above. If $G$ is any finite group, what is the dimension of $\bC[G]$ (viewed as a vector space)?
%\end{exercise}
\end{remark}


\section{Representations}

We define representations in three equivalent ways - and encourage the reader to become familiar with all points of views, as each has its own advantages.
\begin{definition}
A (finite dimensional, complex) {\bf representation} $\rho$ of $S_d$ is, equivalently:
\begin{description}
    \item[(group action)] a  finite dimensional vector space $V_\rho$ together with a linear action of $S_d$, i.e. a map
    $$``\text{dot}": S_d \times V_\rho \to V_\rho  $$
such that, for every $\sigma, \sigma_1, \sigma_2\in S_d$, $v,w\in V_\rho$, $\lambda\in \bC$:
\begin{enumerate}
\item $e\cdot v= v$
\item $\sigma_2\cdot (\sigma_1\cdot v)= (\sigma_2\sigma_1)\cdot v    $
\item $\sigma\cdot (v+w)= \sigma\cdot v+\sigma \cdot w$
\item $\sigma\cdot \lambda v= \lambda \sigma\cdot v.$
\end{enumerate}
     \item[(module)] A finitely generated  module over the group ring $\bC[S_d]$, i.e. a finitely generated abelian group  $M_\rho$ together with an external product $ \star:\bC[S_d]\times M_\rho \to M_\rho$ which distributes with respect to the algebra and group operations (see \cite{} for an explicit spelling out of the module axioms).
     \todo[color=green!40,inline]{I think that to be fair to the students, we'd want to describe explicitly what an ``external product'' entails, since it asks for more than just ``distributivity,'' right? I vote for spelling it out - and I think it's ok that it would make the connection with the ``group action'' point more obvious. (Also, note that I added a name (``star'') to the external product.) Renzo: OK, with the star, I don't want to write the module axioms because they really are exactly the same as the group action axioms above. But I think a good compromise is to give a precise reference for them.}
    \item[(homomorphism)] A group homomorphism $$\Phi_\rho: S_d \to GL(n, \bC). $$
\end{description}
\end{definition}
\begin{exercise}
Show that the three definitions are in fact equivalent.
\end{exercise}
\begin{exercise}
In mathematics, we follow the philosophy that for a class of mathematical objects with certain structure and properties (e.g. operations satisfying axioms), the ``desirable" functions  are those which respect all of the structure and properties used to define the objects. Functions that pass this test are then called {\bf morphisms}, and invertible morphisms are called {\bf isomorphisms}.
Develop the appropriate notion of morphisms and isomorphism for representations.
\end{exercise}

%\begin{exercise}
%Now that we have our class of objects, a natural question is ``What are functions which meaningfully relate these objects to each other?'' or in other words, ``What are the morphisms between them?'' A good class of morphisms should make use of all of the structure used to define the objects. For example, a group homomorphism (i.e. a morphism of groups) is a function between groups which ``plays well'' with the group operations - in this context, ``plays well'' means ``commutes''.

%Pick the definition of a representation of $S_d$ that you are most comfortable with and develop what you think the morphisms (and isomorphisms) between these objects should be. Now do the same with the other two points of view.
%\end{exercise}
\todo[color=green!40,inline]{I broke apart your above exercise and added some commentary to the 2nd part - your original test is commented-out below. Renzo: I kept your structure of splitting into two exercises, but rewrote your second exercise in a language which seems a bit more terse to me.}
%Develop from all three points of view the notion of morphisms and isomorphisms of representations.

The dimension of $V_\rho$ (or the rank of $M_\rho$, or the $n$ in $GL(n,\bC)$) is called the {\bf dimension} of the representation $\rho$.



A {\bf subrepresentation} $\rho' \leq\rho$ is an invariant subspace (or a $\bC[S_d]$ submodule) $U_{\rho'}$ of $V_\rho$. The $0$ vector, and $V_\rho$ itself are trivial examples of subrepresentations of $\rho$.
A representation $\rho$ that does not contain any non-trivial subrepresentation is called {\bf irreducible}.

\begin{example}
The one-dimensional vector space $\bC$ can be made into a representation by letting $S_d$ act trivially:
$$
\sigma \cdot z = z,
$$
for all $\sigma\in S_d$, $v\in V$. This is called the {\bf trivial} representation of $S_d$ and denoted $\rho_1$. The trivial representation is irreducible simply because a  one-dimensional vector space does not have any proper subspace.
\end{example}
\begin{example}
The group action on $\bC$:
$$
\sigma \cdot z =
\left\{
\begin{array}{cl}
z &  \mbox{if $\sigma$ is an even permutation}\\
-z & \mbox{if $\sigma$ is an odd permutation}
\end{array}
\right.
$$
gives another one-dimensional (hence irreducible) representation of $S_d$, called the {\bf sign} representation, denoted $\rho_{-1}$.
\end{example}
\begin{example}
 Consider a $d$ dimensional vector space $V$ with basis $\{e_1, \ldots, e_d\}$. Define a group action {of $S_d$} on $V$ by extending by linearity the following action on the bases vectors:
$$
\sigma \cdot e_i = e_{\sigma(i)}.
$$
This is called a {\bf permutation} representation. We see that it is not an irreducible representation by noting that the linear span of the vector $e_1+\ldots +e_d$ is invariant under the action of $S_d$ (and hence it gives a proper subrepresentation isomorpic to the trivial representation).
\end{example}
\begin{exercise}
Refer to the module axioms from \cite{}, and prove that
the group ring itself is in a natural way a module over itself. As such, it is a representation of $S_d$ called the {\bf regular} representation.
 \end{exercise}

An important feature of the regular representation is that it contains all irreducible representations of $S_d$: we make this statement precise in the next paragraph.

\todo[color=green,inline]{I think we should make showing that the group ring is a module over itself into an exercise - it will give them a chance to think more about modules, and I think that without it, the claim will seem ``far-off''. Then, after, the exercise, we could mention the important aspect of the regular rep. Renzo: OK, done.}
\begin{exercise}
Given two representations $\rho_1$ and $\rho_2$, one can form the {\bf direct sum} representation $\rho_1\oplus\rho_2$ by considering the direct sum of the  corresponding vector spaces  $V_{\rho_1}\oplus V_{\rho_2}$
with the natural extension of the action.  Describe the matrix $\Phi_{\rho_1\oplus\rho_2}(\sigma)$ in terms of $\Phi_{\rho_1}(\sigma)$ and $\Phi_{\rho_2}(\sigma)$.
\end{exercise}

We recall a few fundamental facts about representations (\cite{}):
\begin{enumerate}
\item Any finite dimensional representation of $S_d$ decomposes uniquely (up to the order of the factors) as a direct sum of irreducible representations.
 \item The number of irreducible representations of $S_d$ equals the number of conjugacy classes of $S_d$, which in turn are naturally indexed by partitions of the integer $d$.
 %Irreducible representations are often labeled by Young Tableaux, which are a graphical way to represent partitions of the integer $d$.
 \todo[color=green!40,inline]{The statement about Young Tableux seems pretty vague - I think we should either expand on it a bit, or omit it. Renzo: agreed!}
\item Denote by $\rho$ an irreducible representation of $S_d$, by $V_\rho$ the corresponding vector space, and understand a sum over the index $\rho$ to mean to sum over all irreducible representations of $S_d$. Then the regular representation decomposes as
\begin{equation}\label{eq:regrep}
\bC[S_d]\cong \bigoplus_\rho V_\rho^{\oplus \dim \rho}.
\end{equation}
By equating the dimensions on either side of \eqref{eq:regrep}, we obtain
\begin{equation}\label{eq:regrep2}
d! = \sum_\rho (\dim \rho)^2.
\end{equation}
\end{enumerate}
\begin{example}
We describe all irreducible representations of $S_3$. By point $2$ above, there are three irreducible representations. We already know two of them: the trivial and the sign representations. It then follows from
 \eqref{eq:regrep2} that the last irreduciblerepresentation must be two-dimensional.
This is  called the {\bf standard} representation and denoted by $\rho_S$. One way to construct the standard representation is to consider the quotient vector space of the three-dimensional permutation represenentation of $S_3$ by the invariant line $\langle e_1+e_2+e_3 \rangle $, and notice that the permutation action naturally descends, since we are quotienting by a trivial representation.
\end{example}
\todo[color=green!40,inline]{I think we should elaborate more explicitly on quotienting representations - especially in light of the following exercise. Renzo: I did - just a little bit - by not assuming that they should know already what a quotient representation is. Howver they should know what a quotient vertor space is! }
\begin{exercise}
Convince yourself that the standard representation is irreducible by showing that it does not admit either the trivial or the sign representation as a subrepresentation. In Section \ref{sec:chars} we see a much more efficient way to prove the irreducibility of $\rho_S$.
\end{exercise}




\section{Characters}
\label{sec:chars}

Characters should be thought as ``coordinates" for representations. They allow to describe representations via a finite list of numbers which {\it play well} with many algebraic constructions in representation theory. We devote this section to making this statement more precise and recalling  some basic notions and properties of characters.

\begin{definition}
Let $\rho$ be a representation of $S_d$. The {\bf character} of $\rho$ is the function
$$\chi_\rho: S_d \to \bC$$
defined as
$$
\chi_\rho(\sigma):= \mbox{trace}(\Phi_\rho(\sigma))
$$
\end{definition}

The trace of a matrix is a coefficient of the characteristic polynomial of the associated linear transformation, and therefore it  is invariant under conjugation.
\todo[color=green!40,inline]{The above statement feels like a graduate text note to me - I think we should elaborate a bit, even a little bit, on it to help out.}
This fact has two very important consequences:
\begin{enumerate}
\item The character of a representation does not depend on the choice of a basis for $V_\rho$ (which gives rise to the matrices $\Phi_\rho(\sigma)$).
\item Characters are constant along conjugacy classes; functions with this property are called {\bf class functions}.
\end{enumerate}

A key fact about characters is that two complex representations of $S_d$ are isomorphic if and only if they have the same character function{\footnote{It is always true that isomorphic representations have the same characters. The converse statement requires to be working over a field of characteristic $0$.}}(\cite{}). Therefore we can use characters to identify representations.
\todo[color=green!40,inline]{My preface statement above feels awkward, but I can't think of a better statement indicating that ``This shouldn't be clear to you'' right now... Renzo: agreed, but I didn't like the "that we will not prove". I think by premising the sentence with "A key fact", and adding a reference at the end of the sentence it should be quite clear that the fact is not just an observation.}
\begin{exercise}
Prove the following useful properties of characters:
\begin{enumerate}
\item For any representation $\rho$, \begin{equation}
\chi_\rho(e)=\dim \rho.
\end{equation}
\item For any $\rho_1,\rho_2$,
\begin{equation}\label{eq:sumch}
\chi_{\rho_1\oplus\rho_2}= \chi_{\rho_1}+\chi_{\rho_2} .
\end{equation}
\end{enumerate}
\end{exercise}
\begin{exercise}
    Compute the character of the standard representation  of $S_3$ as follows. First compute the character of the permutation representation $\rho_P$  by explicitly constructing the relevant matrices. Then use  \eqref{eq:sumch} together with the fact that the permutation representation decomposes as $\rho_P\cong \rho_1\oplus \rho_S$. In addition, use the characters   $\chi_{\rho_1},\chi_{\rho_{-1}}$, $\chi_{\rho_S}$  and \eqref{eq:sumch} to show that $\rho_S$ is irreducible.
\end{exercise}

\begin{remark}Because the matrices $\Phi_\rho(\sigma)$ have finite order, %{\color{green}(i.e. a finite power of them yields the identity matrix - can you prove it?)
 it follows that characters take value in algebraic integers (sums of complex roots of unity). In the case of the symmetric group, characters are actually integer valued functions.
\end{remark}

We recall one final fact in our whirlwind tour of character theory. There is a complex inner-product on the vector space of class functions, defined as follows:
\begin{equation}
\langle \alpha, \beta \rangle= \frac{1}{d!}\sum_{\sigma \in S_d} \alpha(\sigma)\overline{\beta(\sigma)}.
\end{equation}
Characters of irreducible representations form an orthonormal basis for the vector space of class functions:
\begin{equation}
\left\langle \chi_{\rho_1}, \chi_{\rho_2}\right\rangle=
\left\{
\begin{array}{cl}
1 & \rho_1\cong \rho_2\\
0 & \rho_1\not\cong \rho_2
\end{array}
\right.
\end{equation}
for $\rho_1$ and  $\rho_2$ irreducible.
\begin{exercise}
Check the orthonormality of the characters of the irreducible representations of $S_3$ and $S_4$. The characters are collected in Table \ref{tab:ct}.
\end{exercise}
\begin{table}[tb]
\centering
$$
\begin{array}{cccc}
\begin{array}{c|ccc}
S_3 & C_{e} & C_{(2,1)} & C_{(3)}\\
\hline
 \hline
 \rho_1  & 1& 1& 1\\
  & & & \\
 \rho_{-1} & 1&-1 &1 \\
  & & & \\
 \rho_S   & 2& 0&1
\end{array}
& & &
\begin{array}{c|ccccc}
S_4 & C_{e} & C_{(2,1,1)} &C_{(2,2)} & C_{(3,1)} & C_{(4)}\\
\hline
 \hline
 \rho_1  & 1& 1& 1 & 1 & 1\\
  & & &  & &\\
 \rho_{-1} & 1  &-1 & 1&1 &-1 \\
  & & &  & &\\
 \rho_2   &2 & 0& 2& -1& 0 \\
   & & &  & &\\
 \rho_{3a}   &3 &-1 & -1& 0&1 \\
   & & &  & &\\
 \rho_{3b}   &3 &1 & -1& 0&-1 \\
\end{array}
\end{array}
$$
\caption{The character tables of $S_3$ and $S_4$.}
\label{tab:ct}
\end{table}

\section{The Class Algebra}

We now introduce a commutative subalgebra of $\bC[S_d]$, which plays a prominent role in our story.

\begin{definition}
The {\bf class algebra} of $S_d$
is the center of the group ring,
$$\cZ \bC[S_d] = \{x \in \bC[S_d] | yx = xy \text{ for all } y \in \bC[S_d] \}.$$
\end{definition}

\begin{exercise}
For $\lambda\vdash d$ (a partition of the positive integer $d$) denote by $C_\lambda \in \bC[S_d]$ the sum of all elements of cycle type $\lambda$.
\begin{enumerate}
\item Show that $C_\lambda$ consists of the sum of all permutations in a particular conjugacy class.
\todo[color=green!40,inline]{I can't remember - have we formally stated that conjugacy classes in $S_d$ correspond to cycle types? If not, I think we should put something before your table above - as you use that fact in it. Renzo: we better have in the Hurwitz number chapters... we'll have to make sure that it's the case.}
\item Prove that for any $\lambda$, $C_\lambda\in\cZ\bC[S_d].$
\item Show that the $C_\lambda$'s form a basis for $\cZ\bC[S_d]$ as a vector space:
$$
\cZ\bC[S_d]=\bigoplus_{\lambda\vdash d} \langle C_\lambda\rangle_\bC.
$$
\todo[color=green!40,inline]{I struggled with proving parts 2 and 3 when I was in grad school - I think it is too much for us to ask undergrads to prove them without any help, which is why I had broken up these into a bunch of subproblems. What would you think about putting them back in? Renzo: I would rather not, because it would then become a too involved exercise in algebra. }
\end{enumerate}




%Let $G$ be a finite group.
%\begin{enumerate}
%\item Show that $z= \sum_{g\in G} g$ is in $\cZ \bC[G]$

%\item Show that $x \in \bC[G]$ is in $\cZ\bC[G]$ iff $x$ commutes with every element of $G$, i.e. $g\cdot x = x \cdot g$ for all $g \in G$ (where we think of $g = 1g \in \bC[G]$).
%\label{centerCharacterization}

%\item Let $\bar{C} \subset G$ be a conjugacy class in $G$, and set $C = \sum_{g \in \bar{C}} g \in \bC[G]$ (i.e. $a_g = 0$ if $g \notin \bar{C}$, otherwise $a_g = 1)$. Show that $C \in \cZ\bC[G]$. \textit{Hint: Show that $g\bar{C} = \bar{C}g \subset G$ for any $g\in G$, then use part \ref{centerCharacterization}.}
%\label{conjClassInCenter}

%\item Let $\bar{C}_1, \ldots, \bar{C}_c$ be the conjugacy classes of $G$, and let $C_1,\ldots, C_c$ be the respective elements of $\bC[G]$ (as in part 2). Show that $\cZ\bC[G] = \{ a_1C_1 + \cdots + a_c C_c | a_i \in \bC \}$ by following these steps:
%\begin{enumerate}
%\item Show that the right-to-left inclusion of sets follows from part \ref{conjClassInCenter}.

%For the left-to-right inclusion, our strategy is to prove the following:
%\begin{itemize}
%\item[$(\star)$] If $g \in \bar{C}_i \subset G$ is in a term of $x \in \bC[G]$ (i.e. if $a_g \neq 0$) then each $h \in \bar{C}_i$ is in a term of $x$. Furthermore, we have $a_g = a_h$.
%\end{itemize}
%
%\item Show that $(\star)$ implies the left-to-right inclusion of sets.

%Now, to prove $(\star)$...


%\item Let $x = \cdots a_g g + \cdots + a_h h + \cdots \in \cZ\bC[G]$. Show that $h \sim g$ (i.e. $h$ conjugate to $g$) implies $a_g = a_h$. \textit{Hint: Say $h = fgf^{-1}$ for some $f \in G$, so that $hf=fg$. Now use the fact that $x$ commutes with $f$, together with Remark \ref{groupRingEqualElts}.
%} \label{conjugateSameCoeffs}

%\item Use part \ref{conjugateSameCoeffs} to deduce the left-to-right inclusion of sets.
%\end{enumerate}
%\end{enumerate}
\end{exercise}
%\todo[inline]{this exercise is based off of Exercise 13 in Dummit and Foote - p239 - I want to make sure that this is ok - i.e. not plagarism}
%\noindent\hrulefill

%The center of the group ring of $G$ is also called the \textbf{class algebra} of $G$. Exercise \ref{centerGrpRingEx} show that as a vector space, the class algebra of $G$ has dimension equal to the number of conjugacy classes of $G$. It has as basis the elements $C_i = \sum_{g\in\bar{C}_i} g$ where $\bar{C}_i$ is a conjugacy class of $G$.

%For $G=S_d$, two elements are in the same conjugacy class iff they have the same cycle type (to give yourself an example, pick some permutation and conjugate it by another - see what happens!)
%\todo[inline]{mention anything about trying to prove the iff statement or something?}
%\noindent Thus we may specify a conjugacy class $\bar{C}_\lambda \subset S_d$ by giving a partition $\lambda$ of $d$.
We denote the conjugacy class of the identity element  and the corresponding element in the class algebra by $C_e =C_{(1,\ldots,1)}= e$.


The conjugacy class basis is a very natural basis for $\cZ\bC[S_d]$. There is however another basis, naturally indexed by the irreducible representations of $S_d$ which has a very nice multiplicative structure.

\begin{theorem}[Maschke]
\label{semisimpleClassAlgebra}
The class algebra $\cZ\bC[S_d]$ is a semi-simple algebra, i.e. there is a basis $\{\e_{\rho_1}, \ldots, \e_{\rho_n}\}$ (where the $\rho_i$'s are all irreducible representations of $S_d$)  of idempotent elements. This means:
\begin{equation}
\e_{\rho_i}\cdot \e_{\rho_j} = \left\{
     \begin{array}{lr}
       \e_{\rho_i} & \text{if }\e_{\rho_i}=\e_{\rho_j}\\
       0 & \mbox{otherwise}
     \end{array}
   \right.
\end{equation}
Furthermore the following change of basis formulas hold
\begin{equation}
\e_{\rho} = \frac{\dim\,\rho}{d!}\sum_\lambda \chi_{\rho}(\lambda)C_\lambda \hspace{.5in} C_\lambda = |C_\lambda|\sum_\rho \frac{\chi_\rho(\lambda)}{\dim\,\rho}\e_\rho
\end{equation}
where the summation index $\lambda$ denotes all partitions $\lambda$ of $d$, and the summation index $\rho$ denotes all irreducible representations of $S_d$.
\end{theorem}

\begin{example}
The class algebra $\cZ\bC[S_3]$ is a three dimensional vector space, with basis
\begin{eqnarray*}
 C_e &=& e\\
 C_{(2,1)}&=& (12)+(13)+(23)\\
 C_{(3)} &=& (123)+(132)
\end{eqnarray*}
The multiplication table of $\cZ\bC[S_3]$ is (generated bilinearly from)
$$
\begin{array}{c||ccc}
& C_{e} & C_{(2,1)} & C_{(3)}\\
\hline
 \hline
 & & & \\
C_e   & C_e& C_{(2,1)}& C_{(3)}\\
  & & & \\
 C_{(2,1)} & C_{(2,1)}& 3(C_e+C_{(3)})& 2C_{(2,1)} \\
  & & & \\
 C_{(3)}   & C_{(3)}& 2C_{(2,1)} & 2C_e+C_{(3)}
\end{array}
$$

We  denote the vectors of the semisimple basis for $\cZ\bC[S_d]$ by e$_1$, e$_{-1}$ and e$_S$  (instead of $e_{\rho_1}$, etc.). The changes  of basis from Theorem \ref{semisimpleClassAlgebra} are:
\begin{equation}
\begin{array}{cc}
\begin{array}{rl}
 & \\
\mbox{e}_1  = & \frac{1}{6}(C_{e}+C_{(2,1)}+C_{(3)}) \\
  & \\
 \mbox{e}_{-1}  = & \frac{1}{6}(C_{e}-C_{(2,1)}+C_{(3)}) \\
  & \\
\mbox{e}_S  = & \frac{1}{3}(2C_{e}\ \ \ \ -C_{(3)}) \\
\end{array}
&
\begin{array}{rl}
 & \\ & \\
C_{e}  = & \mbox{e}_1+\mbox{e}_{-1}+\mbox{e}_{S} \\
  & \\
 C_{(2,1)} = & 3\mbox{e}_1-3\mbox{e}_{-1} \\
  & \\
 C_{(3)}  = & 2\mbox{e}_1+2\mbox{e}_{-1}-\mbox{e}_{S} \\
  & \\
\end{array}
\end{array}
\end{equation}
\end{example}

\begin{exercise}
Compute the change of basis between the semisimple and the conjugacy classes bases in the class algebra of the symmetric group $S_4$. Refer to Table \ref{tab:ct} for the characters of $S_4$.
\end{exercise}
%\begin{example}
%In Example \ref{charTableS3} we found that $S_3$ has 3 irredubile represntations: $\rho_1, \rho_{-1}, \rho$. Using the character table we have
%\begin{align*}
%       e_{\rho_1} &= \frac{1}{6}(1C_e + 1C_{(12)} + 1C_{(123)})\\
%       e_{\rho_{-1}} &= \frac{1}{6}(1C_e - 1C_{(12)} + 1C_{(123)})\\
%       e_{\rho} &= \frac{1}{3}(2C_e + 0C_{(12)} - 1C_{(123)})
%\end{align*}

%and conversely we have

%\begin{align*}
%\label{basisChangeS3etoc}
%       C_e &= 1(1e_{\rho_1}+1e_{\rho_2}+2(\frac{1}{2}e_\rho))\\
%       C_{(12)} &= 3(1e_{\rho_1}-1e_{\rho_2}+0(\frac{1}{2}e_\rho))\\
%       C_{(123)} &= 2(1e_{\rho_1}+1e_{\rho_2}-1(\frac{1}{2}e_\rho))
%\end{align*}
%\end{example}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{Hurwitz Numbers and  $\cZ(S_d)$}
\label{multProblemInZSd}

We have seen that computing Hurwitz numbers can be accomplished by computing monodromy representations. Remember to put in the intro that we are setting $r=0$ wlog through this chapter.

\section{Genus $0$}

We begin our study by setting the genus of the base curve to be $0$. In this case the fundamental group of a punctured sphere is just a free group, and giving a homomorphism to $S_d$ amounts to choosing elements in $S_d$ that belong to specified conjugacy classes. A concise way to express all possible such choices is given in the following proposition.

\begin{proposition}
\label{classAlgHurwitzNumberProp}
Let $\lambda_1,\ldots \lambda_n$ be partitions of the integer $d$ and for every $i$ denote by $C_{\lambda_i}\in  \cZ\bC[S_d]$ the basis element associated to the corresponding conjugacy class, i.e. the sum of all elements in $S_d$ of cycle type $\lambda_i$.
A disconnected, genus 0 Hurwitz number is given by
\[
H^{\bullet}_{h\to 0,d}(\lambda_1,\ldots,\lambda_n) = \frac{1}{d!}[C_e]C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1},
\]
where $[C_e]C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ denotes the coefficient of $C_e = \{e\}$  after writing the product $C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ as a linear combination of the basis elements $C_\lambda \in \cZ\bC[S_d]$. Note that the genus $h$ of the cover curve is determined by the Riemann-Hurwitz Formula.
\end{proposition}

We give an example demonstrating this notation, then carry out the proof.

\begin{example}
\label{coefficientEx}
In $\cZ\bC[S_3]$ we have
\begin{eqnarray}
C_{(3)} C_{(3)} &=& ((123)+(132))((123)+(132)) \\
 &=& (123)(132)+(132)(123)+(132)(132)+ (123)(123) \label{fexp}\\
 &=& 2e+(123)+(132) = 2C_e + C_{(3)}.\end{eqnarray}
 Thus $[C_e]C_{(3)} C_{(3)} = 2$.
\end{example}

\begin{proof}[Proof of Proposition \ref{classAlgHurwitzNumberProp}]
We show that the number $M$ of  monodromy representations of type $(0,d,\lambda_1,\ldots,\lambda_n)$ is equal to $[C_e]C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$.  Proposition \ref{classAlgHurwitzNumberProp} then follows from Theorem \ref{monodromyHurwitzNumbersThm}.


The fundamental group of $\PoneC \smallsetminus \{b_1,\ldots,b_n\}$ is a free group in $n-1$ generators, but it is conveniently presented in a more symmetric way as:
$$
\pi_1\left(\PoneC \smallsetminus \{b_1,\ldots,b_n\}\right)=\langle \rho_1, \ldots, \rho_n|\rho_1\star \ldots\star\rho_n\rangle,
$$
where $\rho_i$ is a small loop around $b_i$.
A monodromy representation $\Phi$ of type $(0,d,\lambda_1,\ldots,\lambda_n)$ is given by a choice of $\sigma_1,\ldots, \sigma_{n} \in S_d$ (the images via $\Phi$ of the small loops $\rho_i$) such that each $\sigma_i$ has  cycle type $\lambda_i$, and such that $\sigma_n \sigma_{n-1} \cdots \sigma_1 = e$.

Write down each
$
C_{\lambda_i}
$
as the formal sum of the group elements in the corresponding conjugacy class, and  formally expand the product $C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ (without actually multiplying any of the group elements - as in \eqref{fexp}). Each $n$-tuple $\sigma_1,\ldots, \sigma_{n}$ giving a monodromy representation appears uniquely as an ordered monomial in such expansion. Viceversa, an ordered monomial in the expansion of $C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ corresponds to a monodromy representation if the product of the corresponding group elements gives the identity.

There is therefore a natural bijection between monodromy representations of type $(0,d,\lambda_1,\ldots,\lambda_n)$ and terms in the formal expansion of $C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ whose product is the identity. This precisely means that the number of monodromy representations equals the coefficient of $C_e$ in the product $C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$.



%Thus $M$ is obtained by counting all possible ways of choosing $\sigma_1 \in \bar{C}_{\lambda_1}, \ldots, \sigma_n \in \bar{C}_{\lambda_n}$ such that $\sigma_n \sigma_{n-1} \cdots \sigma_1 = e$. But this is exactly $[C_e] C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$.
\end{proof}


\begin{example}
 The Hurwitz number $H_{0 \to 0,3}((3),(3)) = (1/3!)[C_e]C_{(3)}\cdot C_{(3)}$ with the product computed in $\cZ\bC[S_3]$. The coefficient $[C_e]C_{(3)}\cdot C_{(3)}$ is computed in Example \ref{coefficientEx} as  2, and hence $H_{0 \to 0,d}((3),(3)) = 2/6 = 1/3$. (This is our third time computing this Hurwitz number! Take a walk down memory lane with Example \ref{Hd00dd} and Exercise \ref{Hd00ddMono}.)
\end{example}

\section{Genus and Commutators}

We now give a formula for higher genus Hurwitz numbers as a product of elements in the class algebra $\cZ\bC[S_d]$.The key idea here is that in the ``standard" presentation of the fundemental group of a punctured positive genus surface, there are additional generators corresponding to loops winding around the handles, and the product of all generators now it must satisfy a relation which contains products of commutators. Before we discuss how to translate all of this in the language of the class algebra, we observe a simple but illustrative example.

\begin{example} \label{ex:gone}
\begin{equation}H^{\bullet}_{1 \to 1,d}= \frac{1}{d!}[C_e]\sum_{\lambda \vdash d} |\xi(\lambda)| C_\lambda^2, \label{goneca}
\end{equation}
  where $|\xi(\lambda)|$ is the size of the centralizer of any permutation in the conjugacy class indexed by $\lambda$.
 Example \ref{Hd11nil} computed $H^{d\bullet}_{1 \to 1}$ as the number of irreducible  representations, or of conjugacy classes, of $S_d$. There we showed that a monodromy representation of type $(1,d,\varnothing)$ corresponds to a choice of $\sigma_1,\sigma_2\in S_d$ such that $\sigma_2^{-1}\sigma_1^{-1}\sigma_2\sigma_1=e$. We now  think of all possible such choices as picking first an element $\sigma_1\in S_d$, then a $\sigma_2$ that gives rise to a conjugate element $\hat{\sigma}_1=\sigma_2^{-1}\sigma_1^{-1}\sigma_2$ such that
$\hat{\sigma}_1\sigma_1=e$. Any pair $\hat{\sigma}_1\sigma_1$ identifies an ordered monomial in the formal expansion of $\sum_{\lambda \vdash d}  C_\lambda^2$: this defines a function $\kappa$ from the set of monodromy representations  of type $(1,d,\varnothing)$ to the set of ordered monomials, whose image are the monomials whose product returns the identity element. For any fixed $\hat{\sigma}_1\sigma_1\in C_\lambda^2$ in the image of $\kappa$, the cardinality of the inverse image of $\kappa$ is $|\xi(\lambda)|$: two permutations $\sigma_2$ and $\sigma_2'$ give rise to the same $\hat{\sigma}_1$ if and only if $\sigma_2^{-1}\sigma_2'\in \xi(\sigma_1)$.
Formula \eqref{goneca} follows from computing the cardinality $M$ of the set of monomdromy representations as
$$
M= \sum_{\hat{\sigma}_1\sigma_1\in Im(\kappa)} |\kappa^{-1}(\hat{\sigma}_1\sigma_1)|=\sum_{\lambda \vdash d} |\xi(\lambda)| \left([C_e]C_\lambda^2\right).
$$
\end{example}

Example \ref{ex:gone} is perhaps an overcomplicated way of computing a simple Hurwitz number, but it allowed us to introduce an important character in our story, which we now formally define.

\begin{definition}
For a fixed positive integer $d$ we define
\begin{equation}
\mathfrak{K}:= \sum_{\lambda \vdash d} |\xi(\lambda)| C_\lambda^2 \in \cZ\bC[S_d].
\end{equation}
The letter ``k" is chosen from the german word {\it kommutator}, since we have already too many ``c's" floating around.
\end{definition}

\begin{exercise}\label{ex:comm}
Denote by $X$ the set of ordered monomials in the formal expansion of the quadratic expression $\sum_{\lambda \vdash d} C_\lambda^2$. Consider the function
$$
\kappa: S_d\times S_d \to  X
$$
defined by $\kappa(\sigma_1,\sigma_2)= (\sigma_2^{-1}\sigma_1^{-1}\sigma_2)\sigma_1$. Show that $\kappa$ is a surjective function and for every $\hat{\sigma}_1\sigma_1\in X$, $|\kappa^{-1}(\hat{\sigma}_1\sigma_1)|= |\xi(\sigma_1)|.$
\end{exercise}

The scope of Exercise \ref{ex:comm} is that one should think of $\mathfrak{K}$ as a way to express the sum of all commutators in $S_d$ as an element in the class algebra $\cZ\bC[S_d]$. We are now ready to express a general (disconnected) Hurwitz number as a multiplication problem in the class algebra.

\begin{proposition}
\label{prop:classgenhurw}
Let $\lambda_1,\ldots \lambda_n$ be partitions of the positive integer $d$.
%and denote by $\tau$ the partition $(2, 1, \ldots, 1)$ corresponding to the class of a simple transposition.
We have the formula
\begin{equation} \label{eq:classhurwg}
H^{\bullet}_{h\to g,d}(\lambda_1,\ldots,\lambda_n) = \frac{1}{d!}[C_e]\mathfrak{K}^g C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1} ,
\end{equation}

where the genus $h$ of the cover curve is determined by the Riemann-Hurwitz Formula.
\end{proposition}
\begin{proof}
The fundamental group of a genus $g$ surface with $n$ punctures may be presented as:

$$
\hspace{-1cm}
\pi_1\left(C_g \smallsetminus \{b_1,\ldots,b_n\}\right)=\langle \rho_1, \ldots, \rho_n, \alpha_1,\beta_1, \ldots, \alpha_g,\beta_g|\rho_1\star \ldots\star\rho_n\star [\alpha_1,\beta_1]\star\ldots\star[\alpha_g,\beta_g]\rangle,
$$
where $\rho_i$ is a small loop around $b_i$, $\alpha_i$ and $\beta_i$ are the two independent loops around the $i$-th handle, and the square brackets denote commutators.
A monodromy representation of type $(g,d,\lambda_1,\ldots,\lambda_n)$ is given by a choice of $\sigma_1,\ldots, \sigma_{n},\mu_1,\nu_1,\ldots,\mu_g,\nu_g \in S_d$  such that each $\sigma_i$ has  cycle type $\lambda_i$, and $[\mu_g,\nu_g]\cdots[\mu_1,\nu_1]\sigma_n \sigma_{n-1} \cdots \sigma_1 = e$.
Given a $(2g+n)$-tuple $\sigma_1,\ldots, \sigma_{n},\mu_1,\nu_1,\ldots,\mu_g,\nu_g$ corresponding to a monodromy represntation, one may write the ordered monomial
\begin{equation}\label{eq:mon}
\hat{\mu}_g\mu_g\cdots\hat{\mu}_1\mu_1\sigma_n \sigma_{n-1} \cdots \sigma_1,
\end{equation}
where $\hat{\mu}_i=\nu_i^{-1}\mu_i^{-1}\nu_i$.

Monomials as in equation \eqref{eq:mon} appear in the formal expansion of the product $\left(\sum_{\lambda \vdash d}  C_\lambda^2\right) C_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$ precisely as those terms where the product of the group elements gives the identity. Each such monomial arises from $\prod_{i=1}^g |\xi(\mu_i)|$ distinct monodromy representations.
By absorbing each term of this product into the corresponding term $\left(\sum_{\lambda \vdash d}  C_\lambda^2\right)$, we see that the number of monodromy representations of type $(g,d,\lambda_1,\ldots,\lambda_n)$ corresponds to the coefficient of the identity in the product $\mathfrak{K}^gC_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}$, which concludes the proof of Proposition \ref{prop:classgenhurw}
\end{proof}


\todo[inline]{Make sure that in Ch 8 we introduce the notion of a formal expansion and an ordered monomial.}
\section{Burnside Formula}

Computing Hurwitz numbers is a multiplication problem in the class algebra of the symmetric group, and that the conjugacy class basis $\{C_\lambda\}$ is well suited to encode the ramification profiles  imposed over the branch points.

Theorem \ref{} proves that $\cZ\bC[S_d]$ is a semisimple algebra, with a semisimple basis naturally indexed by irreducible representations. By changing  basis we obtain a closed formula for Hurwitz numbers, in terms of characters of the irreducible representations of $S_d$. Andrei Okounkov attributed the following formula to Burnside - as it appears as an exercise in his book {\it Theory of Groups of Finite Order} \cite{}.
%Using the change of basis formulas in Theorem \ref{semisimpleClassAlgebra} we can rewrite the equation in Proposition \ref{classAlgHurwitzNumberProp}. Notice that in the new formula below, the ``grab the coefficient of $C_e$'' mechanism is done away with.

\begin{theorem}[Burnside Character Formula]
\label{representationHNProp}
Fix a positive integer $d$ and $m$ partitions $\lambda_i\vdash d$. Denote by $\rho$ an irreducible representations of $S_d$, and intend a summation over the index $\rho$ to be ranging over all irreducible representations. Then
\begin{equation}\label{eq:bf}
H^{\bullet}_{h\to g,d}(\lambda_1,\ldots,\lambda_m) =  \sum_{\rho} \left(\frac{\dim  \rho}{d!}\right)^{2-2g} \prod_{j=1}^m \frac{ |C_{\lambda_j}|\chi_{\rho}(\lambda_j)}{\dim  \rho}
\end{equation}
\end{theorem}

\begin{remark}
At first glance it might not be apparent why \eqref{eq:bf} represents an improvement over \eqref{eq:classhurwg}. Arguably, it is not: in mathematics when we translate a problem we often just ``shift" the complexity of the problem around. In formula \eqref{eq:classhurwg} we have simple inputs (the conjugacy class basis vectors for $\cZ\bC[S_d]$), but we are multiplying vectors in a very high dimensional algebra. In formula \eqref{eq:bf}, the inputs are more sophisticated (the characters of representations of $S_d$), but the multiplication is now an ordinary multiplication of real numbers! In other words we have shifted the complexity from the operation to the inputs.
\end{remark}

\begin{proof}
We first consider the element $\mathfrak{K}\in \cZ\bC[S_d]$ and express it in terms of the semisimple basis. Using the change of basis formulas from Theorem \ref{semisimpleClassAlgebra}, we have

\begin{eqnarray}
\mathfrak{K} &=&  \sum_{\lambda } |\xi(\lambda)| C_\lambda^2\\
 &=& \sum_{\lambda } |\xi(\lambda)| \left(\sum_{\rho}
 \frac{|C_{\lambda}|\chi_{\rho_}(\lambda)}{\dim\rho}\ e_{\rho}\right)^2 \label{eq:e1}\\
 &=& \sum_{\lambda } |\xi(\lambda)| \sum_{\rho}
 \left(\frac{|C_{\lambda}|\chi_{\rho}(\lambda)}{\text{dim}\, \rho}\right)^2e_{\rho}\label{eq:e2}\\
  &=& \sum_{\rho } \frac{d!}{(\text{dim}\, \rho)^2}\left(\sum_{\lambda}  |C_{\lambda}|\chi_{\rho}(\lambda)^2\right)e_{\rho}\label{eq:e3}\\
   &=& \sum_{\rho } \frac{d!}{(\text{dim}\, \rho)^2}\left(\sum_{\sigma\in S_d}  \chi_{\rho}(\sigma)^2\right)e_{\rho}\label{eq:e4}\\
    &=& \sum_{\rho } \left(\frac{d!}{\text{dim}\, \rho}\right)^2e_{\rho} \label{eq:e5}
\end{eqnarray}
\todo[inline]{Make sure to put inner product of characters in Section $8$.}

In this string of equations we have applied the change of basis \eqref{eq:e1} and the orthonormality of the vectors $e_\rho$ \eqref{eq:e2}; then we switched order of summation and used the identity $|C_\lambda||\xi(\lambda)|=d!$ to obtain \eqref{eq:e3}; expressed the second summation as a sum over all elements of $S_d$ \eqref{eq:e4} and finally recognized the second summation as the inner product of $\chi_\rho$ with itself \eqref{eq:e5}.

Next we consider the product
\begin{eqnarray}
C_{\lambda_m}\cdots C_{\lambda_1} &=&\left(\sum_\rho \frac{|C_{\lambda_m}|\chi_{\rho}(\lambda_m)}{\text{dim}\, \rho}e_{\rho}\right)\cdots\left(\sum_\rho \frac{|C_{\lambda_1}|\chi_{\rho}(\lambda_1)}{\text{dim}\, \rho}e_{\rho}\right)\\
&=& \sum_\rho \prod_{j=1}^m\left(\frac{|C_{\lambda_j}|\chi_{\rho}(\lambda_j)}{\text{dim}\, \rho}\right)e_{\rho}
\end{eqnarray}
The magic of expressing a product of vectors in a semisimple basis: you just multiply together the coefficients of each basis vector.

Consider formula \eqref{eq:classhurwg}
\begin{eqnarray} \hspace{-0.3cm}\label{eq:classhurwg}
H^{\bullet}_{h\to g,d}(\lambda_1,\ldots,\lambda_n) &=& \frac{1}{d!}[C_e]\mathfrak{K}^gC_{\lambda_n}\ldots C_{\lambda_2}  C_{\lambda_1}\\
  &=& \frac{1}{d!}[C_e]\sum_\rho \left(\frac{d!}{\text{dim}\, \rho}\right)^{2g}\prod_{j=1}^m\left(\frac{|C_{\lambda_j}|\chi_{\rho}(\lambda_j)}{\text{dim}\, \rho}\right)e_{\rho}\label{eq:almostthere}
\end{eqnarray}
We now need to apply the inverse change of basis (back to the conjugacy class basis), and extract the coefficient of $C_e$. Recall from  Theorem \ref{semisimpleClassAlgebra} that
\begin{equation}\label{eq:cid}
e_\rho=  \frac{\dim\rho}{d!} \chi_{\rho}(e)C_e+\ldots
\end{equation}
We observe that $\chi_{\rho}(e)=\dim\rho$; we finally obtain \eqref{eq:bf} by plugging
\eqref{eq:cid} into \eqref{eq:almostthere}.
\end{proof}


%By Proposition \ref{classAlgHurwitzNumberProp} and Theorem \ref{semisimpleClassAlgebra} we have
%\begin{align}
%H^{d\bullet}_{g\to 0}(\lambda_1,\ldots,\lambda_m) &= \frac{1}{d!}[C_e]C_{\lambda_1}\cdot C_{\lambda_2} \cdots C_{\lambda_m}\\
%&= \frac{1}{d!}[C_e]\left(\sum_{i=1}^n \frac{|C_{\lambda_1}|\chi_{\rho_i}(\lambda_1)}{\text{dim}\, \rho_i}e_{\rho_i}\right)
%\cdots
%\left(\sum_{i=1}^n \frac{|C_{\lambda_m}|\chi_{\rho_i}(\lambda_m)}{\text{dim}\, \rho_i}e_{\rho_i}\right) \label{pluggingIn}
%\end{align}




%\begin{enumerate}
%\item Compute $[C_e]e_{\rho_i}$. \label{Ceerho}
%\item Let $x,y \in \cZ\bC[S_d]$ and $\alpha,\beta \in \bC$. Show that $[C_e](\alpha x + \beta y) = \alpha [C_e]x + \beta [C_e]y$. \label{CeIsLinear}
%\item Simplify the product in Equation \ref{pluggingIn} by following these steps:
%    \begin{itemize}
%    \item[(i)] Simplify the product to the right of $[C_e]$ using the multiplicative properties of the basis $\{e_{\rho_i}\}_i$.
%    \item[(ii)] Distribute $[C_e]$ using part \ref{CeIsLinear}.
%    \item[(iii)] Apply the formula from part \ref{Ceerho} to remove $[C_e]$ from the expression.
%    \item[(iv)] Rearrange factors to match the right-hand side of Proposition \ref{representationHNProp}.
%    \end{itemize}
%\end{enumerate}
%\end{exercise}
\begin{example}
Let us revisit the computation of $H_{1\to 0,3}((3),(2,1)^4)$. In this case the condition of a point with full ramification forces all covers to be connected, so $H=H^\bullet$.
Refer to Table \ref{s3} for the character table of $S_3$ and  the transformations from the conjugacy class basis to the representation basis.
We have:
\begin{eqnarray*}
H_{1\to 0,3}((3),(2,1)^4) & =&  \frac{1}{6}[C_{e}] C_{(3)} C_{(2,1)}^4 \\
& =&  \frac{1}{6}[C_{e}] (2\cdot3^4\mbox{e}_1+2\cdot(-3)^4\mbox{e}_{-1}) \\
 & = & \frac{1}{6}\left(\frac{2\cdot3^4}{6}+\frac{2\cdot3^4}{6}\right)=9
\end{eqnarray*}
\end{example}


\begin{exercise}
Familiarize yourself with Proposition \ref{representationHNProp}, and warm up by computing the following Hurwitz numbers.
\begin{enumerate}
\item $H_{2\to 0,3}((3),(2,1)^6)$
\item $H_{5 \to 0,3}((3)^4, (2,1)^6)$
\item $H^{\bullet}_{0 \to 0,3}((2,1)^4)$
\end{enumerate}
Now compute the general degree $3$ disconnected Hurwitz number.
$$H^{\bullet}_{ 3g-2+a+b\to g,3}((3)^a(2,1)^{2b}).$$
\end{exercise}










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%

\chapter{The Hurwitz Potential}

{\it Generating functions are efficient ways of encoding combinatorial information about sequences/ordered sets of numbers. One function keeps track of infinitely many numbers and operations on functions correspond to universal recursions. Make reference to Generatingfunctionology. (funny quote from this book: A generating function is a clothesline on which we hang up a sequence
of numbers for display.)}


\section{Generating functions}
The book \cite{} introduces generating functions with this pictorial image:

 \vspace{0.1cm}
\noindent
{\it  ``A generating function is a clothesline on which we hang up a sequence
of numbers for display."}
\vspace{0.1cm}

Behind the facetious lightheartedness of this sentence, lies the philosophy that encoding sequences of numbers as coefficients of power series is a convenient way to encode and manipulate combinatorial information. Let us make some precise definitions.

\begin{definition}
Given a sequence of numbers $A=\{a_n\}_{n\in \bZ^{\geq 0}}$, the {\bf ordinary generating function} for $A$ is the formal power series:
\begin{equation}
\f(x)= \sum_{n\in \bN} a_n x^n.
\end{equation}
The {\bf exponential generating function} for $A$ is defined to be
\begin{equation}
\g(x)= \sum_{n\in \bZ^{\geq 0}} \frac{a_n}{n!} x^n.
\end{equation}
If either of the above power series converge in a neighborhood of $x=0$, then we also call generating function for $A$ the analytic function that the power series converges to.
\end{definition}
\begin{example}\label{ex:trgf}
If $A=\{1\}_{n\in \bZ^{\geq 0}}$ is the constant sequence, then the ordinary  and exponential generating functions for $A$ are
\begin{equation}\label{eq:cgf}
\f(x)= \frac{1}{1-x}  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\g(x)= e^x.
\end{equation}
Now suppose that you don't know that $A$ is the constant sequence, but you are rather told the recursive information that for every non-negative integer $n$,
$
a_{n}=a_{n+1}.
$
(I know, it must be a really bad day if you don't recognize a constant sequence from this information, but bear with me for the sake of exposition...) We may reconstruct $f$ and $g$ from this recursive information as follows.

By definition,   $a_n=[x^n]\f$ is the coefficient of $x^n$ in the  function  $\f$ (which we want to consider as an unknown) for every non-negative integer $n$. The coefficient $a_{n+1}$ can be viewed as the coefficient of $x^n$ for the function $\frac{\f}{x}$. Therefore for every $n\geq 0$,
\begin{equation}\label{eq:orec}
[x^n] \f = [x^n] \frac{\f}{x}.
\end{equation}
Note that \eqref{eq:orec}  is not true if we remove $[x^n]$, as the function $\frac{\f}{x}$ has a ``pole" at $0$, while $\f$ doesn't. However we can fix this issue ``by hand" to obtain  an honest functional equation satisfied by $\f$:
\begin{equation}\label{eq:orec}
 \f =  \frac{\f}{x} -\frac{1}{x} .
\end{equation}
It is now immediate to solve \eqref{eq:orec} for $\f$ and obtain \eqref{eq:cgf}.

For the exponential generating function, we have that for every  $n\geq 0$, $a_{n+1}= [x^n] \frac{d\g}{dx}$, and hence $\g$ satisfies the ordinary differential equation $\g'=\g$ with boundary condition $\g(0)=1$.
\end{example}

Example \ref{ex:trgf} shows that a recursive relation among elements of a sequence can be turned into a functional or differential equation involving the corresponding generating functions.
Which one between the ordinary or exponential generating function encoding is more desirable often depends on the problem at hand...
Some times in enumerative geometry the natural encoding is dictated to us from the geometric problem, as the next (also silly) example illustrated.

\begin{example}
We want to describe the generating function for the sequence counting {\it isomorphism classes of finite sets of cardinality n}. Isomorphisms of sets are just bijective functions, and any two sets of cardinality $n$ can be put in bijection (that is essentially the definition of having cardinality $n$), so it looks like we are again just talking about the constant sequence.
However we have already encountered in this book that enumerative geometers like to divide by the symmetries (i.e. the order of the automorphism group) of the geometric objects considered. A set of order $n$ has $S_n$ as its automorphism group: therefore the exponential generating function for the constant sequence is {\it morally} the best way to encode the counting of finite sets.

As a consequence, if you ask an enumerative geometer what is the total number of finite sets, the answer will of course be:
$$
\sum_{n=0}^{\infty}\frac{1}{n!}= \e.
$$
\end{example}

Sometime we want to encode sets of numbers that depend on more than  one index, and we do so by introducing a formal variable in the generating function for each index. We illustrate this philosophy with a simple example.

\begin{example}
Our counting problem is: $\{a_{k,n}\}$={\it number of subsets of order $k$ of a set of cardinality $n$}.
We introduce a formal variable $q$ to keep track of the cardinality of the ambient set, and a variable $x$ to keep track of the cardinality of the subset, and define
\begin{equation}
\f(x,q)= \sum a_{n,k}x^k q^n.
\end{equation}
We know from combinatorics that $a_{n,k}={{n}\choose{k}}$, and, using Newton's binomial theorem, we obtain:
\begin{equation}
\f(x,q)= \sum (x+1)^n q^n= \frac{1}{1-(x+1)q}.
\end{equation}
Finally we observe that if we set $x=1$ we ignore the information of how many subsets of order $k$ are there and recover the generating function encoding the total number of subsets of a set of order $n$.
Philosophically, often introducing new variables amounts to refining the combinatorial information, whereas specializing variables amounts to forgetting part of the structure.
\end{example}

\begin{exercise}
Let $p_n$ denote the number of partitions of the positive integer $n$, and define the generating function for this sequence to be:
\begin{equation}
\MM(x):=\sum_{n=0}^{\infty} p_n x^n.
\end{equation}
Prove that
\begin{equation}
\MM(x)= \prod_{k=1}^{\infty}\frac{1}{(1-x^k)}=1+x+2x^2+ 3x^3+ 5x^4 +7x^5+\ldots
\end{equation}
\end{exercise}

Let us now dive into the generating function for Hurwitz numbers, which is what we are ultimately interested in.


\begin{definition}
The {\bf genus $g$ Hurwitz Potential} is a generating function for Hurwitz numbers counting covers of curves of genus $g$. We present it here with as many variables as possible. In almost all applications one makes a choice of the appropriate variables to mantain:
\begin{equation}
\HP_g(p_{i,j},u,z,q):=\sum  H^{r}_{h\to g, d}(\lambda_1, \ldots, \lambda_m)\ p_{1,\lambda_1} \ldots p_{m,\lambda_m} \frac{u^r}{r!}z^{1-h} q^d,
\end{equation}
where:
\begin{itemize}
	\item $p_{i,j}$, for $i$ and $j$ varying among positive integers, index ramification profiles. The first index $i$ keeps track of the branch point, the second of the ramification profile. For a partition $\lambda=(l_1, \ldots, l_k)$ the notation $p_{i,\lambda}$ is defined to mean:
	$$p_{i,\lambda}=\prod_{j=1}^l p_{i, l_j}.$$
	\item $u$ is a variable for unmarked simple ramification. The exponential encoding may seem a bit mysterious at this point, but we will see soon that it is very convenient.
	%reflects the fact that these points are not marked.
	\item $z$ indexes the genus of the cover curve (more precisely it indexes the euler characteristic, which is additive under disjoint unions).
	\item $q$ keeps track of degree.
\end{itemize}
The {\bf total Hurwitz potential} is defined to be the sum over all general of the genus $g$ potentials:
\begin{equation}
\HP:= \sum_{g=0}^\infty \HP_g.
\end{equation}

Similarly one can define  disconnected  Hurwitz potentials $\HP_g^\bullet$, $\HP^\bullet$, encoding  disconnected Hurwitz numbers. Note that in this case the genus $h$ of the cover curve ranges over all integers.
\end{definition}
%\begin{remark}
%We did not attach any formal variable to the genus of the base curve, as this information can be recovered from all other invariants via the Riemann-Hurwitz formula. If we wish to fix the genus of the base curve to be a particular $g$, we denote the corresponding generating function by $\HP_g$.
%\end{remark}

%\noindent{\bf Silly but Important Convention:} we choose to set $p_{i,1}=1$ for all $i$. This means that an unramified point sitting above a branch point is not ``recorded". With this convention, the monomial in $p_i$'s (for a fixed $i$) has weighted degree at most (but not necessarily equal) the exponent of the variable $q$.


\todo[inline]{Revise all Hurwitz numbers to uniformize notation. I think I like the one in the Hurwitz potential better than appending an $r$ up with the $d$...}

\begin{example}
The Hurwitz number $H^{6}_{3 \to 0, 3}((3)^2,(1,1,1))$
appears in $\HP_0$ as the coefficient of the monomials:
 $$p_{1,3}p_{2,3}p_{3,1}^3\frac{u^6}{6!}z^{-4}q^3,$$
 $$p_{1,3}p_{2,1}^3p_{3,3}\frac{u^6}{6!}z^{-4}q^3,$$
and
$$p_{1,1}^3p_{2,3}p_{3,3}\frac{u^6}{6!}z^{-4}q^3.$$
The reason a Hurwitz number appears as a coefficient of several different monomials is that in our definition of Hurwitz numbers we chose to not keep track of the actual labeling of the branch points, whereas in the potential we do.
\end{example}

\begin{example}
Setting $u$ and all the $p$ variables equal to $0$, we obtain a generating function $\ET$ for \'{e}tale (i.e. unramified) covers of Riemann Surfaces:
\begin{eqnarray}
\ET(z,q)&=&\HP(\underline{0},0,z,q)=\sum_{d=1}^{\infty}\sum_{g=0}^\infty  H^{0}_{dg-d+1 \to g, d}z^{d(1-g)} q^d \nonumber \\
 &=& q\frac{z^2}{z-1}+ \frac{3}{2}q^2\frac{z^4}{(z^2-1)(z^2-4)} + \ldots  %\frac{2^{2g}-1}{2}z^{2-2g}
 \end{eqnarray}

Note that because of our encoding of the genus variable, the enumerative information is encoded in the coefficients of the Taylor/Laurent expansions of the above rational functions in $z$ at $z=\infty$.
\end{example}

\todo[inline]{Generating function for degree $2$ etale covers has been Maplechecked. Make sure that this example is discussed in the appropriate chapter.}

\section{Connected Hurwitz numbers}

We first restrict our attention to connected unramified covers of genus $0$ curves: we denote the generating function for such covers $\ET_0$. The Riemann-Hurwitz formula tells us that the only possible unramified map to $\PoneC$ is a degree $1$ map from $\PoneC$ itself, which is unique up to isomorphism. Hence
\begin{equation}
\ET_0(z,q)= zq.
\end{equation}

Now allow the source curve to be possibly disconnected. For every degree $d$, there exists an unramified cover of $\PoneC$ of degree $d$: it consists of $d$ distinct copies of $\PoneC$ - i.e. a genus $1-d$ curve -  each mapping down isomorphically to the base curve. There is one such map, and it has $S_d$ as its automorphism group, since the $d$ connected components of the source curve can be arbitrarily permuted. We therefore obtain:

\begin{equation}\label{eq:etd}
\ET_0^\bullet(z,q)= \sum_{d=1}^{\infty}\frac{1}{d!}{z^{d}q^d}=\e^{zq}-1.
\end{equation}

The relationship that we observed in \eqref{eq:etd} between is in fact a general phenomenon.

%The number of disconnected covers of a given curve with specified data generically equals the product of the number covers fod the data restricted to each component. However, if some of the components have exactly the same data, then there are automorphisms amounting to the possibility of permuting such components. Refer to Figure \ref{} for an illustration. Finally, we observe that when we have a map from a disconnected cover, the degree of the map is the sum of the degrees of the map restricted to each connected component, the euler characteristic of the disconnected curve equals the sum of the euler characteristics of each connected component,






\begin{theorem}
The connected and disconnected genus $g$ Hurwitz potentials are related by exponentiation:
\begin{equation}\label{thm:expon}
1+\HP_g^\bullet= \e^{\HP_g}
\end{equation}
\end{theorem}
\begin{proof}
We first observe that the $q^0$ coefficient of equation \eqref{thm:expon} is correct - we make this happen by adding $1$ to the left hand side.

Let $\mathfrak{d}= (h,d,r, \lambda_1, \ldots, \lambda_m)$ denote the combinatorial data needed to identify a connected cover of a genus $g$ curve with special ramification profiles over $m$ fixed points:  $h$ denotes the genus of the cover curve, $d$ the degree, the $\lambda$'s prescribe the ramification profiles over the special points and $r$ denotes the amount of additional generic ramification needed to satisfy the Riemann-Hurwitz formula. The Hurwitz number $H^{r}_{h\to g, d}(\lambda_1, \ldots, \lambda_m)$ (which in this proof we denote for short as $H_\mathfrak{d}$) times the exponential encoding factor $\frac{1}{r!}$ gives the coefficient of the monomial
$ p_{1,\lambda_1} \ldots p_{m,\lambda_m} {u^r}z^{1-h} q^d$ in $\HP_g$.
 Now consider a tuple  $\vec{\mathfrak{d}}=(\mathfrak{d}_1^{l_1}, \ldots, \mathfrak{d}_k^{l_k})$, indexing a particular type of disconnected Hurwitz covers, as represented in Figure \ref{}. The length of  $\vec{\mathfrak{d}}$, which equals $L:=\sum_{j=1}^k l_j$, is the number of connected components of the source curve. The number of disconnected Hurwitz cover of type $\vec{\mathfrak{d}}$ (times $1/R!$) contributes to the coefficient of the monomial
 \begin{equation}\label{eq:mon}
 p_{1,\Lambda_1} \ldots p_{m,\Lambda_m} {u^R}z^{1-H} q^D
 \end{equation}
in $\HP^{\bullet}_g$, where $D, R, 1-H$ are the sums of the corresponding quantities appearing in each of the entries of $\vec{\mathfrak{d}}$ and similarly $\Lambda_i$ is the partition of $D$ obtained by taking the disjoint union of the $i$-th partition in each entry of  $\vec{\mathfrak{d}}$.
We can express the contribution to coefficient of \eqref{eq:mon} in $\HP^{\bullet}$ by covers of type  $\vec{\mathfrak{d}}$ in terms of connected Hurwitz numbers:
\begin{equation}\label{eq:discco}
\frac{1}{R!}{{R}\choose{r_1, \ldots, r_L}}
\frac{1}{l_1!\cdots l_k!}\prod_{j=1}^k\left(H_{\mathfrak{d}_j}\right)^{l_j},
\end{equation}
 where
\begin{itemize}
\item the quotient by the $l_j!$'s accounts for the automorphisms corresponding to permuting the connected components with equal data.
\item the multinomial coefficient accounts for all possible ways that the $R$ unmarked simple ramification can distribute themselves on the various connected component of the disconnected source curve.
\end{itemize}

Now we look at the term of order $L$ in the Taylor expansion of $\e^{\HP_g}$. There is a contribution to the monomial \eqref{eq:mon} coming from the partition $L=(l_1,\ldots,l_k)$, which has coefficient:
\begin{equation}
\frac{1}{r_1!\cdots r_L!}
\frac{1}{L!}{{L}\choose{l_1, \ldots, l_k}}\prod_{j=1}^k\left(H_{\mathfrak{d}_j}\right)^{l_j},
\end{equation}
equal to $\eqref{eq:discco}$. Adding this equation over all possible  $\vec{\mathfrak{d}}$ we obtain \eqref{eq:discco}.
\missingfigure{Count of disconnected covers}
\end{proof}


\begin{example} We observe \eqref{thm:expon} for the coefficients of the monomial $u^4 z q^3$:
\begin{equation}\label{eq:dcon}
H^{\bullet,4}_{0\to 0,3}\frac{u^4}{4!} z q^3=H^4_{0\to 0,3}
\frac{u^4}{4!} z q^3+\frac{1}{2!}2\left(H^4_{1\to 0,2}\frac{u^4}{4!} q^2\right)\left(H^0_{0\to 0,1} z q\right).
\end{equation}
\end{example}
\begin{exercise}
Check that equation \eqref{eq:dcon} is correct by evaluating the appropriate Hurwitz numbers.
\end{exercise}

\begin{exercise}
 Compute the disconnected Hurwitz number  $H^{\bullet,4}_{-1\to 0,4}=5$ in two ways: first using the Burnside formula (refer to Table \ref{tab:ct} for the character table of $S_4$); then by observing what kind of disconnected covers contribute to this Hurwitz number and computing the contribution of each type by elementary methods.

 What monomial is $H^{\bullet,4}_{-1\to 0,4}/4!$ the coefficient of in $\HP^\bullet$? Check that equation \eqref{thm:expon} holds for the coefficients of such monomial.
\end{exercise}




%\section{Degeneration Formulas}
%\todo[inline]{I am thinking of introducing the degeneration formula geometrically in chapters either 6 or 7 and here just do the generating function discussion of it...or at least think whether this makes sense to do...}
\section{Cut and join}

The name {\it cut and join} refers to a set of recursive relations among Hurwitz numbers, obtained by analyzing what happens to the cycle type of a fixed permutation in the symmetric group $S_d$ when it composed with any simple transposition. From a geometric point of view, this is a special case of the degeneration formulas (Section \ref{}), which amounts to degenerating the target curve to a nodal curve where one rational component is only supporting two branch points, one of which is given an arbitrary ramification profile condition, the other a simple ramification condition. These infinitely many recursions are efficiently encoded in one partial differential equation which the Hurwitz potential satisfies. This showcases the power of the generating function language to handle an incredible amount of combinatorial recursive complexity, provided that the recursive structure is well tuned to the generating function encoding.

We begin this discussion by stating the elementary group theoretic fact underlying the cut and join recursions.

\begin{fact}
\label{bascaj}
Let $\sigma\in S_d$ be a fixed element of cycle type $\lambda=(n_1,\ldots, n_l)$, written as a composition of disjoint cycles as $\sigma= c_l \ldots  c_1$. Let $\tau=(ij)\in S_d$ vary among all  transpositions. The cycle types of the composite elements $\tau  \sigma$ are described below.
\begin{description}
	\item[cut] if $i,j$ belong to the same cycle (say $c_l$), then this cycle gets ``cut in two'': $\tau  \sigma$ has cycle type	 $\lambda'=(n_1,\ldots, n_{l-1},m',m'')$, with $m'+m''=n_l$. If $m'\not=m''$, there are $n_l$ transpositions giving rise to an element of cycle type $\lambda'$. If $m'=m''=n_l/2$, then there are $n_l/2$.

	\item[join] if $i,j$ belong to different cycles (say $c_{l-1}$ and $c_l$ ), then these cycles are ``joined'':
	$\tau  \sigma$ has cycle type	$\lambda'=(n_1,\ldots, n_{l-1}+n_l)$. There are $n_{l-1}n_l$ transpositions giving rise to cycle type $\lambda'$.
\end{description}

\begin{example}
Let $d=4$. There are $6$ transpositions in $S_4$.
If $\sigma= (12)(34)$ is of cycle type $(2,2)$, then there are $2$  transpositions ($(12)$ and $(34)$ ) that ``cut'' $\sigma$ to give rise to a transposition and $2\cdot 2$ transpositions ($(13),(14),(23),(24)$) that  ``join'' $\sigma$ into a four-cycle.
\end{example}
\end{fact}
For readers allergic to notation, Figure \ref{fig:cutjoin} illustrates the above discussion.
\missingfigure{Cut and Join}
\begin{exercise}
Prove the statements of Fact \ref{bascaj}.
\end{exercise}

We now apply Fact \ref{bascaj} in the context of Hurwitz numbers. We focus our attention on one particular branch point $b$ on the base curve: the cut-and-join analysis describes what happens when a branch point corresponding to a simple ramification collides with $b$. Since all the ``action" happens locally around $b$, for ease of notation we set to zero all the variables $p_{i,j}$ with $j \geq 2$ and drop the subscript $1$ from the unique set of $p$-variables remaining:
%. We therefore denote the disconnected single Hurwitz potential:
\begin{equation}
\HP^\bullet_g(p_j,u,z,q):=\sum  H^{\bullet, r}_{h\to g, d}(\lambda)\ p_{\lambda} \frac{u^r}{r!}z^{1-h} q^d,
\end{equation}
The cut-and-join analysis translates to the following statement.

\begin{theorem}\label{caj}
The disconnected Hurwitz potential $\HP_g^\bullet$ is a solution to the following partial differential equation (cut-and-join operator):
\begin{equation}\label{disccaj}
\frac{\partial }{\partial{u}} =
\frac{1}{2}
\sum_{i,j\geq 1}
ijp_{i+j}z
\frac{\partial^2}{\partial{p_i}\partial{p_j}}
+ (i + j)p_ip_j
\frac{\partial}{\partial{p_{i+j}}}.
\end{equation}
\end{theorem}
\begin{proof}
We proof this theorem by analyzing the coefficient of an arbitrary monomial in equation \eqref{disccaj}. Consider the monomial $p_\lambda \frac{u^r}{r!} z^{1-h} q^d$ for arbitrary values of $\lambda, r,h$ and $d$. The coefficient on the left hand side of \eqref{disccaj} is the Hurwitz number $H^{\bullet, r+1}_{h\to g, d}(\lambda)$, which is $1/d!$ times the number of elements in the set
$$M^{r+1}_\lambda=\left\{(\sigma, \tau_0, \ldots, \tau_r, \alpha_1, \beta_1, \ldots,\alpha_g,\beta_g) \left|
\begin{array}{l}
 \bullet \ \sigma \in C_\lambda, \\ \bullet \
\tau_i \  \mbox{are simple transpositions},\\ \bullet \  [\alpha_g,\beta_g]\ldots [\alpha_1,\beta_1]\tau_r\ldots\tau_0\sigma= e
\end{array}\right.\right\}.$$
Now let $\Lambda'$ denote the set of partitions $\lambda' \dashv d$ that are obtained from $\lambda$ by either adding two parts of $\lambda$ or splitting one of the parts of $\lambda$ into two parts. For each $\lambda'\in \Lambda'$ define the set $M^r_{\lambda'}$ analogously (but note now that there are only $r$ transpositions).
Consider the natural function:
$$
\Phi: M^{r+1}_\lambda \to \coprod_{\lambda'\in \Lambda'}M^r_{\lambda'},
$$
defined by $$\Phi(\sigma, \tau_0, \tau_1, \ldots, \tau_r, \alpha_1, \beta_1, \ldots,\alpha_g,\beta_g) = (\tau_0\sigma, \tau_1, \ldots, \tau_r, \alpha_1, \beta_1, \ldots,\alpha_g,\beta_g).$$
Assume $\lambda$ is obtained from $\lambda'$ by adding two of the parts of $\lambda'$, say one of size $i$ and one of size $j$. By Fact \ref{bascaj}, for any element $x\in M^r_{\lambda'}$, the cardinality of the inverse image $\Phi^{-1}(x)$ is equal to $ij$ times the number $n_i$ of parts equal to $i$ in $\lambda'$, times the number $n_j$ of parts equal to $j$ in $\lambda'$.
Since the cardinality of $M^r_{\lambda'}$ is equal to $d!H^{\bullet, r}_{h-1\to g, d}(\lambda')$ (the genus of the cover curve drops by one by the Riemann-Hurwitz formula), we have:
\begin{equation}
\label{eq:caj1}
|\Phi^{-1}(M^r_{\lambda'})| = d! ijn_i n_j H^{\bullet, r}_{h-1\to g, d}(\lambda')
\end{equation}
We note that the quantity $ijn_i n_j H^{\bullet, r}_{h-1\to g, d}(\lambda')$ is the coefficient of the monomial $p_\lambda \frac{u^r}{r!} z^{1-h} q^d$ in the expression
$$
ijp_{i+j}z
\frac{\partial^2}{\partial{p_i}\partial{p_j}}\HP_g^{\bullet}.
$$

Now assume $\lambda$ is obtained from $\lambda'$ by splitting a part of $\lambda'$, say of size $i+j$  into one part of size $i$ and one of size $j$, with $i\not=j$. By Fact \ref{bascaj}, for any element $x\in M^r_{\lambda'}$, the cardinality of the inverse image $\Phi^{-1}(x)$ is equal to $i+j$ times the number $n_{i+j}$ of parts equal to $i+j$ in $\lambda'$.
The cardinality of $M^r_{\lambda'}$ is equal to $d!H^{\bullet, r}_{h\to g, d}(\lambda')$ , hence
\begin{equation}\label{eqij}
|\Phi^{-1}(M^r_{\lambda'})| = d! (i+j)n_{i+j} H^{\bullet, r}_{h\to g, d}(\lambda').
\end{equation}

The quantity $(i+j)n_{i+j} H^{\bullet, r}_{h\to g, d}(\lambda')$ is the coefficient of the monomial $p_\lambda \frac{u^r}{r!} z^{1-h} q^d$ in the expression
$$
(i + j)p_ip_j
\frac{\partial}{\partial{p_{i+j}}}\HP_g^{\bullet}.
$$

Finally, in the case in which a part of size $2i$ in $\lambda'$ is split into two parts of equal size $i$, we must divide the RHS of \eqref{eqij} by $2$, and correspondingly the term $1/2(i+i)n_{i+i}H^{\bullet, r}_{h\to g, d}(\lambda')$ is the coefficient of the monomial  $p_\lambda \frac{u^r}{r!} z^{1-h} q^d$ in the expression
$$
\frac{1}{2}(i + i)p_ip_i
\frac{\partial}{\partial{p_{i+i}}}\HP_g^{\bullet}.
$$




Now we have
\begin{equation}\label{eq:caj2}
|\Phi^{-1}(M^{r+1}_{\lambda})| = \sum_{\lambda' \in \Lambda}|\Phi^{-1}(M^r_{\lambda'})|
\end{equation}

If we substitute \eqref{eq:caj1},\eqref{eqij} in \eqref{eq:caj2} and divide \eqref{eq:caj2} by $d!$, we obtain the equality of the coefficients of the monomial $p_\lambda \frac{u^r}{r!} z^{1-h} q^d$ in equation \eqref{disccaj}: we only must notice that reorganizing the sum over $\lambda' \in \Lambda$ as a sum over all possible $i,j$, we must divide by $1/2$ to account for the overcounting arising from  switching the roles of $i$ and $j$ and for the factor of $1/2$ that appears when $i=j$.
\end{proof}

\begin{exercise}
Write an exercise to check a particular coefficient of the CAJ equation.
\end{exercise}

Like for most facts in Hurwitz theory that are directly connected to the representation theory of the symmetric group, the disconnected setting is the most natural one to formulate the cut-and-join recursions. However, when a cycle is cut, it is cut in exactly two parts. Consequently, a connected cover can be disconnected in at most two components. One can therefore obtain a connected cut-and-join operator by keeping track of this additional information. The connected cut-and-join analysis appears in \cite{}. Here we state it and leave the proof as a {\it gran finale} exercise for our readers!
%, that at this point are Hurwitz theory experts!


\begin{corollary} \label{conncaj}
The connected Hurwitz potential $\HP_g$ is a solution to the following differential equation (connected cut-and-join operator):
\begin{equation}
\frac{\partial }{\partial{u}} =
\frac{1}{2}
\sum_{i,j1}
ijp_{i+j}
\left(z
\frac{\partial^2}{\partial{p_i}\partial{p_j}}
+
\frac{\partial}{\partial{p_i}}
\frac{\partial}{\partial{p_j}}\right)
+ (i + j)p_ip_j
\frac{\partial}{\partial{p_{i+j}}}.
\end{equation}
\end{corollary}
\begin{exercise}
Prove Corollary \ref{conncaj}
\end{exercise}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\section*{Acknowledgements}
%Here are our acknowledgements.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\bibliographystyle{alphaurl}
%\bibliography{references}

%\appendix
%\chapter{Classification of Compact, Connected Topological Surfaces}
%\label{classificationOfSurfaces}
%\chapter{Complex Tori and Elliptic Curves}
%\label{complextoriellcur}
\appendix
\chapter{TQFT - Renzo}
\chapter{Positive Characteristics- Rachel}
\chapter{Tropical - Hannah and/or Dhruv}
\chapter{Physics - Vincent}
\chapter{ELSV-Fock Space - Paul}
\end{document}





